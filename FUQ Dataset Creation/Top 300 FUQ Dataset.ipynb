{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d481827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from haystack.nodes import QuestionGenerator, ElasticsearchRetriever, FARMReader\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "from haystack.pipelines import (\n",
    "    QuestionGenerationPipeline,\n",
    "    RetrieverQuestionGenerationPipeline,\n",
    "    QuestionAnswerGenerationPipeline,\n",
    ")\n",
    "from haystack.utils import launch_es\n",
    "from haystack.document_stores import FAISSDocumentStore\n",
    "from haystack.schema import Document\n",
    "import nltk\n",
    "from rouge import Rouge \n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as urllib2\n",
    "import wikipediaapi\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a112db84",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = pd.read_csv(\"Keywords-Springer-83K-20210405.csv\", header = None)\n",
    "keywords = keywords[0].to_numpy().tolist()[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37c80935",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/roberta-base-squad2 were not used when initializing RobertaModel: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at deepset/roberta-base-squad2 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n"
     ]
    }
   ],
   "source": [
    "wiki_wiki = wikipediaapi.Wikipedia('en', extract_format=wikipediaapi.ExtractFormat.HTML)\n",
    "question_generator = QuestionGenerator()\n",
    "question_generation_pipeline = QuestionGenerationPipeline(question_generator)\n",
    "reader = FARMReader(\"deepset/roberta-base-squad2\")\n",
    "qag_pipeline = QuestionAnswerGenerationPipeline(question_generator, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "637cd0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "failed_topics = []\n",
    "headings = [\"title\", \"section\", \"full_text\", \"summ_text\", \"questions\", \"answers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33ebcb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "start_time = time.time()\n",
    "for topic in keywords:\n",
    "    try:\n",
    "        page = wiki_wiki.page(topic)\n",
    "\n",
    "        content = [(\"Summary\", page.summary)]\n",
    "        for section in page.sections:\n",
    "            if section.title == \"See also\":\n",
    "                break\n",
    "            content.append((section.title, section.text))\n",
    "\n",
    "        docs_data = []\n",
    "        for title, text in content:\n",
    "            soup = BeautifulSoup(text)\n",
    "            for p in soup.find_all(\"p\"):\n",
    "                sentences = nltk.sent_tokenize(p.text)\n",
    "                if len(sentences) < 2:\n",
    "                    continue\n",
    "                docs_data.append((title, p.text, \" \".join(sentences[:2])))\n",
    "\n",
    "        for doc in docs_data:\n",
    "            result = qag_pipeline.run(documents = [Document(content = doc[2])])\n",
    "\n",
    "            questions = [ret[\"query\"] for ret in result[\"results\"]]\n",
    "            answers = [ret[\"answers\"][0].answer for ret in result[\"results\"]]\n",
    "\n",
    "            data.append([topic, doc[0], doc[1], doc[2], questions, answers])\n",
    "    except:\n",
    "        failed_topics.append(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6f9214c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 30970.05046772957 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c336e910",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data).to_csv(\"top300.csv\", header = headings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05841cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature selection',\n",
       " 'independent component analysis',\n",
       " 'image segmentation',\n",
       " 'multi-objective optimization',\n",
       " 'multiobjective optimization',\n",
       " 'linear discriminant analysis',\n",
       " 'homomorphic encryption']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed_topics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
