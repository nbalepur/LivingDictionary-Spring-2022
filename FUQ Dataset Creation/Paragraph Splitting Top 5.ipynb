{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f243c892",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nishu\\Anaconda3\\envs\\haystack\\lib\\site-packages\\ray\\autoscaler\\_private\\cli_logger.py:57: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from haystack.nodes import QuestionGenerator, ElasticsearchRetriever, FARMReader\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "from haystack.pipelines import (\n",
    "    QuestionGenerationPipeline,\n",
    "    RetrieverQuestionGenerationPipeline,\n",
    "    QuestionAnswerGenerationPipeline,\n",
    ")\n",
    "from haystack.utils import launch_es\n",
    "from haystack.document_stores import FAISSDocumentStore\n",
    "from haystack.schema import Document\n",
    "import nltk\n",
    "from rouge import Rouge \n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as urllib2\n",
    "import wikipediaapi\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77d20e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = pd.read_csv(\"Keywords-Springer-83K-20210405.csv\", header = None)\n",
    "keywords = keywords[0].to_numpy().tolist()[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f453d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/roberta-base-squad2 were not used when initializing RobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at deepset/roberta-base-squad2 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n"
     ]
    }
   ],
   "source": [
    "wiki_wiki = wikipediaapi.Wikipedia('en', extract_format=wikipediaapi.ExtractFormat.HTML)\n",
    "question_generator = QuestionGenerator()\n",
    "question_generation_pipeline = QuestionGenerationPipeline(question_generator)\n",
    "reader = FARMReader(\"deepset/roberta-base-squad2\")\n",
    "qag_pipeline = QuestionAnswerGenerationPipeline(question_generator, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03663fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "failed_topics = []\n",
    "headings = [\"topic\", \"prev_section\", \"next_section\", \"prev_doc_text\", \"next_doc_text\", \"questions\", \"answers\", \"scores\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94cabe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "start_time = time.time()\n",
    "for topic in keywords[:5]:\n",
    "    try:\n",
    "        page = wiki_wiki.page(topic)\n",
    "\n",
    "        content = [(\"Summary\", page.summary)]\n",
    "        for section in page.sections:\n",
    "            if section.title == \"See also\":\n",
    "                break\n",
    "            content.append((section.title, section.text))\n",
    "\n",
    "        docs_data = []\n",
    "        for title, text in content:\n",
    "            soup = BeautifulSoup(text)\n",
    "            for p in soup.find_all(\"p\"):\n",
    "                #sentences = nltk.sent_tokenize(p.text)\n",
    "                #if len(sentences) <= 2:\n",
    "                #continue\n",
    "                \n",
    "                # section, text\n",
    "                docs_data.append((title, p.text))\n",
    "        \n",
    "        \n",
    "        for i in range(len(docs_data) - 1):\n",
    "            \n",
    "            try:\n",
    "                curr_doc = docs_data[i]\n",
    "                next_doc = docs_data[i + 1]\n",
    "\n",
    "                result = qag_pipeline.run(documents = [Document(content = next_doc[-1])])\n",
    "\n",
    "                if len(result[\"results\"][0][\"answers\"]) == 0:\n",
    "                    continue\n",
    "\n",
    "                questions = [ret[\"query\"] for ret in result[\"results\"]]\n",
    "                answers = [ret[\"answers\"][0].answer for ret in result[\"results\"]]\n",
    "                scores = [ret[\"answers\"][0].score for ret in result[\"results\"]]\n",
    "\n",
    "                # topic, prev_section, next_section, prev_doc_text, next_doc_text, next_doc_questions, next_doc_answers, scores\n",
    "                data.append([topic, curr_doc[0], next_doc[0], curr_doc[1], next_doc[1], questions, answers, scores])\n",
    "                \n",
    "            except:\n",
    "                a = 1\n",
    "\n",
    "    except:\n",
    "        failed_topics.append(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c92d34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2466.0360250473022\n"
     ]
    }
   ],
   "source": [
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7dafa361",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data).to_csv(\"paragraph_split_top5.csv\", header = headings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
