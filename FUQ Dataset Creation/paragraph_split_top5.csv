,topic,prev_section,next_section,prev_doc_text,next_doc_text,questions,answers,scores
0,machine learning,Summary,Summary,"Machine learning (ML) is the study of computer algorithms that can improve automatically through experience and by the use of data. It is seen as a part of artificial intelligence. Machine learning algorithms build a model based on sample data, known as training data, in order to make predictions or decisions without being explicitly programmed to do so. Machine learning algorithms are used in a wide variety of applications, such as in medicine, email filtering, speech recognition, and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.","A subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers; but not all machine learning is statistical learning. The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning. Some implementations of machine learning use data and neural networks in a way that mimics the working of a biological brain.  In its application across business problems, machine learning is also referred to as predictive analytics.
","[' What is a subset of machine learning closely related to?', ' What focuses on making predictions using computers?', ' The study of mathematical optimization delivers methods, theory and application domains to what field of learning?', ' What is a related field of study?', ' What does data mining focus on?', ' Some implementations of machine learning use data and neural networks in a way that mimics the working of a biological brain?', ' What is machine learning also referred to as in business problems?']","['computational statistics', 'computational statistics', 'machine learning', 'Data mining', 'exploratory data analysis through unsupervised learning', 'Data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning. Some implementations of machine learning use data and neural networks in a way that mimics the working of a biological brain.', 'predictive analytics']","[0.9746738374233246, 0.9813735783100128, 0.7400325834751129, 0.6854493319988251, 0.7274577170610428, 0.10543884336948395, 0.9764671921730042]"
1,machine learning,Summary,Overview,"A subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers; but not all machine learning is statistical learning. The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning. Some implementations of machine learning use data and neural networks in a way that mimics the working of a biological brain.  In its application across business problems, machine learning is also referred to as predictive analytics.
","Learning algorithms work on the basis that strategies, algorithms, and inferences that worked well in the past are likely to continue working well in the future. These inferences can be obvious, such as ""since the sun rose every morning for the last 10,000 days, it will probably rise tomorrow morning as well"". They can be nuanced, such as ""X% of families have geographically separate species with color variants, so there is a Y% chance that undiscovered black swans exist"".","[' Learning algorithms work on the basis that strategies, algorithms, and inferences that worked well in the past are likely to continue working well in what future?', ' What percentage of families have geographically separate species with color variants?', ' What is the chance that undiscovered black swans exist?']","['the future', 'X%', 'Y%']","[0.4122489243745804, 0.8027888238430023, 0.8620643019676208]"
2,machine learning,Overview,Overview,"Learning algorithms work on the basis that strategies, algorithms, and inferences that worked well in the past are likely to continue working well in the future. These inferences can be obvious, such as ""since the sun rose every morning for the last 10,000 days, it will probably rise tomorrow morning as well"". They can be nuanced, such as ""X% of families have geographically separate species with color variants, so there is a Y% chance that undiscovered black swans exist"".","Machine learning programs can perform tasks without being explicitly programmed to do so. It involves computers learning from data provided so that they carry out certain tasks. For simple tasks assigned to computers, it is possible to program algorithms telling the machine how to execute all steps required to solve the problem at hand; on the computer's part, no learning is needed. For more advanced tasks, it can be challenging for a human to manually create the needed algorithms. In practice, it can turn out to be more effective to help the machine develop its own algorithm, rather than having human programmers specify every needed step.","[' What type of programs can perform tasks without being explicitly programmed to do so?', ' Machine learning involves computers learning from data provided so that they carry out certain tasks?', ' What does the computer do?', ' What can be challenging for a human to manually create?', ' In practice, it can turn out to be more effective to help the machine develop what?']","['Machine learning', 'Machine learning', 'learning from data provided so that they carry out certain tasks. For simple tasks assigned to computers, it is possible to program algorithms telling the machine how to execute all steps required to solve the problem at hand', 'the needed algorithms', 'its own algorithm']","[0.8381513357162476, 0.4335131496191025, 0.12790382280945778, 0.5445558279752731, 0.9334076941013336]"
3,machine learning,Overview,Overview,"Machine learning programs can perform tasks without being explicitly programmed to do so. It involves computers learning from data provided so that they carry out certain tasks. For simple tasks assigned to computers, it is possible to program algorithms telling the machine how to execute all steps required to solve the problem at hand; on the computer's part, no learning is needed. For more advanced tasks, it can be challenging for a human to manually create the needed algorithms. In practice, it can turn out to be more effective to help the machine develop its own algorithm, rather than having human programmers specify every needed step.","The discipline of machine learning employs various approaches to teach computers to accomplish tasks where no fully satisfactory algorithm is available. In cases where vast numbers of potential answers exist, one approach is to label some of the correct answers as valid. This can then be used as training data for the computer to improve the algorithm(s) it uses to determine correct answers. For example, to train a system for the task of digital character recognition, the MNIST dataset of handwritten digits has often been used.","[' What discipline uses various approaches to teach computers to accomplish tasks where no fully satisfactory algorithm is available?', ' In cases where vast numbers of potential answers exist, one approach is to label some of the correct answers as what?', ' What can be used as training data for the computer to improve?', ' What dataset has often been used to train a system for the task of digital character recognition?']","['machine learning', 'valid', 'label some of the correct answers', 'MNIST']","[0.9422248303890228, 0.9953899383544922, 0.25189972668886185, 0.6350553333759308]"
4,machine learning,Overview,History and relationships to other fields,"The discipline of machine learning employs various approaches to teach computers to accomplish tasks where no fully satisfactory algorithm is available. In cases where vast numbers of potential answers exist, one approach is to label some of the correct answers as valid. This can then be used as training data for the computer to improve the algorithm(s) it uses to determine correct answers. For example, to train a system for the task of digital character recognition, the MNIST dataset of handwritten digits has often been used.","The term machine learning was coined in 1959 by Arthur Samuel, an American IBMer and pioneer in the field of computer gaming and artificial intelligence. Also the synonym self-teaching computers was used in this time period. A representative book of the machine learning research during the 1960s was the Nilsson's book on Learning Machines, dealing mostly with machine learning for pattern classification. Interest related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973. In 1981 a report was given on using teaching strategies so that a neural network learns to recognize 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal.","[' Who coined the term machine learning in 1959?', ' Who was a pioneer in the field of computer gaming and artificial intelligence?', ' What was the synonym for self-teaching computers in the 1960s?', "" What was the focus of Nilsson's book on Learning Machines in the 1960's?"", ' What did Duda and Hart describe in 1973?', ' In what year was a report given on using teaching strategies?', ' What year was a report given on using teaching strategies?', ' How many characters did a neural network learn to recognize from a computer terminal?']","['Arthur Samuel', 'Arthur Samuel', 'machine learning', 'machine learning for pattern classification', 'pattern recognition', '1981', '1981', '40']","[0.9945755302906036, 0.9614342153072357, 0.05364692769944668, 0.7193358540534973, 0.7720434963703156, 0.9668631553649902, 0.9539737701416016, 0.9024312794208527]"
5,machine learning,History and relationships to other fields,History and relationships to other fields,"The term machine learning was coined in 1959 by Arthur Samuel, an American IBMer and pioneer in the field of computer gaming and artificial intelligence. Also the synonym self-teaching computers was used in this time period. A representative book of the machine learning research during the 1960s was the Nilsson's book on Learning Machines, dealing mostly with machine learning for pattern classification. Interest related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973. In 1981 a report was given on using teaching strategies so that a neural network learns to recognize 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal.","Tom M. Mitchell provided a widely quoted, more formal definition of the algorithms studied in the machine learning field: ""A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P,  improves with experience E."" This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather than defining the field in cognitive terms. This follows Alan Turing's proposal in his paper ""Computing Machinery and Intelligence"", in which the question ""Can machines think?"" is replaced with the question ""Can machines do what we (as thinking entities) can do?"".","[' Tom M. Mitchell provided a more formal definition of the algorithms studied in what field?', ' What does P do if its performance at tasks in T, as measured by P, improves with experience E?', ' What does Alan Turing\'s paper ""Computing"" offer?', ' What did Alan Turing propose in his paper ""Computing Machinery and Intelligence""?', ' What was replaced with the question ""Can machines think?""']","['machine learning', 'performance measure', 'the question ""Can machines think?"" is replaced with the question ""Can machines do what we (as thinking entities) can do?"".', 'the question ""Can machines think?"" is replaced with the question ""Can machines do what we (as thinking entities) can do?"".', 'Can machines do what we (as thinking entities) can do?"".']","[0.7920979857444763, 0.6576171964406967, 0.07004428654909134, 0.4031449034810066, 0.5448727905750275]"
6,machine learning,History and relationships to other fields,History and relationships to other fields,"Tom M. Mitchell provided a widely quoted, more formal definition of the algorithms studied in the machine learning field: ""A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P,  improves with experience E."" This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather than defining the field in cognitive terms. This follows Alan Turing's proposal in his paper ""Computing Machinery and Intelligence"", in which the question ""Can machines think?"" is replaced with the question ""Can machines do what we (as thinking entities) can do?"".","Modern day machine learning has two objectives, one is to classify data based on models which have been developed, the other purpose is to make predictions for future outcomes based on these models. A hypothetical algorithm specific to classifying data may use computer vision of moles coupled with supervised learning in order to train it to classify the cancerous moles. Where as, a machine learning algorithm for stock trading may inform the trader of future potential predictions.","[' How many objectives does modern day machine learning have?', ' What is the other purpose of machine learning?', ' A hypothetical algorithm specific to classifying data may use what?', ' What could be used to train a machine learning algorithm to classify cancerous moles?']","['two', 'to make predictions for future outcomes based on these models', 'computer vision of moles', 'computer vision of moles coupled with supervised learning']","[0.8722682297229767, 0.6042370200157166, 0.8595366179943085, 0.6416972875595093]"
7,machine learning,History and relationships to other fields,Theory,"Modern day machine learning has two objectives, one is to classify data based on models which have been developed, the other purpose is to make predictions for future outcomes based on these models. A hypothetical algorithm specific to classifying data may use computer vision of moles coupled with supervised learning in order to train it to classify the cancerous moles. Where as, a machine learning algorithm for stock trading may inform the trader of future potential predictions.","A core objective of a learner is to generalize from its experience. Generalization in this context is the ability of a learning machine to perform accurately on new, unseen examples/tasks after having experienced a learning data set. The training examples come from some generally unknown probability distribution (considered representative of the space of occurrences) and the learner has to build a general model about this space that enables it to produce sufficiently accurate predictions in new cases.
","[' What is a core objective of a learner?', ' What is generalization?', ' How does a learning machine perform on new, unseen examples?', ' What is considered representative of the space of occurrences?', ' The learner has to build a general model about what space?']","['to generalize from its experience', 'the ability of a learning machine to perform accurately on new, unseen examples/tasks after having experienced a learning data set', 'accurately', 'probability distribution', 'probability distribution']","[0.8444018661975861, 0.6967074573040009, 0.7750635743141174, 0.5864997804164886, 0.4402386099100113]"
8,machine learning,Theory,Theory,"A core objective of a learner is to generalize from its experience. Generalization in this context is the ability of a learning machine to perform accurately on new, unseen examples/tasks after having experienced a learning data set. The training examples come from some generally unknown probability distribution (considered representative of the space of occurrences) and the learner has to build a general model about this space that enables it to produce sufficiently accurate predictions in new cases.
","The computational analysis of machine learning algorithms and their performance is a branch of theoretical computer science known as computational learning theory. Because training sets are finite and the future is uncertain, learning theory usually does not yield guarantees of the performance of algorithms. Instead, probabilistic bounds on the performance are quite common. The bias–variance decomposition is one way to quantify generalization error.
","[' What is the branch of theoretical computer science known as?', ' What does computational analysis of machine learning algorithms and their performance do?', ' Training sets are finite and the future is uncertain, what does learning theory usually not yield?', ' Learning theory does not yield guarantees of what?', ' What is one way to quantify generalization error?']","['computational learning theory', 'computational learning theory', 'guarantees of the performance of algorithms', 'the performance of algorithms', 'bias–variance decomposition']","[0.7433665692806244, 0.30565236508846283, 0.9144635200500488, 0.7026781588792801, 0.741848349571228]"
9,machine learning,Theory,Theory,"The computational analysis of machine learning algorithms and their performance is a branch of theoretical computer science known as computational learning theory. Because training sets are finite and the future is uncertain, learning theory usually does not yield guarantees of the performance of algorithms. Instead, probabilistic bounds on the performance are quite common. The bias–variance decomposition is one way to quantify generalization error.
","For the best performance in the context of generalization, the complexity of the hypothesis should match the complexity of the function underlying the data. If the hypothesis is less complex than the function, then the model has under fitted the data. If the complexity of the model is increased in response, then the training error decreases. But if the hypothesis is too complex, then the model is subject to overfitting and generalization will be poorer.","[' What should the complexity of the hypothesis match?', ' If the hypothesis is less complex than the function, then the model has under fitted the data?', ' What happens if the complexity of the model is increased in response to an increase in complexity?', ' If the hypothesis is too complex, what happens to the model?']","['the complexity of the function underlying the data', 'complexity of the hypothesis should match the complexity of the function underlying the data. If the hypothesis is less complex than the function, then the model has under fitted the data. If the complexity of the model is increased in response, then the training error decreases. But if the hypothesis is too complex, then the model is subject to overfitting', 'the training error decreases', 'overfitting']","[0.7263937890529633, 0.01481617521494627, 0.732125461101532, 0.6105529963970184]"
10,machine learning,Theory,Theory,"For the best performance in the context of generalization, the complexity of the hypothesis should match the complexity of the function underlying the data. If the hypothesis is less complex than the function, then the model has under fitted the data. If the complexity of the model is increased in response, then the training error decreases. But if the hypothesis is too complex, then the model is subject to overfitting and generalization will be poorer.","In addition to performance bounds, learning theorists study the time complexity and feasibility of learning. In computational learning theory, a computation is considered feasible if it can be done in polynomial time. There are two kinds of time complexity results: Positive results show that a certain class of functions can be learned in polynomial time. Negative results show that certain classes cannot be learned in polynomial time.
","[' What do learning theorists study in addition to performance bounds?', ' What is considered feasible in computational learning theory if it can be done in polynomial time?', ' How many kinds of time complexity results are there?', ' Positive results show that a certain class of functions can do what?', ' Positive results show that a certain class of functions can be learned in what time?', ' Negative results show what?']","['time complexity and feasibility of learning', 'a computation', 'two', 'learned in polynomial time', 'polynomial time', 'certain classes cannot be learned in polynomial time']","[0.6634190231561661, 0.8728274405002594, 0.900559812784195, 0.4282187968492508, 0.45551133155822754, 0.6703253090381622]"
11,machine learning,Theory,Approaches,"In addition to performance bounds, learning theorists study the time complexity and feasibility of learning. In computational learning theory, a computation is considered feasible if it can be done in polynomial time. There are two kinds of time complexity results: Positive results show that a certain class of functions can be learned in polynomial time. Negative results show that certain classes cannot be learned in polynomial time.
","
Machine learning approaches are traditionally divided into three broad categories, depending on the nature of the ""signal"" or ""feedback"" available to the learning system:
",[' Machine learning approaches are traditionally divided into how many broad categories?'],['three'],[0.9168162941932678]
12,machine learning,Applications,Applications,"There are many applications for machine learning, including:
","In 2006, the media-services provider Netflix held the first ""Netflix Prize"" competition to find a program to better predict user preferences and improve the accuracy of its existing Cinematch movie recommendation algorithm by at least 10%.  A joint team made up of researchers from AT&T Labs-Research in collaboration with the teams Big Chaos and Pragmatic Theory built an ensemble model to win the Grand Prize in 2009 for $1 million. Shortly after the prize was awarded, Netflix realized that viewers' ratings were not the best indicators of their viewing patterns (""everything is a recommendation"") and they changed their recommendation engine accordingly. In 2010 The Wall Street Journal wrote about the firm Rebellion Research and their use of machine learning to predict the financial crisis. In 2012, co-founder of Sun Microsystems, Vinod Khosla, predicted that 80% of medical doctors' jobs would be lost in the next two decades to automated machine learning medical diagnostic software. In 2014, it was reported that a machine learning algorithm had been applied in the field of art history to study fine art paintings and that it may have revealed previously unrecognized influences among artists. In 2019 Springer Nature published the first research book created using machine learning. In 2020, machine learning technology was used to help make diagnoses and aid researchers in developing a cure for COVID-19. Machine learning is recently applied to predict the green behavior of human-being. Recently, machine learning technology is also applied to optimise smartphone's performance and thermal behaviour based on the user's interaction with the phone.","[' In what year did Netflix hold the first ""Netflix Prize"" competition?', ' What was the goal of the first competition for a program to better predict user preferences and improve the accuracy of its existing Cinematch movie recommendation algorithm?', ' In 2006, what was the name of the competition held by the media-services provider Netflix?', ' What was the prize for the ensemble model that won the Grand Prize in 2009?', "" What company realized that viewers' ratings were not the best indicators of their viewing patterns?"", ' In what year did the grand prize win?', ' What did The Wall Street Journal write about in 2010?', ' What did Rebellion Research use to predict the financial crisis?', ' Who was the co-founder of Sun Microsystems in 2012?', "" Who predicted that 80% of medical doctors' jobs would be lost in the next two decades?"", ' What year was it reported that a machine learning algorithm had been applied in the field?', ' In what field was a machine learning algorithm applied to study fine art paintings?', ' In what year did Springer Nature publish the first research book created using machine learning?', ' In what year was machine learning used to help researchers develop a cure for COVID-19?', ' What has been applied to predict the green behavior of human-being?', ' Machine learning is also applied to optimise what?', "" What is applied to optimise smartphone's performance and thermal behaviour based on user interaction with the phone?""]","['2006', 'at least 10%.', 'Netflix Prize', '$1\xa0million', 'Netflix', '2009', 'Rebellion Research', 'machine learning', 'Vinod Khosla', 'Vinod Khosla', '2014', 'art history', '2019', '2020', 'Machine learning', ""smartphone's performance and thermal behaviour"", 'machine learning technology']","[0.990334689617157, 0.6495348215103149, 0.6387156546115875, 0.9709452688694, 0.5677154362201691, 0.9829132854938507, 0.7218020856380463, 0.993554562330246, 0.9948334693908691, 0.9076131582260132, 0.8304426074028015, 0.966478705406189, 0.9926455020904541, 0.9823903143405914, 0.9787939190864563, 0.7162711471319199, 0.8794623017311096]"
13,machine learning,Applications,Limitations,"In 2006, the media-services provider Netflix held the first ""Netflix Prize"" competition to find a program to better predict user preferences and improve the accuracy of its existing Cinematch movie recommendation algorithm by at least 10%.  A joint team made up of researchers from AT&T Labs-Research in collaboration with the teams Big Chaos and Pragmatic Theory built an ensemble model to win the Grand Prize in 2009 for $1 million. Shortly after the prize was awarded, Netflix realized that viewers' ratings were not the best indicators of their viewing patterns (""everything is a recommendation"") and they changed their recommendation engine accordingly. In 2010 The Wall Street Journal wrote about the firm Rebellion Research and their use of machine learning to predict the financial crisis. In 2012, co-founder of Sun Microsystems, Vinod Khosla, predicted that 80% of medical doctors' jobs would be lost in the next two decades to automated machine learning medical diagnostic software. In 2014, it was reported that a machine learning algorithm had been applied in the field of art history to study fine art paintings and that it may have revealed previously unrecognized influences among artists. In 2019 Springer Nature published the first research book created using machine learning. In 2020, machine learning technology was used to help make diagnoses and aid researchers in developing a cure for COVID-19. Machine learning is recently applied to predict the green behavior of human-being. Recently, machine learning technology is also applied to optimise smartphone's performance and thermal behaviour based on the user's interaction with the phone.","Although machine learning has been transformative in some fields, machine-learning programs often fail to deliver expected results. Reasons for this are numerous: lack of (suitable) data, lack of access to the data, data bias, privacy problems, badly chosen tasks and algorithms, wrong tools and people, lack of resources, and evaluation problems.","[' Machine learning has been transformative in what fields?', ' Why do machine learning programs often fail to deliver expected results?', ' What are some of the problems with algorithms?', ' What is one of the issues with evaluation?']","['some fields', 'lack of (suitable) data', 'badly chosen tasks and algorithms, wrong tools and people, lack of resources, and evaluation problems', 'lack of resources']","[0.36313020437955856, 0.6245921701192856, 0.06115887500345707, 0.37439996004104614]"
14,machine learning,Limitations,Limitations,"Although machine learning has been transformative in some fields, machine-learning programs often fail to deliver expected results. Reasons for this are numerous: lack of (suitable) data, lack of access to the data, data bias, privacy problems, badly chosen tasks and algorithms, wrong tools and people, lack of resources, and evaluation problems.","In 2018, a self-driving car from Uber failed to detect a pedestrian, who was killed after a collision. Attempts to use machine learning in healthcare with the IBM Watson system failed to deliver even after years of time and billions of dollars invested.","[' In 2018, a self-driving car from what company failed to detect a pedestrian?', "" What was the cause of the pedestrian's death?"", ' In 2018, what system failed to deliver even after years of time and billions of dollars invested?']","['Uber', 'after a collision', 'IBM Watson']","[0.9966593086719513, 0.6916291266679764, 0.7207906544208527]"
15,machine learning,Limitations,Limitations,"In 2018, a self-driving car from Uber failed to detect a pedestrian, who was killed after a collision. Attempts to use machine learning in healthcare with the IBM Watson system failed to deliver even after years of time and billions of dollars invested.","Machine learning has been used as a strategy to update the evidence related to systematic review and increased reviewer burden related to the growth of biomedical literature. While it has improved with training sets, it has not yet developed sufficiently to reduce the workload burden without limiting the necessary sensitivity for the findings research themselves.","[' Machine learning has been used to update the evidence related to what?', ' What has increased reviewer burden related to the growth of biomedical literature?', ' How has machine learning improved with training sets?', ' To reduce the workload without limiting the necessary sensitivity for the findings research themselves?']","['systematic review', 'Machine learning', 'it has not yet developed sufficiently to reduce the workload burden without limiting the necessary sensitivity for the findings research themselves', 'Machine learning']","[0.850388914346695, 0.7973089218139648, 0.4360301047563553, 0.2751920372247696]"
16,machine learning,Limitations,Model assessments,"Machine learning has been used as a strategy to update the evidence related to systematic review and increased reviewer burden related to the growth of biomedical literature. While it has improved with training sets, it has not yet developed sufficiently to reduce the workload burden without limiting the necessary sensitivity for the findings research themselves.","Classification of machine learning models can be validated by accuracy estimation techniques like the holdout method, which splits the data in a training and test set (conventionally 2/3 training set and 1/3 test set designation) and evaluates the performance of the training model on the test set. In comparison, the K-fold-cross-validation method randomly partitions the data into K subsets and then K experiments are performed each respectively considering 1 subset for evaluation and the remaining K-1 subsets for training the model. In addition to the holdout and cross-validation methods, bootstrap, which samples n instances with replacement from the dataset, can be used to assess model accuracy.","[' What can be validated by accuracy estimation techniques like the holdout method?', ' What splits the data in a training and test set and evaluates the performance of the training model on the test set?', ' What does the K-fold-cross-validation method randomly partition the data into?', ' How many subsets of data are used for evaluation?', ' What is used for training the model?', ' What can be used to assess model accuracy?', ' What does bootstrap sample?']","['Classification of machine learning models', 'holdout method', 'K subsets', '1', 'K-1 subsets', 'bootstrap', 'n instances with replacement from the dataset']","[0.9114567637443542, 0.7829971313476562, 0.9814216196537018, 0.8412502408027649, 0.8153704106807709, 0.9603467881679535, 0.9254405796527863]"
17,machine learning,Model assessments,Model assessments,"Classification of machine learning models can be validated by accuracy estimation techniques like the holdout method, which splits the data in a training and test set (conventionally 2/3 training set and 1/3 test set designation) and evaluates the performance of the training model on the test set. In comparison, the K-fold-cross-validation method randomly partitions the data into K subsets and then K experiments are performed each respectively considering 1 subset for evaluation and the remaining K-1 subsets for training the model. In addition to the holdout and cross-validation methods, bootstrap, which samples n instances with replacement from the dataset, can be used to assess model accuracy.","In addition to overall accuracy, investigators frequently report sensitivity and specificity meaning True Positive Rate (TPR) and True Negative Rate (TNR) respectively. Similarly, investigators sometimes report the false positive rate (FPR) as well as the false negative rate (FNR). However, these rates are ratios that fail to reveal their numerators and denominators. The total operating characteristic (TOC) is an effective method to express a model's diagnostic ability. TOC shows the numerators and denominators of the previously mentioned rates, thus TOC provides more information than the commonly used receiver operating characteristic (ROC) and ROC's associated area under the curve (AUC).","[' What do investigators often report in addition to overall accuracy?', ' What are TPR and TNR?', ' What are ratios that fail to reveal their numerators and denominators?', "" What is an effective method to express a model's diagnostic ability?"", ' What does AUC stand for?', ' What is the most common receiver operating characteristic?']","['sensitivity and specificity', 'True Positive Rate (TPR) and True Negative Rate', 'false positive rate', 'The total operating characteristic', 'associated area under the curve', 'ROC']","[0.8083942532539368, 0.6759800314903259, 0.3409174829721451, 0.5349939465522766, 0.9199413359165192, 0.7472849190235138]"
18,machine learning,Model assessments,Ethics,"In addition to overall accuracy, investigators frequently report sensitivity and specificity meaning True Positive Rate (TPR) and True Negative Rate (TNR) respectively. Similarly, investigators sometimes report the false positive rate (FPR) as well as the false negative rate (FNR). However, these rates are ratios that fail to reveal their numerators and denominators. The total operating characteristic (TOC) is an effective method to express a model's diagnostic ability. TOC shows the numerators and denominators of the previously mentioned rates, thus TOC provides more information than the commonly used receiver operating characteristic (ROC) and ROC's associated area under the curve (AUC).","Machine learning poses a host of ethical questions. Systems which are trained on datasets collected with biases may exhibit these biases upon use (algorithmic bias), thus digitizing cultural prejudices. For example, in 1988, the UK's Commission for Racial Equality found that St. George's Medical School had been using a computer program trained from data of previous admissions staff and this program had denied nearly 60 candidates who were found to be either women or had non-European sounding names. Using job hiring data from a firm with racist hiring policies may lead to a machine learning system duplicating the bias by scoring job applicants by similarity to previous successful applicants. Responsible collection of data and documentation of algorithmic rules used by a system thus is a critical part of machine learning.
","[' Machine learning poses a host of what?', ' What may systems trained on datasets collected with biases exhibit upon use?', "" Who found that St. George's Medical School had been using a computer?"", "" What computer program was used at St. George's Medical School?"", ' How many candidates were denied by the computer program?', ' What were the names of the candidates that were denied?', ' Who was using job hiring data from?', ' What may lead to a machine learning system duplicating the bias?', ' What is a critical part of machine learning?']","['ethical questions', 'digitizing cultural prejudices', ""UK's Commission for Racial Equality"", 'trained from data of previous admissions staff', 'nearly 60', 'women or had non-European sounding names', 'a firm with racist hiring policies', 'Using job hiring data from a firm with racist hiring policies', 'Responsible collection of data and documentation of algorithmic rules']","[0.9559535384178162, 0.3762038052082062, 0.7378281652927399, 0.2567901574075222, 0.688878744840622, 0.5877679139375687, 0.5813488662242889, 0.8192422389984131, 0.6463737338781357]"
19,machine learning,Ethics,Ethics,"Machine learning poses a host of ethical questions. Systems which are trained on datasets collected with biases may exhibit these biases upon use (algorithmic bias), thus digitizing cultural prejudices. For example, in 1988, the UK's Commission for Racial Equality found that St. George's Medical School had been using a computer program trained from data of previous admissions staff and this program had denied nearly 60 candidates who were found to be either women or had non-European sounding names. Using job hiring data from a firm with racist hiring policies may lead to a machine learning system duplicating the bias by scoring job applicants by similarity to previous successful applicants. Responsible collection of data and documentation of algorithmic rules used by a system thus is a critical part of machine learning.
","AI can be well-equipped to make decisions in technical fields, which rely heavily on data and historical information. These decisions rely on objectivity and logical reasoning. Because human languages contain biases, machines trained on language corpora will necessarily also learn these biases.","[' AI can be well-equipped to make decisions in what fields?', ' Decisions in technical fields rely heavily on what?', ' Machines trained on what corpora will automatically learn these biases?']","['technical fields', 'data and historical information', 'language']","[0.818221390247345, 0.7530719935894012, 0.6715354919433594]"
20,machine learning,Ethics,Ethics,"AI can be well-equipped to make decisions in technical fields, which rely heavily on data and historical information. These decisions rely on objectivity and logical reasoning. Because human languages contain biases, machines trained on language corpora will necessarily also learn these biases.","Other forms of ethical challenges, not related to personal biases, are seen in health care. There are concerns among health care professionals that these systems might not be designed in the public's interest but as income-generating machines. This is especially true in the United States where there is a long-standing ethical dilemma of improving health care, but also increasing profits. For example, the algorithms could be designed to provide patients with unnecessary tests or medication in which the algorithm's proprietary owners hold stakes. There is  potential for machine learning in health care to provide professionals an additional tool to diagnose, medicate, and plan recovery paths for patients, but this requires these biases to be mitigated.","[' What are other forms of ethical challenges seen in health care?', "" There are concerns among health care professionals that systems might not be designed in the public's interest but as what?"", ' Where is there a long-standing ethical dilemma of improving health care but also increasing profits?', ' What could be designed to provide patients with unnecessary tests or medication?', ' What do owners hold stakes in?', ' What is potential for machine learning in health care to provide?']","['not related to personal biases', 'income-generating machines', 'the United States', 'algorithms', 'medication', 'an additional tool to diagnose, medicate, and plan recovery paths for patients']","[0.3401649668812752, 0.9733764827251434, 0.7839846014976501, 0.8036337196826935, 0.15472186356782913, 0.5177566856145859]"
21,machine learning,Ethics,Hardware,"Other forms of ethical challenges, not related to personal biases, are seen in health care. There are concerns among health care professionals that these systems might not be designed in the public's interest but as income-generating machines. This is especially true in the United States where there is a long-standing ethical dilemma of improving health care, but also increasing profits. For example, the algorithms could be designed to provide patients with unnecessary tests or medication in which the algorithm's proprietary owners hold stakes. There is  potential for machine learning in health care to provide professionals an additional tool to diagnose, medicate, and plan recovery paths for patients, but this requires these biases to be mitigated.","Since the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks (a particular narrow subdomain of machine learning) that contain many layers of non-linear hidden units. By 2019, graphic processing units (GPUs), often with AI-specific enhancements, had displaced CPUs as the dominant method of training large-scale commercial cloud AI. OpenAI estimated the hardware compute used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017), and found a 300,000-fold increase in the amount of compute required, with a doubling-time trendline of 3.4 months.","[' In what decade did advances in machine learning algorithms and computer hardware lead to more efficient methods for training deep neural networks?', ' Deep neural networks contain many layers of what?', ' Graphic processing units (GPUs) had displaced what in AI-specific enhancements by 2019?', ' What was the dominant method of training large-scale commercial cloud AI?', ' OpenAI estimated the hardware compute used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017)?', ' How many times did the amount of compute required increase?', ' What was the doubling-time trendline of 3.4 months?']","['2010s', 'non-linear hidden units', 'CPUs', 'CPUs', '300,000-fold increase in the amount of compute required', '300,000-fold', '300,000-fold increase in the amount of compute required']","[0.9165545403957367, 0.9767566919326782, 0.9763616323471069, 0.5269246995449066, 0.070795226842165, 0.7569250166416168, 0.26015493273735046]"
22,machine learning,Hardware,Software,"Since the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks (a particular narrow subdomain of machine learning) that contain many layers of non-linear hidden units. By 2019, graphic processing units (GPUs), often with AI-specific enhancements, had displaced CPUs as the dominant method of training large-scale commercial cloud AI. OpenAI estimated the hardware compute used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017), and found a 300,000-fold increase in the amount of compute required, with a doubling-time trendline of 3.4 months.","Software suites containing a variety of machine learning algorithms include the following:
",[' What is a suite of software suites containing machine learning algorithms?'],['the following:'],[0.13880803808569908]
23,genetic algorithm,Summary,Summary,"
","In computer science and operations research, a genetic algorithm (GA) is a metaheuristic inspired by the process of natural selection that belongs to the larger class of evolutionary algorithms (EA). Genetic algorithms are commonly used to generate high-quality solutions to optimization and search problems by relying on biologically inspired operators such as mutation, crossover and selection. Some examples of GA applications include optimizing decision trees for better performance, automatically solve sudoku puzzles, hyperparameter optimization, etc.
","[' What is a genetic algorithm inspired by?', ' What is the larger class of evolutionary algorithms?', ' Genetic algorithms are commonly used to generate what?', ' What are some examples of GA applications?', ' What are three examples of biologically inspired operators?']","['the process of natural selection', 'EA', 'high-quality solutions to optimization and search problems', 'optimizing decision trees for better performance, automatically solve sudoku puzzles, hyperparameter optimization', 'mutation, crossover and selection']","[0.700000211596489, 0.8368761241436005, 0.9235862195491791, 0.7813596725463867, 0.04516628570854664]"
24,genetic algorithm,Summary,The building block hypothesis,"In computer science and operations research, a genetic algorithm (GA) is a metaheuristic inspired by the process of natural selection that belongs to the larger class of evolutionary algorithms (EA). Genetic algorithms are commonly used to generate high-quality solutions to optimization and search problems by relying on biologically inspired operators such as mutation, crossover and selection. Some examples of GA applications include optimizing decision trees for better performance, automatically solve sudoku puzzles, hyperparameter optimization, etc.
","Genetic algorithms are simple to implement, but their behavior is difficult to understand. In particular, it is difficult to understand why these algorithms frequently succeed at generating solutions of high fitness when applied to practical problems. The building block hypothesis (BBH) consists of:
","[' Genetic algorithms are simple to implement, but their behavior is what?', ' Genetic algorithms often succeed at generating solutions of high fitness when applied to what kind of problems?', ' What is the building block hypothesis?']","['difficult to understand', 'practical', 'BBH']","[0.9844296276569366, 0.8603508770465851, 0.4515674114227295]"
25,genetic algorithm,The building block hypothesis,The building block hypothesis,"Goldberg describes the heuristic as follows:
","Despite the lack of consensus regarding the validity of the building-block hypothesis, it has been consistently evaluated and used as reference throughout the years. Many estimation of distribution algorithms, for example, have been proposed in an attempt to provide an environment in which the hypothesis would hold. Although good results have been reported for some classes of problems, skepticism concerning the generality and/or practicality of the building-block hypothesis as an explanation for GAs efficiency still remains. Indeed, there is a reasonable amount of work that attempts to understand its limitations from the perspective of estimation of distribution algorithms.","[' What has been consistently evaluated and used as reference throughout the years?', ' Many estimation of distribution algorithms have been proposed in an attempt to provide an environment in which the hypothesis would hold?', ' What has been reported for some classes of problems?', ' What remains skepticism regarding the generality and/or practicality of the building block hypothesis as an explanation for GAs efficiency?', ' What does reasonable amount of work attempt to understand from the perspective of estimation of distribution algorithms?']","['building-block hypothesis', 'building-block hypothesis', 'good results', 'Although good results have been reported for some classes of problems, skepticism concerning the generality and/or practicality of the building-block hypothesis as an explanation for GAs efficiency still remains. Indeed, there is a reasonable amount of work that attempts to understand its limitations from the perspective of estimation of distribution algorithms', 'its limitations']","[0.7613719403743744, 0.12052981555461884, 0.9659111201763153, 0.24952438473701477, 0.7928684055805206]"
26,genetic algorithm,Limitations,Problem domains,"There are limitations of the use of a genetic algorithm compared to alternative optimization algorithms:
","Problems which appear to be particularly appropriate for solution by genetic algorithms include timetabling and scheduling problems, and many scheduling software packages are based on GAs. GAs have also been applied to engineering. Genetic algorithms are often applied as an approach to solve global optimization problems.
","[' What are two problems that are particularly suitable for genetic algorithms?', ' What are many scheduling software packages based on?', ' GAs have also been applied to what?', ' Genetic algorithms are often applied as an approach to solve global optimization problems?']","['timetabling and scheduling problems', 'GAs', 'engineering', 'GAs have also been applied to engineering']","[0.8707312643527985, 0.9714659452438354, 0.9928503036499023, 0.02935763355344534]"
27,genetic algorithm,Problem domains,Problem domains,"Problems which appear to be particularly appropriate for solution by genetic algorithms include timetabling and scheduling problems, and many scheduling software packages are based on GAs. GAs have also been applied to engineering. Genetic algorithms are often applied as an approach to solve global optimization problems.
","As a general rule of thumb genetic algorithms might be useful in problem domains that have a complex fitness landscape as mixing, i.e., mutation in combination with crossover, is designed to move the population away from local optima that a traditional hill climbing algorithm might get stuck in. Observe that commonly used crossover operators cannot change any uniform population. Mutation alone can provide ergodicity of the overall genetic algorithm process (seen as a Markov chain).
","[' Genetic algorithms might be useful in problem domains that have a complex what?', ' Mutation in combination with crossover is designed to move the population away from local optima that a traditional hill climbing algorithm might get stuck in?', ' What type of algorithm might get stuck in?', "" What can't change any uniform population?"", ' Mutation alone can provide what?']","['fitness landscape', 'mixing', 'hill climbing', 'commonly used crossover operators', 'ergodicity']","[0.9796129167079926, 0.08425130695104599, 0.38720375299453735, 0.7380366623401642, 0.8784908354282379]"
28,genetic algorithm,Problem domains,Problem domains,"As a general rule of thumb genetic algorithms might be useful in problem domains that have a complex fitness landscape as mixing, i.e., mutation in combination with crossover, is designed to move the population away from local optima that a traditional hill climbing algorithm might get stuck in. Observe that commonly used crossover operators cannot change any uniform population. Mutation alone can provide ergodicity of the overall genetic algorithm process (seen as a Markov chain).
","Examples of problems solved by genetic algorithms include: mirrors designed to funnel sunlight to a solar collector, antennae designed to pick up radio signals in space, walking methods for computer figures, optimal design of aerodynamic bodies in complex flowfields","[' What are some examples of problems solved by genetic algorithms?', ' What are mirrors designed to funnel sunlight to?', ' How are antennae designed to pick up radio signals in space?']","['mirrors designed to funnel sunlight to a solar collector, antennae designed to pick up radio signals in space, walking methods for computer figures', 'a solar collector', 'mirrors']","[0.6473124325275421, 0.8090282678604126, 0.2493467777967453]"
29,genetic algorithm,Problem domains,Problem domains,"Examples of problems solved by genetic algorithms include: mirrors designed to funnel sunlight to a solar collector, antennae designed to pick up radio signals in space, walking methods for computer figures, optimal design of aerodynamic bodies in complex flowfields","In his Algorithm Design Manual, Skiena advises against genetic algorithms for any task:
","[' In his Algorithm Design Manual, who advises against genetic algorithms for any task?']",['Skiena'],[0.994492918252945]
30,genetic algorithm,Problem domains,Problem domains,"In his Algorithm Design Manual, Skiena advises against genetic algorithms for any task:
","[I]t is quite unnatural to model applications in terms of genetic operators like mutation and crossover on bit strings. The pseudobiology adds another level of complexity between you and your problem. Second, genetic algorithms take a very long time on nontrivial problems. [...] [T]he analogy with evolution—where significant progress require [sic] millions of years—can be quite appropriate.
","[' What is it unnatural to model applications in terms of genetic operators?', ' What adds another level of complexity between you and your problem?', ' Genetic algorithms take a very long time on what?', ' What are nontrivial problems?', ' What is an analogy with evolution?']","['mutation and crossover on bit strings', 'The pseudobiology', 'nontrivial problems', 'genetic algorithms take a very long time', 'significant progress require [sic] millions of years']","[0.31155436486005783, 0.8231284022331238, 0.9822539687156677, 0.5361518114805222, 0.5862746089696884]"
31,genetic algorithm,Problem domains,Problem domains,"[...]
","
I have never encountered any problem where genetic algorithms seemed to me the right way to attack it. Further, I have never seen any computational results reported using genetic algorithms that have favorably impressed me. Stick to simulated annealing for your heuristic search voodoo needs.","[' I have never encountered any problem where genetic algorithms seemed to me the right way to attack it?', ' What has never seen any computational results reported using genetic algorithms that have favorably impressed me?', ' Stick to what for your heuristic search voodoo needs?']","['I have never encountered any problem where genetic algorithms seemed to me the right way to attack it.', 'I', 'simulated annealing']","[0.01622341899201274, 0.12553550116717815, 0.9623545110225677]"
32,genetic algorithm,Problem domains,History,"
I have never encountered any problem where genetic algorithms seemed to me the right way to attack it. Further, I have never seen any computational results reported using genetic algorithms that have favorably impressed me. Stick to simulated annealing for your heuristic search voodoo needs.","In 1950, Alan Turing proposed a ""learning machine"" which would parallel the principles of evolution. Computer simulation of evolution started as early as in 1954 with the work of Nils Aall Barricelli, who was using the computer at the Institute for Advanced Study in Princeton, New Jersey. His 1954 publication was not widely noticed. Starting in 1957, the Australian quantitative geneticist Alex Fraser published a series of papers on simulation of artificial selection of organisms with multiple loci controlling a measurable trait. From these beginnings, computer simulation of evolution by biologists became more common in the early 1960s, and the methods were described in books by Fraser and Burnell (1970) and Crosby (1973). Fraser's simulations included all of the essential elements of modern genetic algorithms. In addition, Hans-Joachim Bremermann published a series of papers in the 1960s that also adopted a population of solution to optimization problems, undergoing recombination, mutation, and selection. Bremermann's research also included the elements of modern genetic algorithms. Other noteworthy early pioneers include Richard Friedberg, George Friedman, and Michael Conrad. Many early papers are reprinted by Fogel (1998).","[' When did Alan Turing propose a ""learning machine""?', ' When did computer simulation of evolution start?', ' Who was using the computer at the Institute for Advanced Study?', ' Where was Alex Fraser born?', ' What year did Alex Fraser publish a series of papers on simulation of artificial selection?', ' When did computer simulations of evolution become more common?', ' Who published a book on computer simulation of evolution?', ' What did Hans-Joachim Bremermann publish?', ' Who published a series of papers in the 1960s that adopted a population of solution to optimization problems?', "" What did Hans-Joachim Bremermann's research include?"", ' Richard Friedberg and George Friedberg are notable early pioneers of what?', ' What are some of the early pioneers of genetic algorithms?', "" Who reprinted many of Fogel's papers?""]","['1950', '1954', 'Nils Aall Barricelli', 'Australian', '1957', 'early 1960s', 'Fraser and Burnell (1970) and Crosby', 'a series of papers in the 1960s that also adopted a population of solution to optimization problems', 'Hans-Joachim Bremermann', 'modern genetic algorithms', 'computer simulation of evolution', 'Richard Friedberg, George Friedman, and Michael Conrad', 'Hans-Joachim Bremermann']","[0.9748186469078064, 0.9603121280670166, 0.9861234426498413, 0.6404178440570831, 0.9799635410308838, 0.7781903743743896, 0.36043016612529755, 0.19927480071783066, 0.960317999124527, 0.6658094823360443, 0.0042025072034448385, 0.8975748419761658, 0.0002964953746413812]"
33,genetic algorithm,History,History,"In 1950, Alan Turing proposed a ""learning machine"" which would parallel the principles of evolution. Computer simulation of evolution started as early as in 1954 with the work of Nils Aall Barricelli, who was using the computer at the Institute for Advanced Study in Princeton, New Jersey. His 1954 publication was not widely noticed. Starting in 1957, the Australian quantitative geneticist Alex Fraser published a series of papers on simulation of artificial selection of organisms with multiple loci controlling a measurable trait. From these beginnings, computer simulation of evolution by biologists became more common in the early 1960s, and the methods were described in books by Fraser and Burnell (1970) and Crosby (1973). Fraser's simulations included all of the essential elements of modern genetic algorithms. In addition, Hans-Joachim Bremermann published a series of papers in the 1960s that also adopted a population of solution to optimization problems, undergoing recombination, mutation, and selection. Bremermann's research also included the elements of modern genetic algorithms. Other noteworthy early pioneers include Richard Friedberg, George Friedman, and Michael Conrad. Many early papers are reprinted by Fogel (1998).","Although Barricelli, in work he reported in 1963, had simulated the evolution of ability to play a simple game, artificial evolution only became a widely recognized optimization method as a result of the work of Ingo Rechenberg and Hans-Paul Schwefel in the 1960s and early 1970s – Rechenberg's group was able to solve complex engineering problems through evolution strategies. Another approach was the evolutionary programming technique of Lawrence J. Fogel, which was proposed for generating artificial intelligence. Evolutionary programming originally used finite state machines for predicting environments, and used variation and selection to optimize the predictive logics. Genetic algorithms in particular became popular through the work of John Holland in the early 1970s, and particularly his book Adaptation in Natural and Artificial Systems (1975). His work originated with studies of cellular automata, conducted by Holland and his students at the University of Michigan. Holland introduced a formalized framework for predicting the quality of the next generation, known as Holland's Schema Theorem. Research in GAs remained largely theoretical until the mid-1980s, when The First International Conference on Genetic Algorithms was held in Pittsburgh, Pennsylvania.
","[' In what year did Barricelli report on the evolution of ability to play a simple game?', ' What was the result of the work of Ingo Rechenberg and Hans-Paul Schwefel in the 1960s and early 1970s?', "" Rechenberg's group was able to solve complex engineering problems through what?"", ' What was the evolutionary programming technique of Lawrence J. Fogel proposed for?', ' Evolutionary programming originally used finite state machines for what purpose?', ' What did finite state machines use for predicting environments?', ' What did variation and selection do to optimize the predictive logics?', ' Who wrote Adaptation in Natural and Artificial Systems?', "" What was the name of Holland's framework for predicting the quality of the next generation?"", ' When did research in GAs remained largely theoretical?', ' Where did Holland and his students study cellular automata?', ' In what year was the First International Conference on Genetic Algorithms held?', ' What was the name of the conference held in Pittsburgh, Pennsylvania?']","['1963', 'artificial evolution only became a widely recognized optimization method', 'evolution strategies', 'generating artificial intelligence', 'predicting environments', 'Evolutionary programming', 'Evolutionary programming', 'John Holland', ""Holland's Schema Theorem"", 'until the mid-1980s', 'University of Michigan', '1980s', 'The First International Conference on Genetic Algorithms']","[0.992954283952713, 0.7325736880302429, 0.9941143691539764, 0.93418288230896, 0.9649873375892639, 0.6660535633563995, 0.4507056623697281, 0.9726984798908234, 0.969608724117279, 0.5807625651359558, 0.8909944891929626, 0.6329462379217148, 0.8056747615337372]"
34,deep learning,Summary,Summary,"Deep learning  (also known as deep structured learning) is part of a broader family of machine learning methods based on artificial neural networks with representation learning. Learning can be supervised, semi-supervised or unsupervised.","Deep-learning architectures such as deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks and convolutional neural networks have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.","[' What are some examples of deep-learning architectures?', ' Computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, material inspection, and board game programs are examples of what?', ' Analyzing, climate science, material inspection, and board game programs have produced results comparable to and in some cases surpassing what?']","['deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks and convolutional neural networks', 'Deep-learning architectures', 'human expert performance']","[0.917387068271637, 0.7959222495555878, 0.9617280066013336]"
35,deep learning,Summary,Summary,"Deep-learning architectures such as deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks and convolutional neural networks have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.","Artificial neural networks (ANNs) were inspired by information processing and distributed communication nodes in biological systems. ANNs have various differences from biological brains.  Specifically, artificial neural networks tend to be static and symbolic, while the biological brain of most living organisms is dynamic (plastic) and analogue.","[' ANNs were inspired by what?', ' What are artificial neural networks inspired by?', ' Artificial neural networks tend to be static and symbolic, while what is the biological brain of most living organisms?']","['information processing and distributed communication nodes in biological systems', 'information processing and distributed communication nodes in biological systems', 'dynamic (plastic) and analogue']","[0.7565768659114838, 0.7798624932765961, 0.667795717716217]"
36,deep learning,Summary,Summary,"Artificial neural networks (ANNs) were inspired by information processing and distributed communication nodes in biological systems. ANNs have various differences from biological brains.  Specifically, artificial neural networks tend to be static and symbolic, while the biological brain of most living organisms is dynamic (plastic) and analogue.","The adjective ""deep"" in deep learning refers to the use of multiple layers in the network. Early work showed that a linear perceptron cannot be a universal classifier, but that a network with a nonpolynomial activation function with one hidden layer of unbounded width can. Deep learning is a modern variation which is concerned with an unbounded number of layers of bounded size, which permits practical application and optimized implementation, while retaining theoretical universality under mild conditions. In deep learning the layers are also permitted to be heterogeneous and to deviate widely from biologically informed connectionist models, for the sake of efficiency, trainability and understandability, whence the ""structured"" part.
","[' What does the adjective ""deep"" in deep learning refer to?', ' Early work showed that a linear perceptron cannot be a universal classifier, but a network with a nonpolynomial activation function with one hidden layer of unbounded width can be what?', ' What is a modern variation of deep learning concerned with an unbounded number of layers of bounded size?', ' What permits practical application and optimized implementation while retaining theoretical universality under mild conditions?', ' Why are layers allowed to be heterogeneous and deviate widely from connectionist models?', ' What is the ""structured"" part?']","['the use of multiple layers in the network', 'can', 'Deep learning', 'Deep learning is a modern variation which is concerned with an unbounded number of layers of bounded size', 'for the sake of efficiency, trainability and understandability', 'efficiency, trainability and understandability']","[0.76544588804245, 0.3848638981580734, 0.9168830811977386, 0.6139897704124451, 0.5956766456365585, 0.38602033257484436]"
37,deep learning,Summary,Definition,"The adjective ""deep"" in deep learning refers to the use of multiple layers in the network. Early work showed that a linear perceptron cannot be a universal classifier, but that a network with a nonpolynomial activation function with one hidden layer of unbounded width can. Deep learning is a modern variation which is concerned with an unbounded number of layers of bounded size, which permits practical application and optimized implementation, while retaining theoretical universality under mild conditions. In deep learning the layers are also permitted to be heterogeneous and to deviate widely from biologically informed connectionist models, for the sake of efficiency, trainability and understandability, whence the ""structured"" part.
","Deep learning is a class of machine learning algorithms that: 199–200  uses multiple layers to progressively extract higher-level features from the raw input. For example, in image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits or letters or faces.
","[' What class of machine learning algorithms uses multiple layers to extract higher-level features from raw input?', ' In image processing, what may lower layers identify?', ' What may higher layers identify the concepts relevant to a human?']","['Deep learning', 'edges', 'digits or letters or faces']","[0.9888663589954376, 0.9591290950775146, 0.07189087383449078]"
38,deep learning,Definition,Overview,"Deep learning is a class of machine learning algorithms that: 199–200  uses multiple layers to progressively extract higher-level features from the raw input. For example, in image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits or letters or faces.
","Most modern deep learning models are based on artificial neural networks, specifically convolutional neural networks (CNN)s, although they can also include propositional formulas or latent variables organized layer-wise in deep generative models such as the nodes in deep belief networks and deep Boltzmann machines.","[' What are the most modern deep learning models based on?', ' What are convolutional neural networks?']","['artificial neural networks', 'CNN)']","[0.9300933480262756, 0.6120887398719788]"
39,deep learning,Overview,Overview,"Most modern deep learning models are based on artificial neural networks, specifically convolutional neural networks (CNN)s, although they can also include propositional formulas or latent variables organized layer-wise in deep generative models such as the nodes in deep belief networks and deep Boltzmann machines.","In deep learning, each level learns to transform its input data into a slightly more abstract and composite representation. In an image recognition application, the raw input may be a matrix of pixels; the first representational layer may abstract the pixels and encode edges; the second layer may compose and encode arrangements of edges; the third layer may encode a nose and eyes; and the fourth layer may recognize that the image contains a face. Importantly, a deep learning process can learn which features to optimally place in which level on its own. This does not eliminate the need for hand-tuning; for example, varying numbers of layers and layer sizes can provide different degrees of abstraction.","[' In deep learning, each level learns to transform its input data into what?', ' In an image recognition application, the raw input may be a matrix of pixels?', ' The first representational layer may abstract the pixels and encode edges.', ' The second layer may compose and what else?', ' What can a deep learning process learn?', ' What may the second layer encode?', ' The third layer may encode what?', ' What can learn which features to optimally place in a level on its own?', ' What does not eliminate the need for hand-tuning?']","['a slightly more abstract and composite representation', 'deep learning', 'image recognition application', 'encode arrangements of edges', 'which features to optimally place in which level on its own', 'arrangements of edges', 'a nose and eyes', 'a deep learning process', 'a deep learning process can learn which features to optimally place in which level on its own']","[0.8094223737716675, 0.05395397171378136, 0.007706556702032685, 0.901647537946701, 0.7672940492630005, 0.9180589914321899, 0.8980529010295868, 0.6979733556509018, 0.512240469455719]"
40,deep learning,Overview,Overview,"In deep learning, each level learns to transform its input data into a slightly more abstract and composite representation. In an image recognition application, the raw input may be a matrix of pixels; the first representational layer may abstract the pixels and encode edges; the second layer may compose and encode arrangements of edges; the third layer may encode a nose and eyes; and the fourth layer may recognize that the image contains a face. Importantly, a deep learning process can learn which features to optimally place in which level on its own. This does not eliminate the need for hand-tuning; for example, varying numbers of layers and layer sizes can provide different degrees of abstraction.","The word ""deep"" in ""deep learning"" refers to the number of layers through which the data is transformed. More precisely, deep learning systems have a substantial credit assignment path (CAP) depth. The CAP is the chain of transformations from input to output. CAPs describe potentially causal connections between input and output. For a feedforward neural network, the depth of the CAPs is that of the network and is the number of hidden layers plus one (as the output layer is also parameterized). For recurrent neural networks, in which a signal may propagate through a layer more than once, the CAP depth is potentially unlimited. No universally agreed-upon threshold of depth divides shallow learning from deep learning, but most researchers agree that deep learning involves CAP depth higher than 2. CAP of depth 2 has been shown to be a universal approximator in the sense that it can emulate any function. Beyond that, more layers do not add to the function approximator ability of the network. Deep models (CAP > 2) are able to extract better features than shallow models and hence, extra layers help in learning the features effectively.
","[' What does the word ""deep"" in deep learning refer to?', ' Deep learning systems have what?', ' What is the chain of transformations from input to output called?', ' What describe potentially causal connections between input and output?', ' What describes the depth of the CAPs?', ' For a feedforward neural network, the depth is that of the network and the number of hidden layers plus one?', ' What is the CAP depth for recurrent neural networks?', ' What does no universal agreed-upon threshold of depth divide shallow learning from deep learning?', ' Most researchers agree that deep learning involves what depth higher than 2?', ' Deep learning involves CAP depth higher than what?', ' CAP of depth 2 has been shown to be a universal approximator in the sense that it can emulate any function in what sense?', ' Deep models (CAP > 2) do not add to what ability of the network?', ' What is the approximator ability of the network?', ' Deep models (CAP > 2) are able to extract better features than what?']","['the number of layers through which the data is transformed', 'a substantial credit assignment path (CAP) depth', 'CAP', 'CAPs', 'the number of hidden layers plus one', 'depth of the CAPs', 'unlimited', 'CAP depth higher than 2', 'CAP', '2', 'CAP depth higher than 2. CAP of depth 2 has been shown to be a universal approximator in the sense that it can emulate any function. Beyond that, more layers do not add to the function approximator ability of the network', 'function approximator ability', 'function', 'shallow models']","[0.8013119399547577, 0.6856270134449005, 0.709704577922821, 0.9805121421813965, 0.5188833177089691, 0.16111478954553604, 0.7003763616085052, 0.046516191214323044, 0.8306930065155029, 0.9560598731040955, 0.11625947430729866, 0.018502330407500267, 0.013177889864891768, 0.9868334829807281]"
41,deep learning,Overview,Overview,"The word ""deep"" in ""deep learning"" refers to the number of layers through which the data is transformed. More precisely, deep learning systems have a substantial credit assignment path (CAP) depth. The CAP is the chain of transformations from input to output. CAPs describe potentially causal connections between input and output. For a feedforward neural network, the depth of the CAPs is that of the network and is the number of hidden layers plus one (as the output layer is also parameterized). For recurrent neural networks, in which a signal may propagate through a layer more than once, the CAP depth is potentially unlimited. No universally agreed-upon threshold of depth divides shallow learning from deep learning, but most researchers agree that deep learning involves CAP depth higher than 2. CAP of depth 2 has been shown to be a universal approximator in the sense that it can emulate any function. Beyond that, more layers do not add to the function approximator ability of the network. Deep models (CAP > 2) are able to extract better features than shallow models and hence, extra layers help in learning the features effectively.
",Deep learning architectures can be constructed with a greedy layer-by-layer method. Deep learning helps to disentangle these abstractions and pick out which features improve performance.,"[' What can be constructed with a greedy layer-by-layer method?', ' Deep learning helps to disentangle these abstractions and pick which features improve performance?']","['Deep learning architectures', 'Deep learning architectures']","[0.9898800849914551, 0.30175866186618805]"
42,deep learning,Overview,Overview,Deep learning architectures can be constructed with a greedy layer-by-layer method. Deep learning helps to disentangle these abstractions and pick out which features improve performance.,"For supervised learning tasks, deep learning methods eliminate feature engineering, by translating the data into compact intermediate representations akin to principal components, and derive layered structures that remove redundancy in representation.
","[' Deep learning methods eliminate feature engineering by translating data into what?', ' Deep Learning methods derive what to remove redundancy in representation?']","['compact intermediate representations', 'layered structures']","[0.9316510260105133, 0.994432270526886]"
43,deep learning,Overview,Overview,"For supervised learning tasks, deep learning methods eliminate feature engineering, by translating the data into compact intermediate representations akin to principal components, and derive layered structures that remove redundancy in representation.
",Deep learning algorithms can be applied to unsupervised learning tasks. This is an important benefit because unlabeled data are more abundant than the labeled data. Examples of deep structures that can be trained in an unsupervised manner are neural history compressors and deep belief networks.,"[' Deep learning algorithms can be applied to what kind of learning tasks?', ' Unlabeled data are more abundant than what type of data?', ' Deep structures that can be trained in an unsupervised manner are what?']","['unsupervised', 'labeled', 'neural history compressors and deep belief networks']","[0.8985009789466858, 0.5272742658853531, 0.8836279213428497]"
44,deep learning,Overview,Interpretations,Deep learning algorithms can be applied to unsupervised learning tasks. This is an important benefit because unlabeled data are more abundant than the labeled data. Examples of deep structures that can be trained in an unsupervised manner are neural history compressors and deep belief networks.,Deep neural networks are generally interpreted in terms of the universal approximation theorem or probabilistic inference.,"[' What are deep neural networks generally interpreted in terms of?', ' What is the universal approximation theorem?']","['the universal approximation theorem or probabilistic inference', 'probabilistic inference']","[0.7719456851482391, 0.5677830278873444]"
45,deep learning,Interpretations,Interpretations,Deep neural networks are generally interpreted in terms of the universal approximation theorem or probabilistic inference.,"The classic universal approximation theorem concerns the capacity of feedforward neural networks with a single hidden layer of finite size to approximate continuous functions. In 1989, the first proof was published by George Cybenko for sigmoid activation functions and was generalised to feed-forward multi-layer architectures in 1991 by Kurt Hornik. Recent work also showed that universal approximation also holds for non-bounded activation functions such as the rectified linear unit.","[' What is the classic universal approximation theorem concerned with?', ' Who published the first proof for sigmoid activation functions in 1989?', ' What was generalised to feed forward multi-layer architectures in 1991 by Kurt Hornik?', ' In what year was universal approximation generalised to feed-forward multi-layer architectures?', ' What did Kurt Hornik generalise in 1991?']","['the capacity of feedforward neural networks with a single hidden layer of finite size to approximate continuous functions', 'George Cybenko', 'the first proof was published by George Cybenko for sigmoid activation functions', '1991', 'feed-forward multi-layer architectures']","[0.48980817198753357, 0.9967271983623505, 0.31708499044179916, 0.934106320142746, 0.8700418472290039]"
46,deep learning,Interpretations,Interpretations,"The classic universal approximation theorem concerns the capacity of feedforward neural networks with a single hidden layer of finite size to approximate continuous functions. In 1989, the first proof was published by George Cybenko for sigmoid activation functions and was generalised to feed-forward multi-layer architectures in 1991 by Kurt Hornik. Recent work also showed that universal approximation also holds for non-bounded activation functions such as the rectified linear unit.","The universal approximation theorem for deep neural networks concerns the capacity of networks with bounded width but the depth is allowed to grow. Lu et al. proved that if the width of a deep neural network with ReLU activation is strictly larger than the input dimension, then the network can approximate any Lebesgue integrable function; If the width is smaller or equal to the input dimension, then a deep neural network is not a universal approximator.
","[' What is the universal approximation theorem for deep neural networks concerned with?', ' What is allowed to grow in networks with bounded width?', ' Lu et al. proved that if the width of a deep neural network with ReLU activation is strictly larger than the input dimension, then the network can what?', ' If the width is smaller or equal to the input dimension, then a deep neural network is not a universal approximator.', ' If the network is strictly larger than what, then it can approximate any Lebesgue integrable function?']","['the capacity of networks with bounded width but the depth is allowed to grow', 'the depth', 'approximate any Lebesgue integrable function', 'Lu', 'input dimension']","[0.6436867415904999, 0.6474602967500687, 0.88631272315979, 0.07757654041051865, 0.6871012449264526]"
47,deep learning,Interpretations,Interpretations,"The universal approximation theorem for deep neural networks concerns the capacity of networks with bounded width but the depth is allowed to grow. Lu et al. proved that if the width of a deep neural network with ReLU activation is strictly larger than the input dimension, then the network can approximate any Lebesgue integrable function; If the width is smaller or equal to the input dimension, then a deep neural network is not a universal approximator.
","The probabilistic interpretation derives from the field of machine learning. It features inference, as well as the optimization concepts of training and testing, related to fitting and generalization, respectively. More specifically, the probabilistic interpretation considers the activation nonlinearity as a cumulative distribution function. The probabilistic interpretation led to the introduction of dropout as regularizer in neural networks. The probabilistic interpretation was introduced by researchers including Hopfield, Widrow and Narendra and popularized in surveys such as the one by Bishop.","[' What field does the probabilistic interpretation originate from?', ' What are the optimization concepts of training and testing related to?', ' The activation nonlinearity is considered as what?', ' What led to the introduction of dropout as regularizer in neural networks?', ' Who introduced the probabilistic interpretation?']","['machine learning', 'fitting and generalization', 'a cumulative distribution function', 'probabilistic interpretation', 'Hopfield, Widrow and Narendra']","[0.9594931304454803, 0.957921028137207, 0.7297438383102417, 0.5949399769306183, 0.9235400557518005]"
48,deep learning,Interpretations,History,"The probabilistic interpretation derives from the field of machine learning. It features inference, as well as the optimization concepts of training and testing, related to fitting and generalization, respectively. More specifically, the probabilistic interpretation considers the activation nonlinearity as a cumulative distribution function. The probabilistic interpretation led to the introduction of dropout as regularizer in neural networks. The probabilistic interpretation was introduced by researchers including Hopfield, Widrow and Narendra and popularized in surveys such as the one by Bishop.","Some sources point out that Frank Rosenblatt developed and explored all of the basic ingredients of the deep learning systems of today. He described it in his book ""Principles of Neurodynamics: Perceptrons and the Theory of Brain Mechanisms"", published by Cornell Aeronautical Laboratory, Inc., Cornell University in 1962.
","[' Who wrote ""Principles of Neurodynamics: Perceptrons and the Theory of Brain Mechanisms""?', ' In what year did Frank Rosenblatt publish his book?']","['Frank Rosenblatt', '1962']","[0.9945965111255646, 0.9897695183753967]"
49,deep learning,History,History,"Some sources point out that Frank Rosenblatt developed and explored all of the basic ingredients of the deep learning systems of today. He described it in his book ""Principles of Neurodynamics: Perceptrons and the Theory of Brain Mechanisms"", published by Cornell Aeronautical Laboratory, Inc., Cornell University in 1962.
","The first general, working learning algorithm for supervised, deep, feedforward, multilayer perceptrons was published by Alexey Ivakhnenko and Lapa in 1967. A 1971 paper described a deep network with eight layers trained by the group method of data handling. Other deep learning working architectures, specifically those built for computer vision, began with the Neocognitron introduced by Kunihiko Fukushima in 1980.","[' In what year was the first working learning algorithm published?', ' What was the name of the first general learning algorithm?', ' How many layers were in the deep network described in a 1971 paper?', ' Who introduced the Neocognitron in 1980?', ' What was the first deep learning working architecture?']","['1967', 'Alexey Ivakhnenko and Lapa', 'eight', 'Kunihiko Fukushima', 'Neocognitron']","[0.9924094080924988, 0.3370015323162079, 0.8506055772304535, 0.9930050671100616, 0.48058120906352997]"
50,deep learning,History,History,"The first general, working learning algorithm for supervised, deep, feedforward, multilayer perceptrons was published by Alexey Ivakhnenko and Lapa in 1967. A 1971 paper described a deep network with eight layers trained by the group method of data handling. Other deep learning working architectures, specifically those built for computer vision, began with the Neocognitron introduced by Kunihiko Fukushima in 1980.","The term Deep Learning was introduced to the machine learning community by Rina Dechter in 1986, and to artificial neural networks by Igor Aizenberg and colleagues in 2000, in the context of Boolean threshold neurons.","[' What term was introduced to the machine learning community by Rina Dechter in 1986?', ' In what year was the term Deep Learning introduced to artificial neural networks by Igor Aizenberg and colleagues?']","['Deep Learning', '2000']","[0.9924200177192688, 0.9826118648052216]"
51,deep learning,History,History,"The term Deep Learning was introduced to the machine learning community by Rina Dechter in 1986, and to artificial neural networks by Igor Aizenberg and colleagues in 2000, in the context of Boolean threshold neurons.","In 1989, Yann LeCun et al. applied the standard backpropagation algorithm, which had been around as the reverse mode of automatic differentiation since 1970, to a deep neural network with the purpose of recognizing handwritten ZIP codes on mail. While the algorithm worked, training required 3 days.","[' When did Yann LeCun apply the standard backpropagation algorithm to a deep neural network?', ' What was the purpose of the algorithm?', ' How long did training the algorithm take?']","['1989', 'recognizing handwritten ZIP codes on mail', '3 days']","[0.976088285446167, 0.8488529324531555, 0.9269328713417053]"
52,deep learning,History,History,"In 1989, Yann LeCun et al. applied the standard backpropagation algorithm, which had been around as the reverse mode of automatic differentiation since 1970, to a deep neural network with the purpose of recognizing handwritten ZIP codes on mail. While the algorithm worked, training required 3 days.","In 1994, André de Carvalho, together with Mike Fairhurst and David Bisset, published experimental results of a multi-layer boolean neural network, also known as a weightless neural network, composed of a 3-layers self-organising feature extraction neural network module (SOFT) followed by a multi-layer classification neural network module (GSN), which were independently trained. Each layer in the feature extraction module extracted features with growing complexity regarding the previous layer.","[' André de Carvalho, Mike Fairhurst and David Bisset published experimental results of what in 1994?', ' What is another name for a multi-layer boolean neural network?', ' How many layers does SOFT consist of?', ' What is a GSN?', ' What did each layer in the feature extraction module extract features with?']","['a multi-layer boolean neural network', 'weightless neural network', '3', 'multi-layer classification neural network module', 'growing complexity']","[0.7067319750785828, 0.8183109164237976, 0.7925124168395996, 0.750535637140274, 0.7367326617240906]"
53,deep learning,History,History,"In 1994, André de Carvalho, together with Mike Fairhurst and David Bisset, published experimental results of a multi-layer boolean neural network, also known as a weightless neural network, composed of a 3-layers self-organising feature extraction neural network module (SOFT) followed by a multi-layer classification neural network module (GSN), which were independently trained. Each layer in the feature extraction module extracted features with growing complexity regarding the previous layer.","In 1995, Brendan Frey demonstrated that it was possible to train (over two days) a network containing six fully connected layers and several hundred hidden units using the wake-sleep algorithm, co-developed with Peter Dayan and Hinton. Many factors contribute to the slow speed, including the vanishing gradient problem analyzed in 1991 by Sepp Hochreiter.","[' In what year did Brendan Frey demonstrate that it was possible to train a network containing six fully connected layers and several hundred hidden units using the wake-sleep algorithm?', ' Along with Peter Dayan and Hinton, what co-developer of the wake - sleep algorithm worked with Frey?', ' What problem contributes to the slow speed?', ' What problem was analyzed in 1991 by Sepp Hochreiter?']","['1995', 'Brendan Frey', 'vanishing gradient problem', 'vanishing gradient']","[0.9694570899009705, 0.9539053738117218, 0.7622645497322083, 0.6606166064739227]"
54,deep learning,History,History,"In 1995, Brendan Frey demonstrated that it was possible to train (over two days) a network containing six fully connected layers and several hundred hidden units using the wake-sleep algorithm, co-developed with Peter Dayan and Hinton. Many factors contribute to the slow speed, including the vanishing gradient problem analyzed in 1991 by Sepp Hochreiter.","Since 1997, Sven Behnke extended the feed-forward hierarchical convolutional approach in the Neural Abstraction Pyramid by lateral and backward connections in order to flexibly incorporate context into decisions and iteratively resolve local ambiguities.
",[' In what year did Sven Behnke extend the feed-forward hierarchical convolutional approach in the Neural Abstraction Pyramid?'],['1997'],[0.9885925352573395]
55,deep learning,History,History,"Since 1997, Sven Behnke extended the feed-forward hierarchical convolutional approach in the Neural Abstraction Pyramid by lateral and backward connections in order to flexibly incorporate context into decisions and iteratively resolve local ambiguities.
","Simpler models that use task-specific handcrafted features such as Gabor filters and support vector machines (SVMs) were a popular choice in the 1990s and 2000s, because of artificial neural network's (ANN) computational cost and a lack of understanding of how the brain wires its biological networks.
","["" What was a popular choice in the 1990's and 2000's?"", ' Why were simpler models popular?', ' What did ANN stand for?']","['Simpler models that use task-specific handcrafted features such as Gabor filters and support vector machines (SVMs)', ""artificial neural network's (ANN) computational cost and a lack of understanding of how the brain wires its biological networks"", 'artificial neural network']","[0.6460858583450317, 0.6359420120716095, 0.9734021127223969]"
56,deep learning,History,History,"Simpler models that use task-specific handcrafted features such as Gabor filters and support vector machines (SVMs) were a popular choice in the 1990s and 2000s, because of artificial neural network's (ANN) computational cost and a lack of understanding of how the brain wires its biological networks.
","Both shallow and deep learning (e.g., recurrent nets) of ANNs have been explored for many years. These methods never outperformed non-uniform internal-handcrafting Gaussian mixture model/Hidden Markov model (GMM-HMM) technology based on generative models of speech trained discriminatively. Key difficulties have been analyzed, including gradient diminishing and weak temporal correlation structure in neural predictive models. Additional difficulties were the lack of training data and limited computing power.
","[' How long have shallow and deep learning of ANNs been explored?', ' What did the methods never outperform non-uniform internal-handcrafting Gaussian mixture model/Hidden Markov model technology based on?', ' Key difficulties have been analyzed, including what?', ' What was one of the difficulties in analyzing neural predictive models?', ' What did the lack of training data cause?']","['many years', 'generative models of speech trained discriminatively', 'gradient diminishing and weak temporal correlation structure in neural predictive models', 'gradient diminishing and weak temporal correlation structure', 'limited computing power']","[0.888142317533493, 0.8905435800552368, 0.7599267661571503, 0.6423572599887848, 0.6306523978710175]"
57,deep learning,History,History,"Both shallow and deep learning (e.g., recurrent nets) of ANNs have been explored for many years. These methods never outperformed non-uniform internal-handcrafting Gaussian mixture model/Hidden Markov model (GMM-HMM) technology based on generative models of speech trained discriminatively. Key difficulties have been analyzed, including gradient diminishing and weak temporal correlation structure in neural predictive models. Additional difficulties were the lack of training data and limited computing power.
","Most speech recognition researchers moved away from neural nets to pursue generative modeling. An exception was at SRI International in the late 1990s. Funded by the US government's NSA and DARPA, SRI studied deep neural networks in speech and speaker recognition. The speaker recognition team led by Larry Heck reported significant success with deep neural networks in speech processing in the 1998 National Institute of Standards and Technology Speaker Recognition evaluation. The SRI deep neural network was then deployed in the Nuance Verifier, representing the first major industrial application of deep learning.","[' What did most speech recognition researchers move away from to pursue?', ' What did SRI International study?', ' Who led the speaker recognition team?', ' What did Larry Heck report success with in 1998?', ' The SRI deep neural network was deployed in what?', ' What is the name of the first industrial application of deep learning?']","['generative modeling', 'deep neural networks in speech and speaker recognition', 'Larry Heck', 'deep neural networks in speech processing', 'Nuance Verifier', 'Nuance Verifier']","[0.48180554807186127, 0.7890869677066803, 0.9972816705703735, 0.5274158418178558, 0.8354619145393372, 0.9234102070331573]"
58,deep learning,History,History,"Most speech recognition researchers moved away from neural nets to pursue generative modeling. An exception was at SRI International in the late 1990s. Funded by the US government's NSA and DARPA, SRI studied deep neural networks in speech and speaker recognition. The speaker recognition team led by Larry Heck reported significant success with deep neural networks in speech processing in the 1998 National Institute of Standards and Technology Speaker Recognition evaluation. The SRI deep neural network was then deployed in the Nuance Verifier, representing the first major industrial application of deep learning.","The principle of elevating ""raw"" features over hand-crafted optimization was first explored successfully in the architecture of deep autoencoder on the ""raw"" spectrogram or linear filter-bank features in the late 1990s, showing its superiority over the Mel-Cepstral features that contain stages of fixed transformation from spectrograms. The raw features of speech, waveforms, later produced excellent larger-scale results.","[' In what decade was the principle of elevating ""raw"" features over hand-crafted optimization first explored?', ' What features contain stages of fixed transformation from spectrograms?', ' In what year did deep autoencoder demonstrate its superiority over Mel-Cepstral features?', ' What are the stages of fixed transformation from spectrograms?', ' The raw features of speech, waveforms, later produced what?']","['1990s', 'Mel-Cepstral', '1990s', 'Mel-Cepstral features', 'excellent larger-scale results']","[0.7985826432704926, 0.7990215718746185, 0.7344167828559875, 0.842666894197464, 0.809035986661911]"
59,deep learning,History,History,"The principle of elevating ""raw"" features over hand-crafted optimization was first explored successfully in the architecture of deep autoencoder on the ""raw"" spectrogram or linear filter-bank features in the late 1990s, showing its superiority over the Mel-Cepstral features that contain stages of fixed transformation from spectrograms. The raw features of speech, waveforms, later produced excellent larger-scale results.","Many aspects of speech recognition were taken over by a deep learning method called long short-term memory (LSTM), a recurrent neural network published by Hochreiter and Schmidhuber in 1997. LSTM RNNs avoid the vanishing gradient problem and can learn ""Very Deep Learning"" tasks that require memories of events that happened thousands of discrete time steps before, which is important for speech. In 2003, LSTM started to become competitive with traditional speech recognizers on certain tasks. Later it was combined with connectionist temporal classification (CTC) in stacks of LSTM RNNs. In 2015, Google's speech recognition reportedly experienced a dramatic performance jump of 49% through CTC-trained LSTM, which they made available through Google Voice Search.","[' What is long short-term memory?', ' When was LSTM published?', ' What is a recurrent neural network called?', ' What tasks require memories of events that happened thousands of discrete time steps before?', ' When did LSTM start to become competitive with traditional speech recognizers?', ' What was combined with connectionist temporal classification?', ' What is connectionist temporal classification?', "" What was the performance jump of Google's speech recognition in 2015?"", ' How much performance jump did Google experience through CTC-trained LSTM?']","['a recurrent neural network', '1997', 'long short-term memory', 'Very Deep Learning', '2003', 'LSTM', 'CTC', '49%', '49%']","[0.42325183749198914, 0.9831070899963379, 0.4362461119890213, 0.6532316952943802, 0.9785553216934204, 0.7422688901424408, 0.835094153881073, 0.9839767515659332, 0.7350649833679199]"
60,deep learning,History,History,"Many aspects of speech recognition were taken over by a deep learning method called long short-term memory (LSTM), a recurrent neural network published by Hochreiter and Schmidhuber in 1997. LSTM RNNs avoid the vanishing gradient problem and can learn ""Very Deep Learning"" tasks that require memories of events that happened thousands of discrete time steps before, which is important for speech. In 2003, LSTM started to become competitive with traditional speech recognizers on certain tasks. Later it was combined with connectionist temporal classification (CTC) in stacks of LSTM RNNs. In 2015, Google's speech recognition reportedly experienced a dramatic performance jump of 49% through CTC-trained LSTM, which they made available through Google Voice Search.","In 2006, publications by Geoff Hinton, Ruslan Salakhutdinov, Osindero and Teh showed how a many-layered feedforward neural network could be effectively pre-trained one layer at a time, treating each layer in turn as an unsupervised restricted Boltzmann machine, then fine-tuning it using supervised backpropagation. The papers referred to learning for deep belief nets.
","[' In what year did Geoff Hinton, Ruslan Salakhutdinov, Osindero and Teh publish their papers?', ' How was a many-layered feedforward neural network effectively pre-trained?', ' What did the papers refer to?', ' How did the papers refer to learning for deep belief nets?']","['2006', 'one layer at a time', 'learning for deep belief nets', 'supervised backpropagation']","[0.9777357578277588, 0.5056431442499161, 0.9580219686031342, 0.42996425181627274]"
61,deep learning,History,History,"In 2006, publications by Geoff Hinton, Ruslan Salakhutdinov, Osindero and Teh showed how a many-layered feedforward neural network could be effectively pre-trained one layer at a time, treating each layer in turn as an unsupervised restricted Boltzmann machine, then fine-tuning it using supervised backpropagation. The papers referred to learning for deep belief nets.
","Deep learning is part of state-of-the-art systems in various disciplines, particularly computer vision and automatic speech recognition (ASR). Results on commonly used evaluation sets such as TIMIT (ASR) and MNIST (image classification), as well as a range of large-vocabulary speech recognition tasks have steadily improved. Convolutional neural networks (CNNs) were superseded for ASR by CTC for LSTM. but are more successful in computer vision.
","[' What type of learning is part of state-of-the-art systems in various disciplines?', ' What are two examples of commonly used evaluation sets?', ' How have results on TIMIT and MNIST improved?', ' What has steadily improved?', ' What was superseded for ASR by CTC for LSTM?']","['Deep learning', 'TIMIT (ASR) and MNIST (image classification),', 'steadily improved', 'Results on commonly used evaluation sets such as TIMIT (ASR) and MNIST (image classification), as well as a range of large-vocabulary speech recognition tasks', 'Convolutional neural networks (CNNs)']","[0.8548823297023773, 0.7012297064065933, 0.6106613576412201, 0.6288845986127853, 0.6285084038972855]"
62,deep learning,History,History,"Deep learning is part of state-of-the-art systems in various disciplines, particularly computer vision and automatic speech recognition (ASR). Results on commonly used evaluation sets such as TIMIT (ASR) and MNIST (image classification), as well as a range of large-vocabulary speech recognition tasks have steadily improved. Convolutional neural networks (CNNs) were superseded for ASR by CTC for LSTM. but are more successful in computer vision.
","The impact of deep learning in industry began in the early 2000s, when CNNs already processed an estimated 10% to 20% of all the checks written in the US, according to Yann LeCun. Industrial applications of deep learning to large-scale speech recognition started around 2010.
","[' When did the impact of deep learning in industry begin?', ' How much of the checks written in the US were processed by CNNs?', ' What was the estimated percentage of checks that CNNs processed?', ' When did industrial applications for deep learning start?']","['early 2000s', '10% to 20%', '10% to 20%', '2010']","[0.7540768980979919, 0.5869438946247101, 0.7377613484859467, 0.7078802585601807]"
63,deep learning,History,History,"The impact of deep learning in industry began in the early 2000s, when CNNs already processed an estimated 10% to 20% of all the checks written in the US, according to Yann LeCun. Industrial applications of deep learning to large-scale speech recognition started around 2010.
","The 2009 NIPS Workshop on Deep Learning for Speech Recognition was motivated by the limitations of deep generative models of speech, and the possibility that given more capable hardware and large-scale data sets that deep neural nets (DNN) might become practical. It was believed that pre-training DNNs using generative models of deep belief nets (DBN) would overcome the main difficulties of neural nets. However, it was discovered that replacing pre-training with large amounts of training data for straightforward backpropagation when using DNNs with large, context-dependent output layers produced error rates dramatically lower than then-state-of-the-art Gaussian mixture model (GMM)/Hidden Markov Model (HMM) and also than more-advanced generative model-based systems. The nature of the recognition errors produced by the two types of systems was characteristically different, offering technical insights into how to integrate deep learning into the existing highly efficient, run-time speech decoding system deployed by all major speech recognition systems. Analysis around 2009–2010, contrasting the GMM (and other generative speech models) vs. DNN models, stimulated early industrial investment in deep learning for speech recognition, eventually leading to pervasive and dominant use in that industry. That analysis was done with comparable performance (less than 1.5% in error rate) between discriminative DNNs and generative models.","[' What was the motivation for the 2009 NIPS Workshop on Deep Learning for Speech Recognition?', ' What was motivated by the limitations of deep generative models of speech and the possibility that more capable hardware and data sets might become practical?', ' What was believed to overcome the main difficulties of neural nets?', ' What was found to produce error rates when using DNNs with large, context-dependent output layers?', ' DNNs with large, context-dependent output layers produced error rates dramatically lower than what?', ' GMM/HMM are what type of model-based systems?', ' What was characteristically different between GMM and HMM?', ' The nature of the recognition errors produced by the two types of systems was what kind of insight?', ' What was characteristically different about deep learning?', ' What did analysis around 2009-2010 stimulate?', ' What type of models stimulated early industrial investment in deep learning for speech recognition?', ' What was the error rate between discriminative DNNs and generative models?']","['the limitations of deep generative models of speech', 'The 2009 NIPS Workshop on Deep Learning for Speech Recognition', 'pre-training DNNs using generative models of deep belief nets (DBN)', 'replacing pre-training with large amounts of training data for straightforward backpropagation', 'then-state-of-the-art Gaussian mixture model (GMM)/Hidden Markov Model (HMM)', 'generative', 'The nature of the recognition errors', 'technical', 'The nature of the recognition errors', 'early industrial investment in deep learning for speech recognition', 'generative speech models) vs. DNN models', 'less than 1.5%']","[0.6292077302932739, 0.6451429426670074, 0.6477378755807877, 0.7041566669940948, 0.47364698350429535, 0.5563042759895325, 0.5549067854881287, 0.5524966418743134, 0.48387011885643005, 0.6656680703163147, 0.31712332367897034, 0.6889908015727997]"
64,deep learning,History,History,"The 2009 NIPS Workshop on Deep Learning for Speech Recognition was motivated by the limitations of deep generative models of speech, and the possibility that given more capable hardware and large-scale data sets that deep neural nets (DNN) might become practical. It was believed that pre-training DNNs using generative models of deep belief nets (DBN) would overcome the main difficulties of neural nets. However, it was discovered that replacing pre-training with large amounts of training data for straightforward backpropagation when using DNNs with large, context-dependent output layers produced error rates dramatically lower than then-state-of-the-art Gaussian mixture model (GMM)/Hidden Markov Model (HMM) and also than more-advanced generative model-based systems. The nature of the recognition errors produced by the two types of systems was characteristically different, offering technical insights into how to integrate deep learning into the existing highly efficient, run-time speech decoding system deployed by all major speech recognition systems. Analysis around 2009–2010, contrasting the GMM (and other generative speech models) vs. DNN models, stimulated early industrial investment in deep learning for speech recognition, eventually leading to pervasive and dominant use in that industry. That analysis was done with comparable performance (less than 1.5% in error rate) between discriminative DNNs and generative models.","In 2010, researchers extended deep learning from TIMIT to large vocabulary speech recognition, by adopting large output layers of the DNN based on context-dependent HMM states constructed by decision trees.","[' When did researchers extend deep learning from TIMIT to large vocabulary speech recognition?', ' Researchers adopted large output layers of the DNN based on what?']","['2010', 'context-dependent HMM states']","[0.9776420593261719, 0.6987705528736115]"
65,deep learning,History,History,"In 2010, researchers extended deep learning from TIMIT to large vocabulary speech recognition, by adopting large output layers of the DNN based on context-dependent HMM states constructed by decision trees.","Advances in hardware have driven renewed interest in deep learning. In 2009, Nvidia was involved in what was called the “big bang” of deep learning, “as deep-learning neural networks were trained with Nvidia graphics processing units (GPUs).” That year, Andrew Ng determined that GPUs could increase the speed of deep-learning systems by about 100 times. In particular, GPUs are well-suited for the matrix/vector computations involved in machine learning. GPUs speed up training algorithms by orders of magnitude, reducing running times from weeks to days. Further, specialized hardware and algorithm optimizations can be used for efficient processing of deep learning models.","[' What has driven renewed interest in deep learning?', ' What was Nvidia involved in in 2009?', ' Who determined that GPUs could increase the speed of deep-learning?', ' Ng determined that GPUs could increase the speed of deep-learning systems by how many times?', ' GPUs are well-suited for the matrix/vector computations involved in what type of computation?', ' What does GPUs speed up training algorithms by?', ' How can specialized hardware and algorithm optimizations be used for efficient processing of deep learning models?']","['Advances in hardware', 'the “big bang” of deep learning', 'Andrew Ng', '100', 'machine learning', 'orders of magnitude', 'GPUs speed up training algorithms by orders of magnitude, reducing running times from weeks to days']","[0.9751278460025787, 0.5376405566930771, 0.9888268411159515, 0.6801014840602875, 0.9831010401248932, 0.9691629111766815, 0.3472064360976219]"
66,deep learning,History,Hardware,"Advances in hardware have driven renewed interest in deep learning. In 2009, Nvidia was involved in what was called the “big bang” of deep learning, “as deep-learning neural networks were trained with Nvidia graphics processing units (GPUs).” That year, Andrew Ng determined that GPUs could increase the speed of deep-learning systems by about 100 times. In particular, GPUs are well-suited for the matrix/vector computations involved in machine learning. GPUs speed up training algorithms by orders of magnitude, reducing running times from weeks to days. Further, specialized hardware and algorithm optimizations can be used for efficient processing of deep learning models.","Since the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks that contain many layers of non-linear hidden units and a very large output layer. By 2019, graphic processing units (GPUs), often with AI-specific enhancements, had displaced CPUs as the dominant method of training large-scale commercial cloud AI. OpenAI estimated the hardware computation used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017), and found a 300,000-fold increase in the amount of computation required, with a doubling-time trendline of 3.4 months.","[' In what decade did advances in machine learning algorithms and computer hardware lead to more efficient methods for training deep neural networks?', ' By 2019, graphic processing units (GPUs) had displaced what CPUs?', ' What was the dominant method of training large-scale commercial cloud AI?', ' What did OpenAI estimate the hardware computation used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017)?', ' How many times increased the amount of computation required?', ' How many times has the amount of computation required increased?', ' What is the doubling-time trendline of 3.4 months?']","['2010s', 'CPUs', 'CPUs', '300,000-fold increase in the amount of computation required', '300,000-fold', '300,000-fold', '300,000-fold increase in the amount of computation required']","[0.9157704710960388, 0.8707824647426605, 0.5602693259716034, 0.5015077888965607, 0.8811346292495728, 0.7206800580024719, 0.30029140412807465]"
67,deep learning,Hardware,Relation to human cognitive and brain development,"Since the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks that contain many layers of non-linear hidden units and a very large output layer. By 2019, graphic processing units (GPUs), often with AI-specific enhancements, had displaced CPUs as the dominant method of training large-scale commercial cloud AI. OpenAI estimated the hardware computation used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017), and found a 300,000-fold increase in the amount of computation required, with a doubling-time trendline of 3.4 months.","Deep learning is closely related to a class of theories of brain development (specifically, neocortical development) proposed by cognitive neuroscientists in the early 1990s. These developmental theories were instantiated in computational models, making them predecessors of deep learning systems. These developmental models share the property that various proposed learning dynamics in the brain (e.g., a wave of nerve growth factor) support the self-organization somewhat analogous to the neural networks utilized in deep learning models. Like the neocortex, neural networks employ a hierarchy of layered filters in which each layer considers information from a prior layer (or the operating environment), and then passes its output (and possibly the original input), to other layers. This process yields a self-organizing stack of transducers, well-tuned to their operating environment. A 1995 description stated, ""...the infant's brain seems to organize itself under the influence of waves of so-called trophic-factors ... different regions of the brain become connected sequentially, with one layer of tissue maturing before another and so on until the whole brain is mature.""","[' Deep learning is closely related to what class of theories of brain development?', ' Deep learning theories were instantiated in what?', ' What model shares the property that various proposed learning dynamics in the brain support the self-organization somewhat analogous to the neural networks utilized in deep learning models?', ' Like the neocortex, neural networks employ a hierarchy of what?', ' What is a hierarchy of layered filters?', ' What does each layer consider from a prior layer?', "" How does the infant's brain organize itself?"", ' What do waves of so-called trophic-factors do?']","['neocortical development', 'computational models', 'developmental models', 'layered filters', 'each layer considers information from a prior layer (or the operating environment), and then passes its output (and possibly the original input), to other layers', 'information', 'under the influence of waves of so-called trophic-factors', 'become connected sequentially']","[0.9164331555366516, 0.9663722813129425, 0.36355920135974884, 0.9807503521442413, 0.5250217318534851, 0.9449560940265656, 0.7946308553218842, 0.31764160096645355]"
68,deep learning,Relation to human cognitive and brain development,Relation to human cognitive and brain development,"Deep learning is closely related to a class of theories of brain development (specifically, neocortical development) proposed by cognitive neuroscientists in the early 1990s. These developmental theories were instantiated in computational models, making them predecessors of deep learning systems. These developmental models share the property that various proposed learning dynamics in the brain (e.g., a wave of nerve growth factor) support the self-organization somewhat analogous to the neural networks utilized in deep learning models. Like the neocortex, neural networks employ a hierarchy of layered filters in which each layer considers information from a prior layer (or the operating environment), and then passes its output (and possibly the original input), to other layers. This process yields a self-organizing stack of transducers, well-tuned to their operating environment. A 1995 description stated, ""...the infant's brain seems to organize itself under the influence of waves of so-called trophic-factors ... different regions of the brain become connected sequentially, with one layer of tissue maturing before another and so on until the whole brain is mature.""","A variety of approaches have been used to investigate the plausibility of deep learning models from a neurobiological perspective. On the one hand, several variants of the backpropagation algorithm have been proposed in order to increase its processing realism. Other researchers have argued that unsupervised forms of deep learning, such as those based on hierarchical generative models and deep belief networks, may be closer to biological reality. In this respect, generative neural network models have been related to neurobiological evidence about sampling-based processing in the cerebral cortex.","[' What has been used to investigate the plausibility of deep learning models from a neurobiological perspective?', ' What have several variants of the backpropagation algorithm been proposed in order to increase its processing realism?', ' Researchers have argued that unsupervised forms of deep learning may be closer to what?', ' generative neural network models have been related to what evidence?']","['A variety of approaches', 'deep learning models', 'biological reality', 'neurobiological evidence about sampling-based processing in the cerebral cortex']","[0.8481274545192719, 0.050240905955433846, 0.979649007320404, 0.5998762845993042]"
69,deep learning,Relation to human cognitive and brain development,Commercial activity,"Although a systematic comparison between the human brain organization and the neuronal encoding in deep networks has not yet been established, several analogies have been reported. For example, the computations performed by deep learning units could be similar to those of actual neurons and neural populations. Similarly, the representations developed by deep learning models are similar to those measured in the primate visual system both at the single-unit and at the population levels.
",Facebook's AI lab performs tasks such as automatically tagging uploaded pictures with the names of the people in them.,"["" What does Facebook's AI lab do?"", ' What does the AI lab tag uploaded pictures?']","['automatically tagging uploaded pictures with the names of the people in them', 'the names of the people in them']","[0.708343893289566, 0.5676580518484116]"
70,deep learning,Commercial activity,Commercial activity,Facebook's AI lab performs tasks such as automatically tagging uploaded pictures with the names of the people in them.,"Google's DeepMind Technologies developed a system capable of learning how to play Atari video games using only pixels as data input. In 2015 they demonstrated their AlphaGo system, which learned the game of Go well enough to beat a professional Go player. Google Translate uses a neural network to translate between more than 100 languages.
","[' What company developed a system capable of learning how to play Atari video games?', ' What year did DeepMind Technologies demonstrate their AlphaGo system?', ' What does Google Translate use to translate between more than 100 languages?']","['DeepMind Technologies', '2015', 'a neural network']","[0.8525890409946442, 0.9739894270896912, 0.8645278811454773]"
71,deep learning,Commercial activity,Commercial activity,"Google's DeepMind Technologies developed a system capable of learning how to play Atari video games using only pixels as data input. In 2015 they demonstrated their AlphaGo system, which learned the game of Go well enough to beat a professional Go player. Google Translate uses a neural network to translate between more than 100 languages.
","In 2015, Blippar demonstrated a mobile augmented reality application that uses deep learning to recognize objects in real time.",[' In what year did Blippar demonstrate a mobile augmented reality application that uses deep learning to recognize objects in real time?'],['2015'],[0.9950196743011475]
72,deep learning,Commercial activity,Commercial activity,"In 2015, Blippar demonstrated a mobile augmented reality application that uses deep learning to recognize objects in real time.","In 2017, Covariant.ai was launched, which focuses on integrating deep learning into factories.",[' In what year was Covariant.ai launched?'],['2017'],[0.9922012984752655]
73,deep learning,Commercial activity,Commercial activity,"In 2017, Covariant.ai was launched, which focuses on integrating deep learning into factories.","As of 2008, researchers at The University of Texas at Austin (UT) developed a machine learning framework called Training an Agent Manually via Evaluative Reinforcement, or TAMER, which proposed new methods for robots or computer programs to learn how to perform tasks by interacting with a human instructor. First developed as TAMER, a new algorithm called Deep TAMER was later introduced in 2018 during a collaboration between U.S. Army Research Laboratory (ARL) and UT researchers. Deep TAMER used deep learning to provide a robot the ability to learn new tasks through observation. Using Deep TAMER, a robot learned a task with a human trainer, watching video streams or observing a human perform a task in-person. The robot later practiced the task with the help of some coaching from the trainer, who provided feedback such as “good job” and “bad job.”","[' What was the name of the machine learning framework developed by researchers at the University of Texas at Austin?', ' What is TAMER?', ' How did robots learn to perform tasks?', ' What is the name of the new algorithm developed by the U.S. Army Research Laboratory?', ' Deep TAMER was introduced in what year?', ' What did deep learning do for a robot?', ' How did a robot learn a task using Deep TAMER?', ' How did the robot learn the task?', ' What was the robot able to do with the help of the trainer?', ' What kind of feedback did the trainer give?']","['Training an Agent Manually via Evaluative Reinforcement', 'Training an Agent Manually via Evaluative Reinforcement', 'by interacting with a human instructor', 'Deep TAMER', '2018', 'the ability to learn new tasks through observation', 'through observation. Using Deep TAMER, a robot learned a task with a human trainer, watching video streams or observing a human perform a task in-person', 'watching video streams or observing a human perform a task in-person', 'practiced the task', '“good job” and “bad job']","[0.6306014358997345, 0.6723159551620483, 0.7702365219593048, 0.628844678401947, 0.9931798577308655, 0.5283106863498688, 0.43087470531463623, 0.31398074328899384, 0.626839816570282, 0.47630675137043]"
74,deep learning,Commercial activity,Criticism and comment,"As of 2008, researchers at The University of Texas at Austin (UT) developed a machine learning framework called Training an Agent Manually via Evaluative Reinforcement, or TAMER, which proposed new methods for robots or computer programs to learn how to perform tasks by interacting with a human instructor. First developed as TAMER, a new algorithm called Deep TAMER was later introduced in 2018 during a collaboration between U.S. Army Research Laboratory (ARL) and UT researchers. Deep TAMER used deep learning to provide a robot the ability to learn new tasks through observation. Using Deep TAMER, a robot learned a task with a human trainer, watching video streams or observing a human perform a task in-person. The robot later practiced the task with the help of some coaching from the trainer, who provided feedback such as “good job” and “bad job.”","Deep learning has attracted both criticism and comment, in some cases from outside the field of computer science.
","[' What has deep learning attracted both criticism and comment?', ' Deep learning has attracted criticism from outside what field?']","['outside the field of computer science', 'computer science']","[0.4017539545893669, 0.9406859278678894]"
75,data mining,Summary,Summary,"Data mining is a process of extracting and discovering patterns in large data sets involving methods at the intersection of machine learning, statistics, and database systems. Data mining is an interdisciplinary subfield of computer science and statistics with an overall goal of extracting information (with intelligent methods) from a data set and transform the information into a comprehensible structure for further use. Data mining is the analysis step of the ""knowledge discovery in databases"" process, or KDD. Aside from the raw analysis step, it also involves database and data management aspects, data pre-processing, model and inference considerations, interestingness metrics, complexity considerations, post-processing of discovered structures, visualization, and online updating.","The term ""data mining"" is a misnomer, because the goal is the extraction of patterns and knowledge from large amounts of data, not the extraction (mining) of data itself. It also is a buzzword and is frequently applied to any form of large-scale data or information processing (collection, extraction, warehousing, analysis, and statistics) as well as any application of computer decision support system, including artificial intelligence (e.g., machine learning) and business intelligence. The book Data mining: Practical machine learning tools and techniques with Java (which covers mostly machine learning material) was originally to be named just Practical machine learning, and the term data mining was only added for marketing reasons. Often the more general terms (large scale) data analysis and analytics—or, when referring to actual methods, artificial intelligence and machine learning—are more appropriate.
","[' What does the term ""data mining"" mean?', ' What is the goal of data mining?', ' Data mining is often applied to what?', ' What is a form of large-scale data processing?', ' What is an application of computer decision support system?', ' Artificial intelligence and business intelligence are examples of what?', ' What was the original name for Java techniques?', ' Why was the term data mining added?', ' What are the terms for large scale data analysis and analytics?', ' What are more appropriate when referring to actual methods?', ' What are artificial intelligence and machine learning?']","['extraction of patterns and knowledge from large amounts of data', 'extraction of patterns and knowledge from large amounts of data', 'any form of large-scale data or information processing', 'collection, extraction, warehousing, analysis, and statistics', 'artificial intelligence', 'computer decision support system', 'Practical machine learning', 'marketing reasons', 'more general', 'artificial intelligence and machine learning', 'computer decision support system']","[0.4307999461889267, 0.7659768462181091, 0.5735123008489609, 0.05526290833950043, 0.3218389004468918, 0.6190207898616791, 0.01764219719916582, 0.7164583206176758, 0.3409391790628433, 0.7643947601318359, 0.14367211610078812]"
76,data mining,Summary,Summary,"The term ""data mining"" is a misnomer, because the goal is the extraction of patterns and knowledge from large amounts of data, not the extraction (mining) of data itself. It also is a buzzword and is frequently applied to any form of large-scale data or information processing (collection, extraction, warehousing, analysis, and statistics) as well as any application of computer decision support system, including artificial intelligence (e.g., machine learning) and business intelligence. The book Data mining: Practical machine learning tools and techniques with Java (which covers mostly machine learning material) was originally to be named just Practical machine learning, and the term data mining was only added for marketing reasons. Often the more general terms (large scale) data analysis and analytics—or, when referring to actual methods, artificial intelligence and machine learning—are more appropriate.
","The actual data mining task is the semi-automatic or automatic analysis of large quantities of data to extract previously unknown, interesting patterns such as groups of data records (cluster analysis), unusual records (anomaly detection), and dependencies (association rule mining, sequential pattern mining). This usually involves using database techniques such as spatial indices. These patterns can then be seen as a kind of summary of the input data, and may be used in further analysis or, for example, in machine learning and predictive analytics. For example, the data mining step might identify multiple groups in the data, which can then be used to obtain more accurate prediction results by a decision support system. Neither the data collection, data preparation, nor result interpretation and reporting is part of the data mining step, but do belong to the overall KDD process as additional steps.
","[' What is the actual data mining task?', ' What is cluster analysis?', ' How does cluster analysis extract previously unknown patterns?', ' What does pattern mining usually involve using?', ' What can patterns be seen as a kind of?', ' What can be used to obtain more accurate prediction results by a decision support system?', ' What steps are not part of the data mining step?', ' What is part of the data mining step?', ' What are two additional steps in the KDD process?']","['the semi-automatic or automatic analysis of large quantities of data', 'groups of data records', 'groups of data records', 'database techniques such as spatial indices', 'summary of the input data', 'the data mining step might identify multiple groups in the data', 'data collection, data preparation, nor result interpretation and reporting', 'Neither the data collection, data preparation, nor result interpretation and reporting', 'data collection, data preparation, nor result interpretation and reporting']","[0.5987424552440643, 0.9496994018554688, 0.1456340067088604, 0.297151155769825, 0.9540274143218994, 0.4358970522880554, 0.8585206866264343, 0.19239528477191925, 0.11151332780718803]"
77,data mining,Summary,Summary,"The actual data mining task is the semi-automatic or automatic analysis of large quantities of data to extract previously unknown, interesting patterns such as groups of data records (cluster analysis), unusual records (anomaly detection), and dependencies (association rule mining, sequential pattern mining). This usually involves using database techniques such as spatial indices. These patterns can then be seen as a kind of summary of the input data, and may be used in further analysis or, for example, in machine learning and predictive analytics. For example, the data mining step might identify multiple groups in the data, which can then be used to obtain more accurate prediction results by a decision support system. Neither the data collection, data preparation, nor result interpretation and reporting is part of the data mining step, but do belong to the overall KDD process as additional steps.
","The difference between data analysis and data mining is that data analysis is used to test models and hypotheses on the dataset, e.g., analyzing the effectiveness of a marketing campaign, regardless of the amount of data; in contrast, data mining uses machine learning and statistical models to uncover clandestine or hidden patterns in a large volume of data.","[' What is used to test models and hypotheses on a dataset?', ' What uses machine learning and statistical models to uncover clandestine or secret information?', ' Machine learning and statistical models uncover what in a large volume of data?']","['data analysis', 'data mining', 'clandestine or hidden patterns']","[0.9728912115097046, 0.6362754106521606, 0.9004696607589722]"
78,data mining,Summary,Summary,"The difference between data analysis and data mining is that data analysis is used to test models and hypotheses on the dataset, e.g., analyzing the effectiveness of a marketing campaign, regardless of the amount of data; in contrast, data mining uses machine learning and statistical models to uncover clandestine or hidden patterns in a large volume of data.","The related terms data dredging, data fishing, and data snooping refer to the use of data mining methods to sample parts of a larger population data set that are (or may be) too small for reliable statistical inferences to be made about the validity of any patterns discovered. These methods can, however, be used in creating new hypotheses to test against the larger data populations.
","[' What are the terms data dredging, data fishing, and data snooping?', ' What are data mining methods used to sample parts of a larger population data set?', ' What can be used to create new hypotheses to test against larger data populations?']","['data mining methods', 'data dredging', 'data mining methods']","[0.2708390802145004, 0.6552704274654388, 0.5275085866451263]"
79,data mining,Summary,Etymology,"The related terms data dredging, data fishing, and data snooping refer to the use of data mining methods to sample parts of a larger population data set that are (or may be) too small for reliable statistical inferences to be made about the validity of any patterns discovered. These methods can, however, be used in creating new hypotheses to test against the larger data populations.
","In the 1960s, statisticians and economists used terms like data fishing or data dredging to refer to what they considered the bad practice of analyzing data without an a-priori hypothesis. The term ""data mining"" was used in a similarly critical way by economist Michael Lovell in an article published in the Review of Economic Studies in 1983. Lovell indicates that the practice ""masquerades under a variety of aliases, ranging from ""experimentation"" (positive) to ""fishing"" or ""snooping"" (negative).
","[' When did statisticians and economists use terms like data fishing and data dredging to refer to bad practice of analyzing data without an a-priori hypothesis?', ' What term was used in a similar way by economist Michael Lovell in an article published in the 1960s?', "" In what year was Michael Lovell's article published in the Review of Economic Studies?"", ' What does Lovell say the practice masquerades under a variety of?']","['1960s', 'data mining', '1983', 'aliases']","[0.7204566597938538, 0.2072354257106781, 0.9579237401485443, 0.9131531417369843]"
80,data mining,Etymology,Etymology,"In the 1960s, statisticians and economists used terms like data fishing or data dredging to refer to what they considered the bad practice of analyzing data without an a-priori hypothesis. The term ""data mining"" was used in a similarly critical way by economist Michael Lovell in an article published in the Review of Economic Studies in 1983. Lovell indicates that the practice ""masquerades under a variety of aliases, ranging from ""experimentation"" (positive) to ""fishing"" or ""snooping"" (negative).
","The term data mining appeared around 1990 in the database community, generally with positive connotations. For a short time in 1980s, a phrase ""database mining""™, was used, but since it was trademarked by HNC, a San Diego-based company, to pitch their Database Mining Workstation; researchers consequently turned to data mining. Other terms used include data archaeology, information harvesting, information discovery, knowledge extraction, etc. Gregory Piatetsky-Shapiro coined the term ""knowledge discovery in databases"" for the first workshop on the same topic (KDD-1989) and this term became more popular in AI and machine learning community. However, the term data mining became more popular in the business and press communities. Currently, the terms data mining and knowledge discovery are used interchangeably.
","[' When did the term data mining appear in the database community?', ' What phrase was used for a short time in the 1980s?', ' Who trademarked the phrase ""database mining""TM?', ' Who coined the term ""knowledge discovery in databases"" for the first workshop on the same topic?', ' What term became more popular in AI and other fields?', ' What term became more popular in the AI and machine learning community?', ' What was the most popular term in the business and press communities?']","['around 1990', 'database mining', 'HNC', 'Gregory Piatetsky-Shapiro', 'knowledge discovery', 'knowledge discovery', 'data mining']","[0.7537205517292023, 0.5998687595129013, 0.8992316126823425, 0.991771012544632, 0.4112122505903244, 0.5664611607789993, 0.736752063035965]"
81,data mining,Etymology,Etymology,"The term data mining appeared around 1990 in the database community, generally with positive connotations. For a short time in 1980s, a phrase ""database mining""™, was used, but since it was trademarked by HNC, a San Diego-based company, to pitch their Database Mining Workstation; researchers consequently turned to data mining. Other terms used include data archaeology, information harvesting, information discovery, knowledge extraction, etc. Gregory Piatetsky-Shapiro coined the term ""knowledge discovery in databases"" for the first workshop on the same topic (KDD-1989) and this term became more popular in AI and machine learning community. However, the term data mining became more popular in the business and press communities. Currently, the terms data mining and knowledge discovery are used interchangeably.
","In the academic community, the major forums for research started in 1995 when the First International Conference on Data Mining and Knowledge Discovery (KDD-95) was started in Montreal under AAAI sponsorship. It was co-chaired by Usama Fayyad and Ramasamy Uthurusamy. A year later, in 1996, Usama Fayyad launched the journal by Kluwer called Data Mining and Knowledge Discovery as its founding editor-in-chief. Later he started the SIGKDD Newsletter SIGKDD Explorations. The KDD International conference became the primary highest quality conference in data mining with an acceptance rate of research paper submissions below 18%. The journal Data Mining and Knowledge Discovery is the primary research journal of the field.
","[' When did the major forums for research start in the academic community?', ' Where was the First International Conference on Data Mining and Knowledge Discovery started?', ' Who co-chaired the first international conference on data mining and knowledge discovery?', ' What journal did Usama Fayyad launch in 1996?', ' When did Usama Fayyad launch Data Mining and Knowledge Discovery?', ' What was the name of the journal by Kluwer called?', ' Who was the founding editor-in-chief of the Kluwer journal?', ' The KDD International conference became the primary highest quality conference in what field?', ' What is the acceptance rate of research paper submissions in data mining?', ' Data Mining and Knowledge Discovery is the primary research journal of what field?']","['1995', 'Montreal', 'Usama Fayyad and Ramasamy Uthurusamy', 'Data Mining and Knowledge Discovery', '1996', 'Data Mining and Knowledge Discovery', 'Usama Fayyad', 'data mining', 'below 18%.', 'data mining']","[0.95980304479599, 0.9866317510604858, 0.9633472561836243, 0.9761972725391388, 0.9262848794460297, 0.8136385381221771, 0.07759813591837883, 0.9905194938182831, 0.6667445600032806, 0.9650724232196808]"
82,data mining,Etymology,Background,"In the academic community, the major forums for research started in 1995 when the First International Conference on Data Mining and Knowledge Discovery (KDD-95) was started in Montreal under AAAI sponsorship. It was co-chaired by Usama Fayyad and Ramasamy Uthurusamy. A year later, in 1996, Usama Fayyad launched the journal by Kluwer called Data Mining and Knowledge Discovery as its founding editor-in-chief. Later he started the SIGKDD Newsletter SIGKDD Explorations. The KDD International conference became the primary highest quality conference in data mining with an acceptance rate of research paper submissions below 18%. The journal Data Mining and Knowledge Discovery is the primary research journal of the field.
","The manual extraction of patterns from data has occurred for centuries. Early methods of identifying patterns in data include Bayes' theorem (1700s) and regression analysis (1800s). The proliferation, ubiquity and increasing power of computer technology have dramatically increased data collection, storage, and manipulation ability. As data sets have grown in size and complexity, direct ""hands-on"" data analysis has increasingly been augmented with indirect, automated data processing, aided by other discoveries in computer science, specially in the field of machine learning, such as neural networks, cluster analysis, genetic algorithms (1950s), decision trees and decision rules (1960s), and support vector machines (1990s). Data mining is the process of applying these methods with the intention of uncovering hidden patterns. in large data sets. It bridges the gap from applied statistics and artificial intelligence (which usually provide the mathematical background) to database management by exploiting the way data is stored and indexed in databases to execute the actual learning and discovery algorithms more efficiently, allowing such methods to be applied to ever-larger data sets.
","[' The manual extraction of patterns from data has occurred for how long?', ' What are two early methods of identifying patterns in data?', ' The proliferation, ubiquity and increasing power of what have dramatically increased data collection, storage, and manipulation ability?', ' What are some of the discoveries in computer science that have aided machine learning?', ' In what decade were genetic algorithms first discovered?', ' What is the process of applying these methods with the intention of uncovering hidden patterns?', ' What bridges the gap from applied statistics and artificial intelligence?', ' What does it bridge the gap from applied statistics and artificial intelligence to?', ' What do it exploit the way data is stored and indexed in databases to execute?']","['centuries', ""Bayes' theorem (1700s) and regression analysis (1800s)."", 'computer technology', 'neural networks, cluster analysis, genetic algorithms (1950s), decision trees and decision rules (1960s), and support vector machines', '1950s', 'Data mining', 'Data mining', 'database management', 'learning and discovery algorithms']","[0.977839469909668, 0.7140627354383469, 0.9941054284572601, 0.6687116473913193, 0.9279958605766296, 0.9927314817905426, 0.9420925378799438, 0.5895999670028687, 0.4684947282075882]"
83,data mining,Process,Process,"The knowledge discovery in databases (KDD) process is commonly defined with the stages:
","It exists, however, in many variations on this theme, such as the Cross-industry standard process for data mining (CRISP-DM) which defines six phases:
","[' What is the Cross-industry standard process for data mining called?', ' How many phases does CRISP-DM define?']","['CRISP-DM', 'six']","[0.9804688990116119, 0.8925378322601318]"
84,data mining,Process,Process,"It exists, however, in many variations on this theme, such as the Cross-industry standard process for data mining (CRISP-DM) which defines six phases:
","or a simplified process such as (1) Pre-processing, (2) Data Mining, and (3) Results Validation.
","[' What is a simplified process such as Pre-processing, Data Mining, and Results Validation?']",['1) Pre-processing'],[0.17254944890737534]
85,data mining,Process,Process,"or a simplified process such as (1) Pre-processing, (2) Data Mining, and (3) Results Validation.
","Polls conducted in 2002, 2004, 2007 and 2014 show that the CRISP-DM methodology is the leading methodology used by data miners. The only other data mining standard named in these polls was SEMMA. However, 3–4 times as many people reported using CRISP-DM. Several teams of researchers have published reviews of data mining process models, and Azevedo and Santos conducted a comparison of CRISP-DM and SEMMA in 2008.","[' What is the leading methodology used by data miners?', ' What was the only other data mining standard named in the polls?', ' How many times as many people reported using CRISP-DM?', ' What has CRISP-DM been used for?', ' When did Azevedo and Santos conduct a comparison?', ' What two processes were compared in 2008?', ' How many teams have published reviews of data mining process models?']","['CRISP-DM', 'SEMMA', '3–4', 'data miners', '2008', 'CRISP-DM and SEMMA', 'Several']","[0.724718302488327, 0.9950800836086273, 0.766159176826477, 0.7443830370903015, 0.9221949279308319, 0.9697589576244354, 0.6851968616247177]"
86,data mining,Process,Research,"Polls conducted in 2002, 2004, 2007 and 2014 show that the CRISP-DM methodology is the leading methodology used by data miners. The only other data mining standard named in these polls was SEMMA. However, 3–4 times as many people reported using CRISP-DM. Several teams of researchers have published reviews of data mining process models, and Azevedo and Santos conducted a comparison of CRISP-DM and SEMMA in 2008.","The premier professional body in the field is the Association for Computing Machinery's (ACM) Special Interest Group (SIG) on Knowledge Discovery and Data Mining (SIGKDD). Since 1989, this ACM SIG has hosted an annual international conference and published its proceedings, and since 1999 it has published a biannual academic journal titled ""SIGKDD Explorations"".","[' What is the acronym for the ACM Special Interest Group on Knowledge Discovery and Data Mining?', ' Since what year has the SIG hosted an annual international conference?', ' What does SIGKDD stand for?', ' What is the name of the biannual academic journal published by SIGKDD Explorations?']","['SIGKDD', '1989', 'Special Interest Group (SIG) on Knowledge Discovery and Data Mining', '1999']","[0.6509551703929901, 0.9008077085018158, 0.7764891982078552, 0.0646002534776926]"
87,data mining,Research,Research,"Computer science conferences on data mining include:
","Data mining topics are also present on many data management/database conferences such as the ICDE Conference, SIGMOD Conference and International Conference on Very Large Data Bases
","[' What topics are present on many data management/database conferences?', ' What is the SIGMOD Conference?']","['Data mining', 'data management/database conferences']","[0.765296071767807, 0.25072434544563293]"
88,data mining,Research,Standards,"Data mining topics are also present on many data management/database conferences such as the ICDE Conference, SIGMOD Conference and International Conference on Very Large Data Bases
","There have been some efforts to define standards for the data mining process, for example, the 1999 European Cross Industry Standard Process for Data Mining (CRISP-DM 1.0) and the 2004 Java Data Mining standard (JDM 1.0). Development on successors to these processes (CRISP-DM 2.0 and JDM 2.0) was active in 2006 but has stalled since. JDM 2.0 was withdrawn without reaching a final draft.
","[' What was the European Cross Industry Standard Process for Data Mining called in 1999?', ' What is the Java Data Mining standard called in 2004?', ' When were CRISP-DM 2.0 and JDM 2.0 developed?', ' When was CRISP-DM 2.0 active?', ' When was JDM 2.0 withdrawn without reaching a final draft?', ' What process was active in 2006 but has stalled since?']","['CRISP-DM 1.0', 'JDM 1.0', '2006', '2006', '2006', 'Development on successors to these processes (CRISP-DM 2.0 and JDM 2.0']","[0.879629373550415, 0.9330572485923767, 0.682950496673584, 0.8052302896976471, 0.3326287418603897, 0.38119758665561676]"
89,data mining,Standards,Standards,"There have been some efforts to define standards for the data mining process, for example, the 1999 European Cross Industry Standard Process for Data Mining (CRISP-DM 1.0) and the 2004 Java Data Mining standard (JDM 1.0). Development on successors to these processes (CRISP-DM 2.0 and JDM 2.0) was active in 2006 but has stalled since. JDM 2.0 was withdrawn without reaching a final draft.
","For exchanging the extracted models—in particular for use in predictive analytics—the key standard is the Predictive Model Markup Language (PMML), which is an XML-based language developed by the Data Mining Group (DMG) and supported as exchange format by many data mining applications. As the name suggests, it only covers prediction models, a particular data mining task of high importance to business applications. However, extensions to cover (for example) subspace clustering have been proposed independently of the DMG.","[' What is the key standard for exchanging extracted models?', ' Who developed PMML?', ' What language is PMML an XML-based language?', ' What does mining applications only cover?', ' What is a particular data mining task of high importance to business applications?', ' Extensions to cover what have been proposed independently of the DMG?']","['Predictive Model Markup Language', 'Data Mining Group (DMG)', 'Predictive Model Markup Language', 'prediction models', 'prediction models', 'subspace clustering']","[0.7204878926277161, 0.5836262702941895, 0.9297119379043579, 0.008427937515079975, 0.976669579744339, 0.9795829951763153]"
90,data mining,Standards,Notable uses,"For exchanging the extracted models—in particular for use in predictive analytics—the key standard is the Predictive Model Markup Language (PMML), which is an XML-based language developed by the Data Mining Group (DMG) and supported as exchange format by many data mining applications. As the name suggests, it only covers prediction models, a particular data mining task of high importance to business applications. However, extensions to cover (for example) subspace clustering have been proposed independently of the DMG.","Data mining is used wherever there is digital data available today. Notable examples of data mining can be found throughout business, medicine, science, and surveillance.
","[' What is used where there is digital data available today?', ' What are some notable examples of data mining?']","['Data mining', 'business, medicine, science, and surveillance']","[0.9632588922977448, 0.922931581735611]"
91,data mining,Notable uses,Privacy concerns and ethics,"Data mining is used wherever there is digital data available today. Notable examples of data mining can be found throughout business, medicine, science, and surveillance.
","While the term ""data mining"" itself may have no ethical implications, it is often associated with the mining of information in relation to peoples' behavior (ethical and otherwise).","[' What does the term ""data mining"" have no ethical implications?', ' What is often associated with the mining of information in relation to peoples behavior?']","[""mining of information in relation to peoples' behavior"", 'data mining']","[0.015819427091628313, 0.8701466023921967]"
92,data mining,Privacy concerns and ethics,Privacy concerns and ethics,"While the term ""data mining"" itself may have no ethical implications, it is often associated with the mining of information in relation to peoples' behavior (ethical and otherwise).","The ways in which data mining can be used can in some cases and contexts raise questions regarding privacy, legality, and ethics. In particular, data mining government or commercial data sets for national security or law enforcement purposes, such as in the Total Information Awareness Program or in ADVISE, has raised privacy concerns.","[' What are some aspects of data mining?', ' What is one example of a government or commercial data mining program?', ' What program has raised privacy concerns?', ' What is the name of the program that raises concerns about privacy?']","['privacy, legality, and ethics', 'Total Information Awareness Program', 'Total Information Awareness Program', 'Total Information Awareness Program']","[0.7577720284461975, 0.6664636135101318, 0.337554469704628, 0.5993932783603668]"
93,data mining,Privacy concerns and ethics,Privacy concerns and ethics,"The ways in which data mining can be used can in some cases and contexts raise questions regarding privacy, legality, and ethics. In particular, data mining government or commercial data sets for national security or law enforcement purposes, such as in the Total Information Awareness Program or in ADVISE, has raised privacy concerns.","Data mining requires data preparation which uncovers information or patterns which compromise confidentiality and privacy obligations. A common way for this to occur is through data aggregation. Data aggregation involves combining data together (possibly from various sources) in a way that facilitates analysis (but that also might make identification of private, individual-level data deducible or otherwise apparent). This is not data mining per se, but a result of the preparation of data before—and for the purposes of—the analysis. The threat to an individual's privacy comes into play when the data, once compiled, cause the data miner, or anyone who has access to the newly compiled data set, to be able to identify specific individuals, especially when the data were originally anonymous.","[' What requires data preparation to uncover information or patterns that compromise confidentiality and privacy obligations?', ' What is a common way for data mining to occur?', ' Data aggregation involves combining data together from what sources?', ' What is a result of the preparation of data before and for the purposes of the analysis?', "" What is the threat to an individual's privacy?"", ' What happens when the data is compiled?', ' Who can identify specific individuals?', ' What was the original purpose of the data?']","['Data mining', 'data aggregation', 'various sources', 'data aggregation', 'when the data, once compiled, cause the data miner, or anyone who has access to the newly compiled data set, to be able to identify specific individuals', ""The threat to an individual's privacy comes into play when the data, once compiled, cause the data miner, or anyone who has access to the newly compiled data set, to be able to identify specific individuals"", 'data miner', 'anonymous']","[0.006958959391340613, 0.84934002161026, 0.6791510879993439, 0.1901916190981865, 0.36817216873168945, 0.1663610339164734, 0.5053655654191971, 0.5822654962539673]"
94,data mining,Privacy concerns and ethics,Privacy concerns and ethics,"Data mining requires data preparation which uncovers information or patterns which compromise confidentiality and privacy obligations. A common way for this to occur is through data aggregation. Data aggregation involves combining data together (possibly from various sources) in a way that facilitates analysis (but that also might make identification of private, individual-level data deducible or otherwise apparent). This is not data mining per se, but a result of the preparation of data before—and for the purposes of—the analysis. The threat to an individual's privacy comes into play when the data, once compiled, cause the data miner, or anyone who has access to the newly compiled data set, to be able to identify specific individuals, especially when the data were originally anonymous.",It is recommended to be aware of the following before data are collected:,[' What should you be aware of before collecting data?'],['the following'],[0.6145231574773788]
95,data mining,Privacy concerns and ethics,Privacy concerns and ethics,It is recommended to be aware of the following before data are collected:,"Data may also be modified so as to become anonymous, so that individuals may not readily be identified. However, even ""anonymized"" data sets can potentially contain enough information to allow identification of individuals, as occurred when journalists were able to find several individuals based on a set of search histories that were inadvertently released by AOL.","[' What can be modified so as to become anonymous?', ' What can potentially contain enough information to allow identification of individuals?', ' How did journalists find several individuals based on a set of search histories?', ' AOL released a set of search histories inadvertently by what company?']","['Data', 'anonymized"" data sets', 'inadvertently released by AOL', 'AOL']","[0.8106151223182678, 0.7809758484363556, 0.18625035136938095, 0.25820622593164444]"
96,data mining,Privacy concerns and ethics,Privacy concerns and ethics,"Data may also be modified so as to become anonymous, so that individuals may not readily be identified. However, even ""anonymized"" data sets can potentially contain enough information to allow identification of individuals, as occurred when journalists were able to find several individuals based on a set of search histories that were inadvertently released by AOL.","The inadvertent revelation of personally identifiable information leading to the provider violates Fair Information Practices.   This indiscretion can cause financial,
emotional, or bodily harm to the indicated individual.  In one instance of privacy violation, the patrons of Walgreens filed a lawsuit against the company in 2011 for selling
prescription information to data mining companies who in turn provided the data
to pharmaceutical companies.","[' What is a violation of Fair Information Practices?', ' Who filed a lawsuit in 2011?', ' What did the patrons of Walgreens do?', ' In what year did a lawsuit be filed against the company for selling prescription information to data mining companies?', ' What did the lawsuit allege the company sold prescription data to?', ' Who provided the data to pharmaceutical companies in 2011?']","['The inadvertent revelation of personally identifiable information leading to the provider', 'the patrons of Walgreens', 'selling\nprescription information to data mining companies', '2011', 'data mining companies', 'data mining companies']","[0.5180177241563797, 0.6839267164468765, 0.19141925871372223, 0.9784871637821198, 0.8117449879646301, 0.44710008800029755]"
