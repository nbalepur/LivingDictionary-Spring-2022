,topic,section,full_text,prefix,suffix,questions,answers,scores
0,machine learning,Summary,"Machine learning (ML) is the study of computer algorithms that can improve automatically through experience and by the use of data. It is seen as a part of artificial intelligence. Machine learning algorithms build a model based on sample data, known as training data, in order to make predictions or decisions without being explicitly programmed to do so. Machine learning algorithms are used in a wide variety of applications, such as in medicine, email filtering, speech recognition, and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.",Machine learning (ML) is the study of computer algorithms that can improve automatically through experience and by the use of data. It is seen as a part of artificial intelligence.,"Machine learning algorithms build a model based on sample data, known as training data, in order to make predictions or decisions without being explicitly programmed to do so. Machine learning algorithms are used in a wide variety of applications, such as in medicine, email filtering, speech recognition, and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.","[' Machine learning algorithms build a model based on what?', ' What is training data?', ' Machine learning is used in medicine, email filtering, speech recognition, and computer vision?', ' Where is it difficult or unfavorable to develop conventional algorithms to perform the needed tasks?']","['sample data', 'sample data', 'Machine learning', 'unfeasible']","[0.8054902255535126, 0.9565122723579407, 0.022041426971554756, 0.6528015434741974]"
1,machine learning,Summary,"A subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers; but not all machine learning is statistical learning. The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning. Some implementations of machine learning use data and neural networks in a way that mimics the working of a biological brain.  In its application across business problems, machine learning is also referred to as predictive analytics.
","A subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers; but not all machine learning is statistical learning. The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning.","Data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning. Some implementations of machine learning use data and neural networks in a way that mimics the working of a biological brain. In its application across business problems, machine learning is also referred to as predictive analytics.","[' What is a related field of study?', ' What does data mining focus on?', ' Some implementations of machine learning use data and neural networks in a way that mimics the working of what?', ' Machine learning is also referred to as what in its application across business problems?', ' Machine learning is also referred to as what?']","['Data mining', 'exploratory data analysis through unsupervised learning', 'a biological brain', 'predictive analytics', 'predictive analytics']","[0.936706006526947, 0.7350618243217468, 0.8518088459968567, 0.9938589036464691, 0.9893425405025482]"
2,machine learning,Overview,"Learning algorithms work on the basis that strategies, algorithms, and inferences that worked well in the past are likely to continue working well in the future. These inferences can be obvious, such as ""since the sun rose every morning for the last 10,000 days, it will probably rise tomorrow morning as well"". They can be nuanced, such as ""X% of families have geographically separate species with color variants, so there is a Y% chance that undiscovered black swans exist"".","Learning algorithms work on the basis that strategies, algorithms, and inferences that worked well in the past are likely to continue working well in the future. These inferences can be obvious, such as ""since the sun rose every morning for the last 10,000 days, it will probably rise tomorrow morning as well"".","They can be nuanced, such as ""X% of families have geographically separate species with color variants, so there is a Y% chance that undiscovered black swans exist"".","[' What percentage of families have geographically separate species with color variants?', ' What is the chance that undiscovered black swans exist?']","['X%', 'Y%']","[0.9154024422168732, 0.8777832686901093]"
3,machine learning,Overview,"Machine learning programs can perform tasks without being explicitly programmed to do so. It involves computers learning from data provided so that they carry out certain tasks. For simple tasks assigned to computers, it is possible to program algorithms telling the machine how to execute all steps required to solve the problem at hand; on the computer's part, no learning is needed. For more advanced tasks, it can be challenging for a human to manually create the needed algorithms. In practice, it can turn out to be more effective to help the machine develop its own algorithm, rather than having human programmers specify every needed step.",Machine learning programs can perform tasks without being explicitly programmed to do so. It involves computers learning from data provided so that they carry out certain tasks.,"For simple tasks assigned to computers, it is possible to program algorithms telling the machine how to execute all steps required to solve the problem at hand; on the computer's part, no learning is needed. For more advanced tasks, it can be challenging for a human to manually create the needed algorithms. In practice, it can turn out to be more effective to help the machine develop its own algorithm, rather than having human programmers specify every needed step.","[' What is it possible to program for simple tasks assigned to computers?', "" What is needed on the computer's part to solve the problem at hand?"", ' For more advanced tasks, it can be challenging for a human to manually create what?', ' What can be challenging for a human to manually create the needed algorithms?', ' What can turn out to be more effective to help the machine develop its own algorithm?']","['algorithms', 'no learning', 'the needed algorithms', 'more advanced tasks', 'manually create the needed algorithms']","[0.8527903258800507, 0.5934649407863617, 0.8385758399963379, 0.8109094500541687, 0.2679069861769676]"
4,machine learning,Overview,"The discipline of machine learning employs various approaches to teach computers to accomplish tasks where no fully satisfactory algorithm is available. In cases where vast numbers of potential answers exist, one approach is to label some of the correct answers as valid. This can then be used as training data for the computer to improve the algorithm(s) it uses to determine correct answers. For example, to train a system for the task of digital character recognition, the MNIST dataset of handwritten digits has often been used.","The discipline of machine learning employs various approaches to teach computers to accomplish tasks where no fully satisfactory algorithm is available. In cases where vast numbers of potential answers exist, one approach is to label some of the correct answers as valid.","This can then be used as training data for the computer to improve the algorithm(s) it uses to determine correct answers. For example, to train a system for the task of digital character recognition, the MNIST dataset of handwritten digits has often been used.","[' What can be used as training data for the computer to improve?', ' What dataset has often been used to train a system for the task of digital character recognition?']","['algorithm(s) it uses to determine correct answers. For example, to train a system for the task of digital character recognition, the MNIST dataset of handwritten digits', 'MNIST']","[0.25001735240221024, 0.5340260416269302]"
5,machine learning,History and relationships to other fields,"The term machine learning was coined in 1959 by Arthur Samuel, an American IBMer and pioneer in the field of computer gaming and artificial intelligence. Also the synonym self-teaching computers was used in this time period. A representative book of the machine learning research during the 1960s was the Nilsson's book on Learning Machines, dealing mostly with machine learning for pattern classification. Interest related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973. In 1981 a report was given on using teaching strategies so that a neural network learns to recognize 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal.","The term machine learning was coined in 1959 by Arthur Samuel, an American IBMer and pioneer in the field of computer gaming and artificial intelligence. Also the synonym self-teaching computers was used in this time period.","A representative book of the machine learning research during the 1960s was the Nilsson's book on Learning Machines, dealing mostly with machine learning for pattern classification. Interest related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973. In 1981 a report was given on using teaching strategies so that a neural network learns to recognize 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal.","["" What was a representative book of machine learning research during the 1960's?"", "" What was the main focus of Nilsson's book?"", ' When did Duda and Hart describe interest in pattern recognition?', ' In what year was Hart born?', ' How many characters does a neural network learn to recognize from a computer terminal?']","[""Nilsson's book on Learning Machines"", 'machine learning for pattern classification', '1973', '1973', '40']","[0.815002828836441, 0.7472980916500092, 0.9678431749343872, 0.03412206284701824, 0.9272209107875824]"
6,machine learning,History and relationships to other fields,"Tom M. Mitchell provided a widely quoted, more formal definition of the algorithms studied in the machine learning field: ""A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P,  improves with experience E."" This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather than defining the field in cognitive terms. This follows Alan Turing's proposal in his paper ""Computing Machinery and Intelligence"", in which the question ""Can machines think?"" is replaced with the question ""Can machines do what we (as thinking entities) can do?"".","Tom M. Mitchell provided a widely quoted, more formal definition of the algorithms studied in the machine learning field: ""A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P,  improves with experience E."" This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather than defining the field in cognitive terms. This follows Alan Turing's proposal in his paper ""Computing Machinery and Intelligence"", in which the question ""Can machines think?""","is replaced with the question ""Can machines do what we (as thinking entities) can do? "".","[' What is replaced by the question ""Can machines do what we can do?""']",['as thinking entities'],[0.11634111404418945]
7,machine learning,History and relationships to other fields,"Modern day machine learning has two objectives, one is to classify data based on models which have been developed, the other purpose is to make predictions for future outcomes based on these models. A hypothetical algorithm specific to classifying data may use computer vision of moles coupled with supervised learning in order to train it to classify the cancerous moles. Where as, a machine learning algorithm for stock trading may inform the trader of future potential predictions.","Modern day machine learning has two objectives, one is to classify data based on models which have been developed, the other purpose is to make predictions for future outcomes based on these models. A hypothetical algorithm specific to classifying data may use computer vision of moles coupled with supervised learning in order to train it to classify the cancerous moles.","Where as, a machine learning algorithm for stock trading may inform the trader of future potential predictions.",[' What can a machine learning algorithm for stock trading inform the trader of?'],['future potential predictions'],[0.95827516913414]
8,machine learning,Theory,"A core objective of a learner is to generalize from its experience. Generalization in this context is the ability of a learning machine to perform accurately on new, unseen examples/tasks after having experienced a learning data set. The training examples come from some generally unknown probability distribution (considered representative of the space of occurrences) and the learner has to build a general model about this space that enables it to produce sufficiently accurate predictions in new cases.
","A core objective of a learner is to generalize from its experience. Generalization in this context is the ability of a learning machine to perform accurately on new, unseen examples/tasks after having experienced a learning data set.",The training examples come from some generally unknown probability distribution (considered representative of the space of occurrences) and the learner has to build a general model about this space that enables it to produce sufficiently accurate predictions in new cases.,"[' What is considered representative of the space of occurrences?', ' The learner has to build a general model about what space?']","['probability distribution', 'probability distribution']","[0.7974168062210083, 0.4634510576725006]"
9,machine learning,Theory,"The computational analysis of machine learning algorithms and their performance is a branch of theoretical computer science known as computational learning theory. Because training sets are finite and the future is uncertain, learning theory usually does not yield guarantees of the performance of algorithms. Instead, probabilistic bounds on the performance are quite common. The bias–variance decomposition is one way to quantify generalization error.
","The computational analysis of machine learning algorithms and their performance is a branch of theoretical computer science known as computational learning theory. Because training sets are finite and the future is uncertain, learning theory usually does not yield guarantees of the performance of algorithms.","Instead, probabilistic bounds on the performance are quite common. The bias–variance decomposition is one way to quantify generalization error.","[' What is one way to quantify generalization error?', ' What are probabilistic bounds on performance?']","['bias–variance decomposition', 'quite common']","[0.7825210392475128, 0.6988092362880707]"
10,machine learning,Theory,"For the best performance in the context of generalization, the complexity of the hypothesis should match the complexity of the function underlying the data. If the hypothesis is less complex than the function, then the model has under fitted the data. If the complexity of the model is increased in response, then the training error decreases. But if the hypothesis is too complex, then the model is subject to overfitting and generalization will be poorer.","For the best performance in the context of generalization, the complexity of the hypothesis should match the complexity of the function underlying the data. If the hypothesis is less complex than the function, then the model has under fitted the data.","If the complexity of the model is increased in response, then the training error decreases. But if the hypothesis is too complex, then the model is subject to overfitting and generalization will be poorer.","[' What happens if the complexity of the model is increased in response?', ' If the hypothesis is too complex, what happens to the model?']","['the training error decreases', 'subject to overfitting']","[0.8028956651687622, 0.4440908133983612]"
11,machine learning,Theory,"In addition to performance bounds, learning theorists study the time complexity and feasibility of learning. In computational learning theory, a computation is considered feasible if it can be done in polynomial time. There are two kinds of time complexity results: Positive results show that a certain class of functions can be learned in polynomial time. Negative results show that certain classes cannot be learned in polynomial time.
","In addition to performance bounds, learning theorists study the time complexity and feasibility of learning. In computational learning theory, a computation is considered feasible if it can be done in polynomial time.",There are two kinds of time complexity results: Positive results show that a certain class of functions can be learned in polynomial time. Negative results show that certain classes cannot be learned in polynomial time.,"[' How many kinds of time complexity results are there?', ' Positive results show that a certain class of functions can be learned in what time?', ' Negative results show what?']","['two', 'polynomial time', 'certain classes cannot be learned in polynomial time']","[0.918920636177063, 0.6468961387872696, 0.7615303695201874]"
12,machine learning,Applications,"In 2006, the media-services provider Netflix held the first ""Netflix Prize"" competition to find a program to better predict user preferences and improve the accuracy of its existing Cinematch movie recommendation algorithm by at least 10%.  A joint team made up of researchers from AT&T Labs-Research in collaboration with the teams Big Chaos and Pragmatic Theory built an ensemble model to win the Grand Prize in 2009 for $1 million. Shortly after the prize was awarded, Netflix realized that viewers' ratings were not the best indicators of their viewing patterns (""everything is a recommendation"") and they changed their recommendation engine accordingly. In 2010 The Wall Street Journal wrote about the firm Rebellion Research and their use of machine learning to predict the financial crisis. In 2012, co-founder of Sun Microsystems, Vinod Khosla, predicted that 80% of medical doctors' jobs would be lost in the next two decades to automated machine learning medical diagnostic software. In 2014, it was reported that a machine learning algorithm had been applied in the field of art history to study fine art paintings and that it may have revealed previously unrecognized influences among artists. In 2019 Springer Nature published the first research book created using machine learning. In 2020, machine learning technology was used to help make diagnoses and aid researchers in developing a cure for COVID-19. Machine learning is recently applied to predict the green behavior of human-being. Recently, machine learning technology is also applied to optimise smartphone's performance and thermal behaviour based on the user's interaction with the phone.","In 2006, the media-services provider Netflix held the first ""Netflix Prize"" competition to find a program to better predict user preferences and improve the accuracy of its existing Cinematch movie recommendation algorithm by at least 10%. A joint team made up of researchers from AT&T Labs-Research in collaboration with the teams Big Chaos and Pragmatic Theory built an ensemble model to win the Grand Prize in 2009 for $1 million.","Shortly after the prize was awarded, Netflix realized that viewers' ratings were not the best indicators of their viewing patterns (""everything is a recommendation"") and they changed their recommendation engine accordingly. In 2010 The Wall Street Journal wrote about the firm Rebellion Research and their use of machine learning to predict the financial crisis. In 2012, co-founder of Sun Microsystems, Vinod Khosla, predicted that 80% of medical doctors' jobs would be lost in the next two decades to automated machine learning medical diagnostic software. In 2014, it was reported that a machine learning algorithm had been applied in the field of art history to study fine art paintings and that it may have revealed previously unrecognized influences among artists. In 2019 Springer Nature published the first research book created using machine learning. In 2020, machine learning technology was used to help make diagnoses and aid researchers in developing a cure for COVID-19. Machine learning is recently applied to predict the green behavior of human-being. Recently, machine learning technology is also applied to optimise smartphone's performance and thermal behaviour based on the user's interaction with the phone.","["" When did Netflix realize that viewers' ratings were not the best indicators of their viewing patterns?"", ' What did Netflix change their recommendation engine accordingly?', ' When did The Wall Street Journal write about the firm Rebellion Research?', ' What company uses machine learning to predict the financial crisis?', ' Who was the co-founder of Sun Microsystems in 2012?', "" What percentage of medical doctors' jobs would be lost in the next two decades due to automated machine learning?"", ' In what year was a machine learning algorithm used to study fine art paintings?', ' What was the name of the first research book created using machine learning?', ' In what year did Springer Nature publish the first research book created using machine learning?', ' In 2020, what was machine learning used to help make diagnoses and aid researchers in developing a cure for?', ' Machine learning is recently applied to predict what behavior of human-being?', ' What is the green behavior of human-being?', "" What is applied to optimise smartphone's performance and thermal behavior?""]","['Shortly after the prize was awarded', ""viewers' ratings were not the best indicators of their viewing patterns"", '2010', 'Rebellion Research', 'Vinod Khosla', '80%', '2014', 'Springer Nature', '2019', 'COVID-19', 'green', 'Machine learning', 'machine learning technology']","[0.9351906478404999, 0.304563008248806, 0.9475529491901398, 0.9933796525001526, 0.9943157732486725, 0.9673645198345184, 0.9668948352336884, 0.9664247035980225, 0.9875976145267487, 0.9002302289009094, 0.7844447493553162, 0.06600278243422508, 0.8381969928741455]"
13,machine learning,Model assessments,"Classification of machine learning models can be validated by accuracy estimation techniques like the holdout method, which splits the data in a training and test set (conventionally 2/3 training set and 1/3 test set designation) and evaluates the performance of the training model on the test set. In comparison, the K-fold-cross-validation method randomly partitions the data into K subsets and then K experiments are performed each respectively considering 1 subset for evaluation and the remaining K-1 subsets for training the model. In addition to the holdout and cross-validation methods, bootstrap, which samples n instances with replacement from the dataset, can be used to assess model accuracy.","Classification of machine learning models can be validated by accuracy estimation techniques like the holdout method, which splits the data in a training and test set (conventionally 2/3 training set and 1/3 test set designation) and evaluates the performance of the training model on the test set. In comparison, the K-fold-cross-validation method randomly partitions the data into K subsets and then K experiments are performed each respectively considering 1 subset for evaluation and the remaining K-1 subsets for training the model.","In addition to the holdout and cross-validation methods, bootstrap, which samples n instances with replacement from the dataset, can be used to assess model accuracy.","[' What can bootstrap be used to assess?', ' How many instances does bootstrap sample?']","['model accuracy', 'n']","[0.9899246394634247, 0.886672854423523]"
14,machine learning,Model assessments,"In addition to overall accuracy, investigators frequently report sensitivity and specificity meaning True Positive Rate (TPR) and True Negative Rate (TNR) respectively. Similarly, investigators sometimes report the false positive rate (FPR) as well as the false negative rate (FNR). However, these rates are ratios that fail to reveal their numerators and denominators. The total operating characteristic (TOC) is an effective method to express a model's diagnostic ability. TOC shows the numerators and denominators of the previously mentioned rates, thus TOC provides more information than the commonly used receiver operating characteristic (ROC) and ROC's associated area under the curve (AUC).","In addition to overall accuracy, investigators frequently report sensitivity and specificity meaning True Positive Rate (TPR) and True Negative Rate (TNR) respectively. Similarly, investigators sometimes report the false positive rate (FPR) as well as the false negative rate (FNR).","However, these rates are ratios that fail to reveal their numerators and denominators. The total operating characteristic (TOC) is an effective method to express a model's diagnostic ability. TOC shows the numerators and denominators of the previously mentioned rates, thus TOC provides more information than the commonly used receiver operating characteristic (ROC) and ROC's associated area under the curve (AUC).","["" What is an effective method to express a model's diagnostic ability?"", ' What does TOC show the numerators and denominators of?', "" What provides more information than the commonly used receiver operating characteristic (ROC) and ROC's associated area under the curve?""]","['The total operating characteristic', 'the previously mentioned rates', 'total operating characteristic']","[0.5672318637371063, 0.8237277269363403, 0.21118485182523727]"
15,machine learning,Ethics,"Machine learning poses a host of ethical questions. Systems which are trained on datasets collected with biases may exhibit these biases upon use (algorithmic bias), thus digitizing cultural prejudices. For example, in 1988, the UK's Commission for Racial Equality found that St. George's Medical School had been using a computer program trained from data of previous admissions staff and this program had denied nearly 60 candidates who were found to be either women or had non-European sounding names. Using job hiring data from a firm with racist hiring policies may lead to a machine learning system duplicating the bias by scoring job applicants by similarity to previous successful applicants. Responsible collection of data and documentation of algorithmic rules used by a system thus is a critical part of machine learning.
","Machine learning poses a host of ethical questions. Systems which are trained on datasets collected with biases may exhibit these biases upon use (algorithmic bias), thus digitizing cultural prejudices.","For example, in 1988, the UK's Commission for Racial Equality found that St. George's Medical School had been using a computer program trained from data of previous admissions staff and this program had denied nearly 60 candidates who were found to be either women or had non-European sounding names. Using job hiring data from a firm with racist hiring policies may lead to a machine learning system duplicating the bias by scoring job applicants by similarity to previous successful applicants. Responsible collection of data and documentation of algorithmic rules used by a system thus is a critical part of machine learning.","["" What year did the UK's Commission for Racial Equality find that St. George's Medical School had been using a computer program?"", ' How many candidates were denied by the computer program that was trained from data of previous admissions staff?', ' What type of names were used?', ' What may lead to a machine learning system duplicating the bias?', ' How are job applicants scored?', ' What is a critical part of machine learning?', ' What is responsible collection of data and documentation of?']","['1988', 'nearly 60', 'non-European sounding names', 'Using job hiring data from a firm with racist hiring policies', 'similarity to previous successful applicants', 'Responsible collection of data and documentation of algorithmic rules', 'algorithmic rules']","[0.9878466427326202, 0.7855466306209564, 0.17669279873371124, 0.8481221199035645, 0.7286947965621948, 0.6595415025949478, 0.8913416564464569]"
16,machine learning,Ethics,"AI can be well-equipped to make decisions in technical fields, which rely heavily on data and historical information. These decisions rely on objectivity and logical reasoning. Because human languages contain biases, machines trained on language corpora will necessarily also learn these biases.","AI can be well-equipped to make decisions in technical fields, which rely heavily on data and historical information. These decisions rely on objectivity and logical reasoning.","Because human languages contain biases, machines trained on language corpora will necessarily also learn these biases.","[' Why do human languages contain biases?', ' Machines trained on language corpora will learn what?']","['machines trained on language corpora will necessarily also learn these biases', 'biases']","[0.3158797025680542, 0.516608938574791]"
17,machine learning,Ethics,"Other forms of ethical challenges, not related to personal biases, are seen in health care. There are concerns among health care professionals that these systems might not be designed in the public's interest but as income-generating machines. This is especially true in the United States where there is a long-standing ethical dilemma of improving health care, but also increasing profits. For example, the algorithms could be designed to provide patients with unnecessary tests or medication in which the algorithm's proprietary owners hold stakes. There is  potential for machine learning in health care to provide professionals an additional tool to diagnose, medicate, and plan recovery paths for patients, but this requires these biases to be mitigated.","Other forms of ethical challenges, not related to personal biases, are seen in health care. There are concerns among health care professionals that these systems might not be designed in the public's interest but as income-generating machines.","This is especially true in the United States where there is a long-standing ethical dilemma of improving health care, but also increasing profits. For example, the algorithms could be designed to provide patients with unnecessary tests or medication in which the algorithm's proprietary owners hold stakes. There is  potential for machine learning in health care to provide professionals an additional tool to diagnose, medicate, and plan recovery paths for patients, but this requires these biases to be mitigated.","[' Where is there a long-standing ethical dilemma of improving health care but also increasing profits?', ' What could algorithms be designed to provide patients with?', ' What do the proprietary owners of the algorithm hold stakes in?', ' There is potential for machine learning in health care to provide what?']","['the United States', 'unnecessary tests or medication', 'unnecessary tests or medication', 'professionals an additional tool to diagnose, medicate, and plan recovery paths for patients']","[0.8110209405422211, 0.924702376127243, 0.7524944841861725, 0.5451114773750305]"
18,machine learning,Hardware,"Since the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks (a particular narrow subdomain of machine learning) that contain many layers of non-linear hidden units. By 2019, graphic processing units (GPUs), often with AI-specific enhancements, had displaced CPUs as the dominant method of training large-scale commercial cloud AI. OpenAI estimated the hardware compute used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017), and found a 300,000-fold increase in the amount of compute required, with a doubling-time trendline of 3.4 months.","Since the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks (a particular narrow subdomain of machine learning) that contain many layers of non-linear hidden units. By 2019, graphic processing units (GPUs), often with AI-specific enhancements, had displaced CPUs as the dominant method of training large-scale commercial cloud AI.","OpenAI estimated the hardware compute used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017), and found a 300,000-fold increase in the amount of compute required, with a doubling-time trendline of 3.4 months.","[' OpenAI estimated the hardware compute used in the largest deep learning projects from AlexNet (2012) to what?', ' OpenAI found a 300,000-fold increase in the amount of compute required, with a doubling-time trendline of how long?']","['AlphaZero', '3.4 months']","[0.7128137648105621, 0.8791193962097168]"
19,genetic algorithm,Summary,"In computer science and operations research, a genetic algorithm (GA) is a metaheuristic inspired by the process of natural selection that belongs to the larger class of evolutionary algorithms (EA). Genetic algorithms are commonly used to generate high-quality solutions to optimization and search problems by relying on biologically inspired operators such as mutation, crossover and selection. Some examples of GA applications include optimizing decision trees for better performance, automatically solve sudoku puzzles, hyperparameter optimization, etc.
","In computer science and operations research, a genetic algorithm (GA) is a metaheuristic inspired by the process of natural selection that belongs to the larger class of evolutionary algorithms (EA). Genetic algorithms are commonly used to generate high-quality solutions to optimization and search problems by relying on biologically inspired operators such as mutation, crossover and selection.","Some examples of GA applications include optimizing decision trees for better performance, automatically solve sudoku puzzles, hyperparameter optimization, etc.","[' What are some examples of GA applications?', ' What is an example of a GA application?']","['optimizing decision trees for better performance, automatically solve sudoku puzzles, hyperparameter optimization', 'optimizing decision trees for better performance, automatically solve sudoku puzzles']","[0.7607408165931702, 0.477945014834404]"
20,genetic algorithm,The building block hypothesis,"Genetic algorithms are simple to implement, but their behavior is difficult to understand. In particular, it is difficult to understand why these algorithms frequently succeed at generating solutions of high fitness when applied to practical problems. The building block hypothesis (BBH) consists of:
","Genetic algorithms are simple to implement, but their behavior is difficult to understand. In particular, it is difficult to understand why these algorithms frequently succeed at generating solutions of high fitness when applied to practical problems.",The building block hypothesis (BBH) consists of:,[' What is the building block hypothesis?'],['BBH'],[0.3928694576025009]
21,genetic algorithm,The building block hypothesis,"Despite the lack of consensus regarding the validity of the building-block hypothesis, it has been consistently evaluated and used as reference throughout the years. Many estimation of distribution algorithms, for example, have been proposed in an attempt to provide an environment in which the hypothesis would hold. Although good results have been reported for some classes of problems, skepticism concerning the generality and/or practicality of the building-block hypothesis as an explanation for GAs efficiency still remains. Indeed, there is a reasonable amount of work that attempts to understand its limitations from the perspective of estimation of distribution algorithms.","Despite the lack of consensus regarding the validity of the building-block hypothesis, it has been consistently evaluated and used as reference throughout the years. Many estimation of distribution algorithms, for example, have been proposed in an attempt to provide an environment in which the hypothesis would hold.","Although good results have been reported for some classes of problems, skepticism concerning the generality and/or practicality of the building-block hypothesis as an explanation for GAs efficiency still remains. Indeed, there is a reasonable amount of work that attempts to understand its limitations from the perspective of estimation of distribution algorithms.","[' What has been reported for some classes of problems?', ' What is skepticism regarding the generality and/or practicality of the building-block hypothesis as an explanation for GAs efficiency?', ' From the perspective of estimation of distribution algorithms, understand its limitations from what perspective?']","['good results', 'still remains', 'building-block hypothesis']","[0.9711193144321442, 0.4861859008669853, 0.14923787862062454]"
22,genetic algorithm,Problem domains,"Problems which appear to be particularly appropriate for solution by genetic algorithms include timetabling and scheduling problems, and many scheduling software packages are based on GAs. GAs have also been applied to engineering. Genetic algorithms are often applied as an approach to solve global optimization problems.
","Problems which appear to be particularly appropriate for solution by genetic algorithms include timetabling and scheduling problems, and many scheduling software packages are based on GAs. GAs have also been applied to engineering.",Genetic algorithms are often applied as an approach to solve global optimization problems.,[' Genetic algorithms are often applied as an approach to solve what?'],['global optimization problems'],[0.8928320705890656]
23,genetic algorithm,Problem domains,"As a general rule of thumb genetic algorithms might be useful in problem domains that have a complex fitness landscape as mixing, i.e., mutation in combination with crossover, is designed to move the population away from local optima that a traditional hill climbing algorithm might get stuck in. Observe that commonly used crossover operators cannot change any uniform population. Mutation alone can provide ergodicity of the overall genetic algorithm process (seen as a Markov chain).
","As a general rule of thumb genetic algorithms might be useful in problem domains that have a complex fitness landscape as mixing, i.e., mutation in combination with crossover, is designed to move the population away from local optima that a traditional hill climbing algorithm might get stuck in. Observe that commonly used crossover operators cannot change any uniform population.",Mutation alone can provide ergodicity of the overall genetic algorithm process (seen as a Markov chain).,"[' What can provide ergodicity of the overall genetic algorithm process?', ' What can be seen as a Markov chain?']","['Mutation', 'Mutation alone can provide ergodicity of the overall genetic algorithm process']","[0.7512477338314056, 0.5757484287023544]"
24,genetic algorithm,Problem domains,"[I]t is quite unnatural to model applications in terms of genetic operators like mutation and crossover on bit strings. The pseudobiology adds another level of complexity between you and your problem. Second, genetic algorithms take a very long time on nontrivial problems. [...] [T]he analogy with evolution—where significant progress require [sic] millions of years—can be quite appropriate.
",[I]t is quite unnatural to model applications in terms of genetic operators like mutation and crossover on bit strings. The pseudobiology adds another level of complexity between you and your problem.,"Second, genetic algorithms take a very long time on nontrivial problems. [...] [T]he analogy with evolution—where significant progress require [sic] millions of years—can be quite appropriate.","[' How long do genetic algorithms take on nontrivial problems?', ' What is an analogy with evolution?', ' How long does significant progress require?']","['very long time', 'significant progress require [sic] millions of years', 'millions of years']","[0.6769793629646301, 0.6107938289642334, 0.7856189906597137]"
25,genetic algorithm,Problem domains,"
I have never encountered any problem where genetic algorithms seemed to me the right way to attack it. Further, I have never seen any computational results reported using genetic algorithms that have favorably impressed me. Stick to simulated annealing for your heuristic search voodoo needs.","
I have never encountered any problem where genetic algorithms seemed to me the right way to attack it. Further, I have never seen any computational results reported using genetic algorithms that have favorably impressed me.",Stick to simulated annealing for your heuristic search voodoo needs.,[' What type of annealing is best for your heuristic search voodoo needs?'],['simulated'],[0.9165331721305847]
26,genetic algorithm,History,"In 1950, Alan Turing proposed a ""learning machine"" which would parallel the principles of evolution. Computer simulation of evolution started as early as in 1954 with the work of Nils Aall Barricelli, who was using the computer at the Institute for Advanced Study in Princeton, New Jersey. His 1954 publication was not widely noticed. Starting in 1957, the Australian quantitative geneticist Alex Fraser published a series of papers on simulation of artificial selection of organisms with multiple loci controlling a measurable trait. From these beginnings, computer simulation of evolution by biologists became more common in the early 1960s, and the methods were described in books by Fraser and Burnell (1970) and Crosby (1973). Fraser's simulations included all of the essential elements of modern genetic algorithms. In addition, Hans-Joachim Bremermann published a series of papers in the 1960s that also adopted a population of solution to optimization problems, undergoing recombination, mutation, and selection. Bremermann's research also included the elements of modern genetic algorithms. Other noteworthy early pioneers include Richard Friedberg, George Friedman, and Michael Conrad. Many early papers are reprinted by Fogel (1998).","In 1950, Alan Turing proposed a ""learning machine"" which would parallel the principles of evolution. Computer simulation of evolution started as early as in 1954 with the work of Nils Aall Barricelli, who was using the computer at the Institute for Advanced Study in Princeton, New Jersey.","His 1954 publication was not widely noticed. Starting in 1957, the Australian quantitative geneticist Alex Fraser published a series of papers on simulation of artificial selection of organisms with multiple loci controlling a measurable trait. From these beginnings, computer simulation of evolution by biologists became more common in the early 1960s, and the methods were described in books by Fraser and Burnell (1970) and Crosby (1973). Fraser's simulations included all of the essential elements of modern genetic algorithms. In addition, Hans-Joachim Bremermann published a series of papers in the 1960s that also adopted a population of solution to optimization problems, undergoing recombination, mutation, and selection. Bremermann's research also included the elements of modern genetic algorithms. Other noteworthy early pioneers include Richard Friedberg, George Friedman, and Michael Conrad. Many early papers are reprinted by Fogel (1998).","[' What year did Alex Fraser publish a series of papers on simulation of artificial selection of organisms with multiple loci controlling a measurable trait?', ' Computer simulation of evolution by biologists became more common in the early years of what?', ' When did biologists become more common?', ' Who published a series of papers in the 1960s?', ' What did Hans-Joachim Bremermann publish?', ' Hans-Joachim Bremermann published a series of papers in what decade?', "" What did Bremerman's research include?"", ' Richard Friedberg, George Friedman, and Michael Conrad are notable early pioneers of what?', ' Richard Friedberg, George Friedman, and Michael Conrad.', ' Fogel reprinted many early papers in what year?']","['1957', '1960s', 'early 1960s', 'Hans-Joachim Bremermann', 'a series of papers in the 1960s that also adopted a population of solution to optimization problems', '1960s', 'the elements of modern genetic algorithms', 'modern genetic algorithms', 'early pioneers', '1998']","[0.9931770265102386, 0.7424228191375732, 0.5824522376060486, 0.9416245520114899, 0.1291828490793705, 0.8443979322910309, 0.6799626052379608, 0.06632784754037857, 0.001264191057998687, 0.9594751298427582]"
27,genetic algorithm,History,"Although Barricelli, in work he reported in 1963, had simulated the evolution of ability to play a simple game, artificial evolution only became a widely recognized optimization method as a result of the work of Ingo Rechenberg and Hans-Paul Schwefel in the 1960s and early 1970s – Rechenberg's group was able to solve complex engineering problems through evolution strategies. Another approach was the evolutionary programming technique of Lawrence J. Fogel, which was proposed for generating artificial intelligence. Evolutionary programming originally used finite state machines for predicting environments, and used variation and selection to optimize the predictive logics. Genetic algorithms in particular became popular through the work of John Holland in the early 1970s, and particularly his book Adaptation in Natural and Artificial Systems (1975). His work originated with studies of cellular automata, conducted by Holland and his students at the University of Michigan. Holland introduced a formalized framework for predicting the quality of the next generation, known as Holland's Schema Theorem. Research in GAs remained largely theoretical until the mid-1980s, when The First International Conference on Genetic Algorithms was held in Pittsburgh, Pennsylvania.
","Although Barricelli, in work he reported in 1963, had simulated the evolution of ability to play a simple game, artificial evolution only became a widely recognized optimization method as a result of the work of Ingo Rechenberg and Hans-Paul Schwefel in the 1960s and early 1970s – Rechenberg's group was able to solve complex engineering problems through evolution strategies. Another approach was the evolutionary programming technique of Lawrence J. Fogel, which was proposed for generating artificial intelligence.","Evolutionary programming originally used finite state machines for predicting environments, and used variation and selection to optimize the predictive logics. Genetic algorithms in particular became popular through the work of John Holland in the early 1970s, and particularly his book Adaptation in Natural and Artificial Systems (1975). His work originated with studies of cellular automata, conducted by Holland and his students at the University of Michigan. Holland introduced a formalized framework for predicting the quality of the next generation, known as Holland's Schema Theorem. Research in GAs remained largely theoretical until the mid-1980s, when The First International Conference on Genetic Algorithms was held in Pittsburgh, Pennsylvania.","[' What did evolutionary programming originally use for predicting environments?', ' What did variation and selection do to optimize the predictive logics?', ' Who wrote Adaptation in Natural and Artificial Systems?', ' In what year was Adaptation in Natural and Artificial Systems published?', ' What was the name of the formal framework for predicting the quality of the next generation introduced by Holland?', ' How did research in GAs remain?', "" What is Holland's Schema Theorem?"", ' When was the First International Conference on Genetic Algorithms held?']","['finite state machines', 'Evolutionary programming', 'John Holland', '1975', ""Holland's Schema Theorem"", 'largely theoretical', 'formalized framework for predicting the quality of the next generation', 'mid-1980s']","[0.9955473244190216, 0.21714797616004944, 0.9731382429599762, 0.992934376001358, 0.9693865478038788, 0.6426965445280075, 0.5908822417259216, 0.6013288646936417]"
28,classification,Summary,"Classification is a process related to categorization, the process in which ideas and objects are recognized, differentiated and understood. 
Classification is the grouping of related facts into classes. 
It may also refer to:
","Classification is a process related to categorization, the process in which ideas and objects are recognized, differentiated and understood. Classification is the grouping of related facts into classes.",It may also refer to:,"[' What does it refer to?', ' What is another name for it?']","[':', 'It may also refer to:']","[0.012063443486113101, 0.0030379142554011196]"
29,deep learning,Summary,"Artificial neural networks (ANNs) were inspired by information processing and distributed communication nodes in biological systems. ANNs have various differences from biological brains.  Specifically, artificial neural networks tend to be static and symbolic, while the biological brain of most living organisms is dynamic (plastic) and analogue.",Artificial neural networks (ANNs) were inspired by information processing and distributed communication nodes in biological systems. ANNs have various differences from biological brains.,"Specifically, artificial neural networks tend to be static and symbolic, while the biological brain of most living organisms is dynamic (plastic) and analogue.","[' Artificial neural networks tend to be what?', ' What is the biological brain of most living organisms?']","['static and symbolic', 'dynamic (plastic) and analogue']","[0.98497074842453, 0.8937408626079559]"
30,deep learning,Summary,"The adjective ""deep"" in deep learning refers to the use of multiple layers in the network. Early work showed that a linear perceptron cannot be a universal classifier, but that a network with a nonpolynomial activation function with one hidden layer of unbounded width can. Deep learning is a modern variation which is concerned with an unbounded number of layers of bounded size, which permits practical application and optimized implementation, while retaining theoretical universality under mild conditions. In deep learning the layers are also permitted to be heterogeneous and to deviate widely from biologically informed connectionist models, for the sake of efficiency, trainability and understandability, whence the ""structured"" part.
","The adjective ""deep"" in deep learning refers to the use of multiple layers in the network. Early work showed that a linear perceptron cannot be a universal classifier, but that a network with a nonpolynomial activation function with one hidden layer of unbounded width can.","Deep learning is a modern variation which is concerned with an unbounded number of layers of bounded size, which permits practical application and optimized implementation, while retaining theoretical universality under mild conditions. In deep learning the layers are also permitted to be heterogeneous and to deviate widely from biologically informed connectionist models, for the sake of efficiency, trainability and understandability, whence the ""structured"" part.","[' Deep learning is concerned with an unbounded number of layers of what size?', ' Deep learning permits practical application and optimized implementation under what conditions?', ' In deep learning layers are permitted to be what?', ' To be heterogeneous and to deviate widely from biologically informed connectionist models, for the sake of efficiency, trainability and understandability, what is the ""structured"" part?']","['bounded', 'mild', 'heterogeneous', 'Deep learning']","[0.7629088163375854, 0.7245811820030212, 0.9868050515651703, 0.36595703661441803]"
31,deep learning,Overview,"In deep learning, each level learns to transform its input data into a slightly more abstract and composite representation. In an image recognition application, the raw input may be a matrix of pixels; the first representational layer may abstract the pixels and encode edges; the second layer may compose and encode arrangements of edges; the third layer may encode a nose and eyes; and the fourth layer may recognize that the image contains a face. Importantly, a deep learning process can learn which features to optimally place in which level on its own. This does not eliminate the need for hand-tuning; for example, varying numbers of layers and layer sizes can provide different degrees of abstraction.","In deep learning, each level learns to transform its input data into a slightly more abstract and composite representation. In an image recognition application, the raw input may be a matrix of pixels; the first representational layer may abstract the pixels and encode edges; the second layer may compose and encode arrangements of edges; the third layer may encode a nose and eyes; and the fourth layer may recognize that the image contains a face.","Importantly, a deep learning process can learn which features to optimally place in which level on its own. This does not eliminate the need for hand-tuning; for example, varying numbers of layers and layer sizes can provide different degrees of abstraction.","[' What can a deep learning process learn on its own?', ' What does not eliminate the need for hand-tuning?', ' Various numbers of layers and what can provide different degrees of abstraction?']","['which features to optimally place in which level', 'a deep learning process can learn which features to optimally place in which level on its own', 'layer sizes']","[0.8525896668434143, 0.46509118378162384, 0.13695607334375381]"
32,deep learning,Overview,"The word ""deep"" in ""deep learning"" refers to the number of layers through which the data is transformed. More precisely, deep learning systems have a substantial credit assignment path (CAP) depth. The CAP is the chain of transformations from input to output. CAPs describe potentially causal connections between input and output. For a feedforward neural network, the depth of the CAPs is that of the network and is the number of hidden layers plus one (as the output layer is also parameterized). For recurrent neural networks, in which a signal may propagate through a layer more than once, the CAP depth is potentially unlimited. No universally agreed-upon threshold of depth divides shallow learning from deep learning, but most researchers agree that deep learning involves CAP depth higher than 2. CAP of depth 2 has been shown to be a universal approximator in the sense that it can emulate any function. Beyond that, more layers do not add to the function approximator ability of the network. Deep models (CAP > 2) are able to extract better features than shallow models and hence, extra layers help in learning the features effectively.
","The word ""deep"" in ""deep learning"" refers to the number of layers through which the data is transformed. More precisely, deep learning systems have a substantial credit assignment path (CAP) depth.","The CAP is the chain of transformations from input to output. CAPs describe potentially causal connections between input and output. For a feedforward neural network, the depth of the CAPs is that of the network and is the number of hidden layers plus one (as the output layer is also parameterized). For recurrent neural networks, in which a signal may propagate through a layer more than once, the CAP depth is potentially unlimited. No universally agreed-upon threshold of depth divides shallow learning from deep learning, but most researchers agree that deep learning involves CAP depth higher than 2. CAP of depth 2 has been shown to be a universal approximator in the sense that it can emulate any function. Beyond that, more layers do not add to the function approximator ability of the network. Deep models (CAP > 2) are able to extract better features than shallow models and hence, extra layers help in learning the features effectively.","[' What is the chain of transformations from input to output called?', ' What describe potentially causal connections between input and output?', ' For a feedforward neural network, what is the depth of the CAPs?', ' How many hidden layers plus one?', ' What is the CAP depth for recurrent neural networks?', ' How many layers can a signal propagate through a layer multiple times?', ' How deep learning differs from shallow learning?', ' What does deep learning involve?', ' CAP of depth 2 has been shown to be what?', ' What does more layers not add to the function approximator ability of the network?', ' Deep models (CAP > 2) are able to extract better features than what?']","['CAP', 'CAPs', 'that of the network', 'number', 'potentially unlimited', 'unlimited', 'No universally agreed-upon threshold of depth', 'CAP depth higher than 2', 'a universal approximator', 'CAP of depth 2 has been shown to be a universal approximator in the sense that it can emulate any function. Beyond that, more layers do not add to the function approximator ability of the network. Deep models', 'shallow models']","[0.7621026337146759, 0.9924413561820984, 0.7630040347576141, 0.02704060822725296, 0.7057681232690811, 0.08458741754293442, 0.2987724542617798, 0.8587840795516968, 0.7571941018104553, 0.017588227055966854, 0.9845839440822601]"
33,deep learning,Overview,Deep learning algorithms can be applied to unsupervised learning tasks. This is an important benefit because unlabeled data are more abundant than the labeled data. Examples of deep structures that can be trained in an unsupervised manner are neural history compressors and deep belief networks.,Deep learning algorithms can be applied to unsupervised learning tasks. This is an important benefit because unlabeled data are more abundant than the labeled data.,Examples of deep structures that can be trained in an unsupervised manner are neural history compressors and deep belief networks.,[' What are two examples of deep structures that can be trained in an unsupervised manner?'],['neural history compressors and deep belief networks'],[0.9672127664089203]
34,deep learning,Interpretations,"The classic universal approximation theorem concerns the capacity of feedforward neural networks with a single hidden layer of finite size to approximate continuous functions. In 1989, the first proof was published by George Cybenko for sigmoid activation functions and was generalised to feed-forward multi-layer architectures in 1991 by Kurt Hornik. Recent work also showed that universal approximation also holds for non-bounded activation functions such as the rectified linear unit.","The classic universal approximation theorem concerns the capacity of feedforward neural networks with a single hidden layer of finite size to approximate continuous functions. In 1989, the first proof was published by George Cybenko for sigmoid activation functions and was generalised to feed-forward multi-layer architectures in 1991 by Kurt Hornik.",Recent work also showed that universal approximation also holds for non-bounded activation functions such as the rectified linear unit.,[' What does universal approximation hold for non-bounded activation functions like the rectified linear unit?'],['universal'],[0.0531459990888834]
35,deep learning,Interpretations,"The universal approximation theorem for deep neural networks concerns the capacity of networks with bounded width but the depth is allowed to grow. Lu et al. proved that if the width of a deep neural network with ReLU activation is strictly larger than the input dimension, then the network can approximate any Lebesgue integrable function; If the width is smaller or equal to the input dimension, then a deep neural network is not a universal approximator.
",The universal approximation theorem for deep neural networks concerns the capacity of networks with bounded width but the depth is allowed to grow. Lu et al.,"proved that if the width of a deep neural network with ReLU activation is strictly larger than the input dimension, then the network can approximate any Lebesgue integrable function; If the width is smaller or equal to the input dimension, then a deep neural network is not a universal approximator.","[' If the width of a deep neural network with ReLU activation is strictly larger than the input dimension, then the network can approximate any Lebesgue integrable function.', ' What is not a universal approximator?']","['proved that if the width of a deep neural network with ReLU activation is strictly larger than the input dimension, then the network can approximate any Lebesgue integrable function; If the width is smaller or equal to the input dimension, then a deep neural network is not a universal approximator', 'deep neural network']","[0.012293063569813967, 0.6538759171962738]"
36,deep learning,Interpretations,"The probabilistic interpretation derives from the field of machine learning. It features inference, as well as the optimization concepts of training and testing, related to fitting and generalization, respectively. More specifically, the probabilistic interpretation considers the activation nonlinearity as a cumulative distribution function. The probabilistic interpretation led to the introduction of dropout as regularizer in neural networks. The probabilistic interpretation was introduced by researchers including Hopfield, Widrow and Narendra and popularized in surveys such as the one by Bishop.","The probabilistic interpretation derives from the field of machine learning. It features inference, as well as the optimization concepts of training and testing, related to fitting and generalization, respectively.","More specifically, the probabilistic interpretation considers the activation nonlinearity as a cumulative distribution function. The probabilistic interpretation led to the introduction of dropout as regularizer in neural networks. The probabilistic interpretation was introduced by researchers including Hopfield, Widrow and Narendra and popularized in surveys such as the one by Bishop.","[' What does the probabilistic interpretation consider the activation nonlinearity as?', ' What led to the introduction of dropout as regularizer in neural networks?', ' Who introduced the probabilityistic interpretation?']","['a cumulative distribution function', 'probabilistic interpretation', 'Hopfield, Widrow and Narendra']","[0.8551572561264038, 0.5678679496049881, 0.005553317489102483]"
37,deep learning,History,"The first general, working learning algorithm for supervised, deep, feedforward, multilayer perceptrons was published by Alexey Ivakhnenko and Lapa in 1967. A 1971 paper described a deep network with eight layers trained by the group method of data handling. Other deep learning working architectures, specifically those built for computer vision, began with the Neocognitron introduced by Kunihiko Fukushima in 1980.","The first general, working learning algorithm for supervised, deep, feedforward, multilayer perceptrons was published by Alexey Ivakhnenko and Lapa in 1967. A 1971 paper described a deep network with eight layers trained by the group method of data handling.","Other deep learning working architectures, specifically those built for computer vision, began with the Neocognitron introduced by Kunihiko Fukushima in 1980.","[' What did Kunihiko Fukushima introduce in 1980?', ' What was the Neocognitron?']","['Neocognitron', 'deep learning working architectures']","[0.820796936750412, 0.6201522052288055]"
38,deep learning,History,"In 1989, Yann LeCun et al. applied the standard backpropagation algorithm, which had been around as the reverse mode of automatic differentiation since 1970, to a deep neural network with the purpose of recognizing handwritten ZIP codes on mail. While the algorithm worked, training required 3 days.","In 1989, Yann LeCun et al. applied the standard backpropagation algorithm, which had been around as the reverse mode of automatic differentiation since 1970, to a deep neural network with the purpose of recognizing handwritten ZIP codes on mail.","While the algorithm worked, training required 3 days.",[' How long did it take to train the algorithm?'],['3 days'],[0.9575519263744354]
39,deep learning,History,"Both shallow and deep learning (e.g., recurrent nets) of ANNs have been explored for many years. These methods never outperformed non-uniform internal-handcrafting Gaussian mixture model/Hidden Markov model (GMM-HMM) technology based on generative models of speech trained discriminatively. Key difficulties have been analyzed, including gradient diminishing and weak temporal correlation structure in neural predictive models. Additional difficulties were the lack of training data and limited computing power.
","Both shallow and deep learning (e.g., recurrent nets) of ANNs have been explored for many years. These methods never outperformed non-uniform internal-handcrafting Gaussian mixture model/Hidden Markov model (GMM-HMM) technology based on generative models of speech trained discriminatively.","Key difficulties have been analyzed, including gradient diminishing and weak temporal correlation structure in neural predictive models. Additional difficulties were the lack of training data and limited computing power.","[' Key difficulties have been analyzed, including what?', ' Other difficulties were the lack of training data and limited computing power?']","['gradient diminishing and weak temporal correlation structure in neural predictive models', 'gradient diminishing and weak temporal correlation structure in neural predictive models']","[0.7644780278205872, 0.04171569272875786]"
40,deep learning,History,"Most speech recognition researchers moved away from neural nets to pursue generative modeling. An exception was at SRI International in the late 1990s. Funded by the US government's NSA and DARPA, SRI studied deep neural networks in speech and speaker recognition. The speaker recognition team led by Larry Heck reported significant success with deep neural networks in speech processing in the 1998 National Institute of Standards and Technology Speaker Recognition evaluation. The SRI deep neural network was then deployed in the Nuance Verifier, representing the first major industrial application of deep learning.",Most speech recognition researchers moved away from neural nets to pursue generative modeling. An exception was at SRI International in the late 1990s.,"Funded by the US government's NSA and DARPA, SRI studied deep neural networks in speech and speaker recognition. The speaker recognition team led by Larry Heck reported significant success with deep neural networks in speech processing in the 1998 National Institute of Standards and Technology Speaker Recognition evaluation. The SRI deep neural network was then deployed in the Nuance Verifier, representing the first major industrial application of deep learning.","[' Who funded the SRI?', ' Who led the speaker recognition team?', ' What did Larry Heck report in 1998?', ' What did the Institute of Standards and Technology evaluate?', ' What was the first industrial application of deep learning?']","['NSA and DARPA', 'Larry Heck', 'significant success with deep neural networks in speech processing', 'Speaker Recognition', 'Nuance Verifier']","[0.7611788213253021, 0.9975644648075104, 0.4619184732437134, 0.7021861374378204, 0.8771668970584869]"
41,deep learning,History,"Many aspects of speech recognition were taken over by a deep learning method called long short-term memory (LSTM), a recurrent neural network published by Hochreiter and Schmidhuber in 1997. LSTM RNNs avoid the vanishing gradient problem and can learn ""Very Deep Learning"" tasks that require memories of events that happened thousands of discrete time steps before, which is important for speech. In 2003, LSTM started to become competitive with traditional speech recognizers on certain tasks. Later it was combined with connectionist temporal classification (CTC) in stacks of LSTM RNNs. In 2015, Google's speech recognition reportedly experienced a dramatic performance jump of 49% through CTC-trained LSTM, which they made available through Google Voice Search.","Many aspects of speech recognition were taken over by a deep learning method called long short-term memory (LSTM), a recurrent neural network published by Hochreiter and Schmidhuber in 1997. LSTM RNNs avoid the vanishing gradient problem and can learn ""Very Deep Learning"" tasks that require memories of events that happened thousands of discrete time steps before, which is important for speech.","In 2003, LSTM started to become competitive with traditional speech recognizers on certain tasks. Later it was combined with connectionist temporal classification (CTC) in stacks of LSTM RNNs. In 2015, Google's speech recognition reportedly experienced a dramatic performance jump of 49% through CTC-trained LSTM, which they made available through Google Voice Search.","[' In what year did LSTM start to become competitive with traditional speech recognizers?', ' What was combined with connectionist temporal classification (CTC)?', "" In 2015, how much did Google's speech recognition experience a performance jump?"", ' What percentage of the respondents were trained in LSTM?', ' What did Google Voice Search make available to the public?']","['2003', 'LSTM', '49%', '49%', 'speech recognition']","[0.9866991937160492, 0.9410401284694672, 0.9943341016769409, 0.4168694168329239, 0.11228388547897339]"
42,deep learning,History,"Deep learning is part of state-of-the-art systems in various disciplines, particularly computer vision and automatic speech recognition (ASR). Results on commonly used evaluation sets such as TIMIT (ASR) and MNIST (image classification), as well as a range of large-vocabulary speech recognition tasks have steadily improved. Convolutional neural networks (CNNs) were superseded for ASR by CTC for LSTM. but are more successful in computer vision.
","Deep learning is part of state-of-the-art systems in various disciplines, particularly computer vision and automatic speech recognition (ASR). Results on commonly used evaluation sets such as TIMIT (ASR) and MNIST (image classification), as well as a range of large-vocabulary speech recognition tasks have steadily improved.",Convolutional neural networks (CNNs) were superseded for ASR by CTC for LSTM. but are more successful in computer vision.,"[' What was superseded for ASR by CTC for LSTM?', ' What are more successful in computer vision?']","['Convolutional neural networks', 'Convolutional neural networks']","[0.5993986129760742, 0.7909227013587952]"
43,deep learning,History,"The 2009 NIPS Workshop on Deep Learning for Speech Recognition was motivated by the limitations of deep generative models of speech, and the possibility that given more capable hardware and large-scale data sets that deep neural nets (DNN) might become practical. It was believed that pre-training DNNs using generative models of deep belief nets (DBN) would overcome the main difficulties of neural nets. However, it was discovered that replacing pre-training with large amounts of training data for straightforward backpropagation when using DNNs with large, context-dependent output layers produced error rates dramatically lower than then-state-of-the-art Gaussian mixture model (GMM)/Hidden Markov Model (HMM) and also than more-advanced generative model-based systems. The nature of the recognition errors produced by the two types of systems was characteristically different, offering technical insights into how to integrate deep learning into the existing highly efficient, run-time speech decoding system deployed by all major speech recognition systems. Analysis around 2009–2010, contrasting the GMM (and other generative speech models) vs. DNN models, stimulated early industrial investment in deep learning for speech recognition, eventually leading to pervasive and dominant use in that industry. That analysis was done with comparable performance (less than 1.5% in error rate) between discriminative DNNs and generative models.","The 2009 NIPS Workshop on Deep Learning for Speech Recognition was motivated by the limitations of deep generative models of speech, and the possibility that given more capable hardware and large-scale data sets that deep neural nets (DNN) might become practical. It was believed that pre-training DNNs using generative models of deep belief nets (DBN) would overcome the main difficulties of neural nets.","However, it was discovered that replacing pre-training with large amounts of training data for straightforward backpropagation when using DNNs with large, context-dependent output layers produced error rates dramatically lower than then-state-of-the-art Gaussian mixture model (GMM)/Hidden Markov Model (HMM) and also than more-advanced generative model-based systems. The nature of the recognition errors produced by the two types of systems was characteristically different, offering technical insights into how to integrate deep learning into the existing highly efficient, run-time speech decoding system deployed by all major speech recognition systems. Analysis around 2009–2010, contrasting the GMM (and other generative speech models) vs. DNN models, stimulated early industrial investment in deep learning for speech recognition, eventually leading to pervasive and dominant use in that industry. That analysis was done with comparable performance (less than 1.5% in error rate) between discriminative DNNs and generative models.","[' What did the DNNs with large, context-dependent output layers produce?', ' What were error rates lower than than the then-state-of-the-art GMM/HMM?', ' What did the two types of systems produce that was characteristically different?', ' What did deep learning offer technical insights into?', ' When was the analysis contrasting?', ' What was the performance of the GMM model compared to the DNN model?', ' What did the early industrial investment in deep learning lead to?', ' What was the error rate between discriminative DNNs and generative models?']","['error rates dramatically lower', 'replacing pre-training with large amounts of training data for straightforward backpropagation when using DNNs with large, context-dependent output layers', 'recognition errors', 'how to integrate deep learning into the existing highly efficient, run-time speech decoding system deployed by all major speech recognition systems', 'around 2009–2010', 'less than 1.5% in error rate', 'pervasive and dominant use', 'less than 1.5%']","[0.7382999062538147, 0.17216164618730545, 0.937615305185318, 0.13677194714546204, 0.3934070020914078, 0.5801672339439392, 0.7157061845064163, 0.6921106576919556]"
44,deep learning,History,"Advances in hardware have driven renewed interest in deep learning. In 2009, Nvidia was involved in what was called the “big bang” of deep learning, “as deep-learning neural networks were trained with Nvidia graphics processing units (GPUs).” That year, Andrew Ng determined that GPUs could increase the speed of deep-learning systems by about 100 times. In particular, GPUs are well-suited for the matrix/vector computations involved in machine learning. GPUs speed up training algorithms by orders of magnitude, reducing running times from weeks to days. Further, specialized hardware and algorithm optimizations can be used for efficient processing of deep learning models.","Advances in hardware have driven renewed interest in deep learning. In 2009, Nvidia was involved in what was called the “big bang” of deep learning, “as deep-learning neural networks were trained with Nvidia graphics processing units (GPUs).” That year, Andrew Ng determined that GPUs could increase the speed of deep-learning systems by about 100 times.","In particular, GPUs are well-suited for the matrix/vector computations involved in machine learning. GPUs speed up training algorithms by orders of magnitude, reducing running times from weeks to days. Further, specialized hardware and algorithm optimizations can be used for efficient processing of deep learning models.","[' What kind of computations are GPUs well suited for?', ' What can GPUs speed up training algorithms by?', ' GPUs reduce running times from weeks to what?', ' Dedicated hardware and algorithm optimizations can be used for what kind of models?']","['matrix/vector', 'orders of magnitude', 'days', 'deep learning']","[0.7626945078372955, 0.9807342886924744, 0.9922324419021606, 0.6848224997520447]"
45,deep learning,Hardware,"Since the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks that contain many layers of non-linear hidden units and a very large output layer. By 2019, graphic processing units (GPUs), often with AI-specific enhancements, had displaced CPUs as the dominant method of training large-scale commercial cloud AI. OpenAI estimated the hardware computation used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017), and found a 300,000-fold increase in the amount of computation required, with a doubling-time trendline of 3.4 months.","Since the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks that contain many layers of non-linear hidden units and a very large output layer. By 2019, graphic processing units (GPUs), often with AI-specific enhancements, had displaced CPUs as the dominant method of training large-scale commercial cloud AI.","OpenAI estimated the hardware computation used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017), and found a 300,000-fold increase in the amount of computation required, with a doubling-time trendline of 3.4 months.","[' OpenAI estimated the amount of computation used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017)?', ' OpenAI found a 300,000-fold increase in what?']","['300,000-fold increase', 'the amount of computation required']","[0.08772065676748753, 0.7733486890792847]"
46,deep learning,Relation to human cognitive and brain development,"Deep learning is closely related to a class of theories of brain development (specifically, neocortical development) proposed by cognitive neuroscientists in the early 1990s. These developmental theories were instantiated in computational models, making them predecessors of deep learning systems. These developmental models share the property that various proposed learning dynamics in the brain (e.g., a wave of nerve growth factor) support the self-organization somewhat analogous to the neural networks utilized in deep learning models. Like the neocortex, neural networks employ a hierarchy of layered filters in which each layer considers information from a prior layer (or the operating environment), and then passes its output (and possibly the original input), to other layers. This process yields a self-organizing stack of transducers, well-tuned to their operating environment. A 1995 description stated, ""...the infant's brain seems to organize itself under the influence of waves of so-called trophic-factors ... different regions of the brain become connected sequentially, with one layer of tissue maturing before another and so on until the whole brain is mature.""","Deep learning is closely related to a class of theories of brain development (specifically, neocortical development) proposed by cognitive neuroscientists in the early 1990s. These developmental theories were instantiated in computational models, making them predecessors of deep learning systems.","These developmental models share the property that various proposed learning dynamics in the brain (e.g., a wave of nerve growth factor) support the self-organization somewhat analogous to the neural networks utilized in deep learning models. Like the neocortex, neural networks employ a hierarchy of layered filters in which each layer considers information from a prior layer (or the operating environment), and then passes its output (and possibly the original input), to other layers. This process yields a self-organizing stack of transducers, well-tuned to their operating environment. A 1995 description stated, ""...the infant's brain seems to organize itself under the influence of waves of so-called trophic-factors ... different regions of the brain become connected sequentially, with one layer of tissue maturing before another and so on until the whole brain is mature.""","[' What do developmental models share with the neocortex?', ' What support the self-organization somewhat analogous to?', ' What does each layer consider from a prior layer or the operating environment?', ' What is the result of the hierarchy of layered filters?', ' What kind of transducers are well-tuned to their operating environment?', "" A 1995 description stated that the infant's brain seems to organize itself under the influence of what?"", ' Before another and so on until the whole brain is mature?']","['various proposed learning dynamics in the brain (e.g., a wave of nerve growth factor) support the self-organization', 'neural networks', 'information', 'a self-organizing stack of transducers', 'self-organizing stack', 'waves of so-called trophic-factors', 'one layer of tissue maturing before another']","[0.19821706414222717, 0.4437757730484009, 0.9903245866298676, 0.6479440629482269, 0.8733814656734467, 0.8236728012561798, 0.4243227243423462]"
47,deep learning,Relation to human cognitive and brain development,"A variety of approaches have been used to investigate the plausibility of deep learning models from a neurobiological perspective. On the one hand, several variants of the backpropagation algorithm have been proposed in order to increase its processing realism. Other researchers have argued that unsupervised forms of deep learning, such as those based on hierarchical generative models and deep belief networks, may be closer to biological reality. In this respect, generative neural network models have been related to neurobiological evidence about sampling-based processing in the cerebral cortex.","A variety of approaches have been used to investigate the plausibility of deep learning models from a neurobiological perspective. On the one hand, several variants of the backpropagation algorithm have been proposed in order to increase its processing realism.","Other researchers have argued that unsupervised forms of deep learning, such as those based on hierarchical generative models and deep belief networks, may be closer to biological reality. In this respect, generative neural network models have been related to neurobiological evidence about sampling-based processing in the cerebral cortex.","[' What are two forms of deep learning based on hierarchical generative models and deep belief networks?', ' What have generative neural network models been related to neurobiological evidence about?']","['unsupervised', 'sampling-based processing in the cerebral cortex']","[0.7205353528261185, 0.827689528465271]"
48,deep learning,Relation to human cognitive and brain development,"Although a systematic comparison between the human brain organization and the neuronal encoding in deep networks has not yet been established, several analogies have been reported. For example, the computations performed by deep learning units could be similar to those of actual neurons and neural populations. Similarly, the representations developed by deep learning models are similar to those measured in the primate visual system both at the single-unit and at the population levels.
","Although a systematic comparison between the human brain organization and the neuronal encoding in deep networks has not yet been established, several analogies have been reported. For example, the computations performed by deep learning units could be similar to those of actual neurons and neural populations.","Similarly, the representations developed by deep learning models are similar to those measured in the primate visual system both at the single-unit and at the population levels.",[' What are the representations developed by deep learning models similar to?'],['those measured in the primate visual system both at the single-unit and at the population levels'],[0.5792076885700226]
49,deep learning,Commercial activity,"Google's DeepMind Technologies developed a system capable of learning how to play Atari video games using only pixels as data input. In 2015 they demonstrated their AlphaGo system, which learned the game of Go well enough to beat a professional Go player. Google Translate uses a neural network to translate between more than 100 languages.
","Google's DeepMind Technologies developed a system capable of learning how to play Atari video games using only pixels as data input. In 2015 they demonstrated their AlphaGo system, which learned the game of Go well enough to beat a professional Go player.",Google Translate uses a neural network to translate between more than 100 languages.,[' Google Translate uses a neural network to translate between how many languages?'],['more than 100'],[0.7333177626132965]
50,deep learning,Commercial activity,"As of 2008, researchers at The University of Texas at Austin (UT) developed a machine learning framework called Training an Agent Manually via Evaluative Reinforcement, or TAMER, which proposed new methods for robots or computer programs to learn how to perform tasks by interacting with a human instructor. First developed as TAMER, a new algorithm called Deep TAMER was later introduced in 2018 during a collaboration between U.S. Army Research Laboratory (ARL) and UT researchers. Deep TAMER used deep learning to provide a robot the ability to learn new tasks through observation. Using Deep TAMER, a robot learned a task with a human trainer, watching video streams or observing a human perform a task in-person. The robot later practiced the task with the help of some coaching from the trainer, who provided feedback such as “good job” and “bad job.”","As of 2008, researchers at The University of Texas at Austin (UT) developed a machine learning framework called Training an Agent Manually via Evaluative Reinforcement, or TAMER, which proposed new methods for robots or computer programs to learn how to perform tasks by interacting with a human instructor. First developed as TAMER, a new algorithm called Deep TAMER was later introduced in 2018 during a collaboration between U.S. Army Research Laboratory (ARL) and UT researchers.","Deep TAMER used deep learning to provide a robot the ability to learn new tasks through observation. Using Deep TAMER, a robot learned a task with a human trainer, watching video streams or observing a human perform a task in-person. The robot later practiced the task with the help of some coaching from the trainer, who provided feedback such as “good job” and “bad job.”","[' Deep TAMER used deep learning to provide a robot the ability to learn new tasks through what?', ' A robot learned a task with a human trainer, watching video streams or what else?', ' The robot later practiced the task with the help of who?', ' What kind of feedback did the robot get from the trainer?']","['observation', 'observing a human perform a task in-person', 'the trainer', '“good job” and “bad job']","[0.990683913230896, 0.9490628242492676, 0.45566143095493317, 0.5511382669210434]"
51,data mining,Summary,"Data mining is a process of extracting and discovering patterns in large data sets involving methods at the intersection of machine learning, statistics, and database systems. Data mining is an interdisciplinary subfield of computer science and statistics with an overall goal of extracting information (with intelligent methods) from a data set and transform the information into a comprehensible structure for further use. Data mining is the analysis step of the ""knowledge discovery in databases"" process, or KDD. Aside from the raw analysis step, it also involves database and data management aspects, data pre-processing, model and inference considerations, interestingness metrics, complexity considerations, post-processing of discovered structures, visualization, and online updating.","Data mining is a process of extracting and discovering patterns in large data sets involving methods at the intersection of machine learning, statistics, and database systems. Data mining is an interdisciplinary subfield of computer science and statistics with an overall goal of extracting information (with intelligent methods) from a data set and transform the information into a comprehensible structure for further use.","Data mining is the analysis step of the ""knowledge discovery in databases"" process, or KDD. Aside from the raw analysis step, it also involves database and data management aspects, data pre-processing, model and inference considerations, interestingness metrics, complexity considerations, post-processing of discovered structures, visualization, and online updating.","[' What is the analysis step of the ""knowledge discovery in databases"" process?', ' What does KDD involve other than the raw analysis step?']","['Data mining', 'database and data management aspects']","[0.9825804233551025, 0.6369207203388214]"
52,data mining,Summary,"The term ""data mining"" is a misnomer, because the goal is the extraction of patterns and knowledge from large amounts of data, not the extraction (mining) of data itself. It also is a buzzword and is frequently applied to any form of large-scale data or information processing (collection, extraction, warehousing, analysis, and statistics) as well as any application of computer decision support system, including artificial intelligence (e.g., machine learning) and business intelligence. The book Data mining: Practical machine learning tools and techniques with Java (which covers mostly machine learning material) was originally to be named just Practical machine learning, and the term data mining was only added for marketing reasons. Often the more general terms (large scale) data analysis and analytics—or, when referring to actual methods, artificial intelligence and machine learning—are more appropriate.
","The term ""data mining"" is a misnomer, because the goal is the extraction of patterns and knowledge from large amounts of data, not the extraction (mining) of data itself. It also is a buzzword and is frequently applied to any form of large-scale data or information processing (collection, extraction, warehousing, analysis, and statistics) as well as any application of computer decision support system, including artificial intelligence (e.g., machine learning) and business intelligence.","The book Data mining: Practical machine learning tools and techniques with Java (which covers mostly machine learning material) was originally to be named just Practical machine learning, and the term data mining was only added for marketing reasons. Often the more general terms (large scale) data analysis and analytics—or, when referring to actual methods, artificial intelligence and machine learning—are more appropriate.","[' What was the original name of Data mining: Practical machine learning tools and techniques with Java?', ' Why was the term data mining added to the book?', ' What are the more general terms for large scale data analysis and analytics?', ' What are more appropriate when referring to actual methods?']","['Practical machine learning', 'marketing reasons', 'artificial intelligence and machine learning', 'artificial intelligence and machine learning']","[0.8769824802875519, 0.7632917165756226, 0.5085797756910324, 0.7624173760414124]"
53,data mining,Summary,"The actual data mining task is the semi-automatic or automatic analysis of large quantities of data to extract previously unknown, interesting patterns such as groups of data records (cluster analysis), unusual records (anomaly detection), and dependencies (association rule mining, sequential pattern mining). This usually involves using database techniques such as spatial indices. These patterns can then be seen as a kind of summary of the input data, and may be used in further analysis or, for example, in machine learning and predictive analytics. For example, the data mining step might identify multiple groups in the data, which can then be used to obtain more accurate prediction results by a decision support system. Neither the data collection, data preparation, nor result interpretation and reporting is part of the data mining step, but do belong to the overall KDD process as additional steps.
","The actual data mining task is the semi-automatic or automatic analysis of large quantities of data to extract previously unknown, interesting patterns such as groups of data records (cluster analysis), unusual records (anomaly detection), and dependencies (association rule mining, sequential pattern mining). This usually involves using database techniques such as spatial indices.","These patterns can then be seen as a kind of summary of the input data, and may be used in further analysis or, for example, in machine learning and predictive analytics. For example, the data mining step might identify multiple groups in the data, which can then be used to obtain more accurate prediction results by a decision support system. Neither the data collection, data preparation, nor result interpretation and reporting is part of the data mining step, but do belong to the overall KDD process as additional steps.","[' What can be seen as a kind of summary of the input data?', ' Machine learning and predictive analytics are examples of what?', ' What might the data mining step identify multiple groups in?', ' What can be used to obtain more accurate prediction results by a decision support system?', ' Data collection, data preparation, and result interpretation and reporting are not part of what step?']","['patterns', 'These patterns', 'the data', 'the data mining step', 'data mining step']","[0.8256309628486633, 0.3527442067861557, 0.7896385192871094, 0.4742238372564316, 0.5708035081624985]"
54,data mining,Etymology,"In the 1960s, statisticians and economists used terms like data fishing or data dredging to refer to what they considered the bad practice of analyzing data without an a-priori hypothesis. The term ""data mining"" was used in a similarly critical way by economist Michael Lovell in an article published in the Review of Economic Studies in 1983. Lovell indicates that the practice ""masquerades under a variety of aliases, ranging from ""experimentation"" (positive) to ""fishing"" or ""snooping"" (negative).
","In the 1960s, statisticians and economists used terms like data fishing or data dredging to refer to what they considered the bad practice of analyzing data without an a-priori hypothesis. The term ""data mining"" was used in a similarly critical way by economist Michael Lovell in an article published in the Review of Economic Studies in 1983.","Lovell indicates that the practice ""masquerades under a variety of aliases, ranging from ""experimentation"" (positive) to ""fishing"" or ""snooping"" (negative).","[' What does Lovell say the practice masquerades under a variety of aliases?', ' What is a positive word for experimentation?']","['experimentation', 'experimentation']","[0.16391251236200333, 0.6783678829669952]"
55,data mining,Etymology,"The term data mining appeared around 1990 in the database community, generally with positive connotations. For a short time in 1980s, a phrase ""database mining""™, was used, but since it was trademarked by HNC, a San Diego-based company, to pitch their Database Mining Workstation; researchers consequently turned to data mining. Other terms used include data archaeology, information harvesting, information discovery, knowledge extraction, etc. Gregory Piatetsky-Shapiro coined the term ""knowledge discovery in databases"" for the first workshop on the same topic (KDD-1989) and this term became more popular in AI and machine learning community. However, the term data mining became more popular in the business and press communities. Currently, the terms data mining and knowledge discovery are used interchangeably.
","The term data mining appeared around 1990 in the database community, generally with positive connotations. For a short time in 1980s, a phrase ""database mining""™, was used, but since it was trademarked by HNC, a San Diego-based company, to pitch their Database Mining Workstation; researchers consequently turned to data mining.","Other terms used include data archaeology, information harvesting, information discovery, knowledge extraction, etc. Gregory Piatetsky-Shapiro coined the term ""knowledge discovery in databases"" for the first workshop on the same topic (KDD-1989) and this term became more popular in AI and machine learning community. However, the term data mining became more popular in the business and press communities. Currently, the terms data mining and knowledge discovery are used interchangeably.","[' Who coined the term ""knowledge discovery in databases"" for the first workshop on the same topic?', ' What term became more popular in AI and machine learning community?', ' What term became more popular in the business and press communities?', ' What are the terms data mining and knowledge discovery used interchangeably?']","['Gregory Piatetsky-Shapiro', 'knowledge discovery in databases', 'data mining', 'data mining']","[0.9845908582210541, 0.662879467010498, 0.9057853817939758, 0.04790874943137169]"
56,data mining,Etymology,"In the academic community, the major forums for research started in 1995 when the First International Conference on Data Mining and Knowledge Discovery (KDD-95) was started in Montreal under AAAI sponsorship. It was co-chaired by Usama Fayyad and Ramasamy Uthurusamy. A year later, in 1996, Usama Fayyad launched the journal by Kluwer called Data Mining and Knowledge Discovery as its founding editor-in-chief. Later he started the SIGKDD Newsletter SIGKDD Explorations. The KDD International conference became the primary highest quality conference in data mining with an acceptance rate of research paper submissions below 18%. The journal Data Mining and Knowledge Discovery is the primary research journal of the field.
","In the academic community, the major forums for research started in 1995 when the First International Conference on Data Mining and Knowledge Discovery (KDD-95) was started in Montreal under AAAI sponsorship. It was co-chaired by Usama Fayyad and Ramasamy Uthurusamy.","A year later, in 1996, Usama Fayyad launched the journal by Kluwer called Data Mining and Knowledge Discovery as its founding editor-in-chief. Later he started the SIGKDD Newsletter SIGKDD Explorations. The KDD International conference became the primary highest quality conference in data mining with an acceptance rate of research paper submissions below 18%. The journal Data Mining and Knowledge Discovery is the primary research journal of the field.","[' When did Usama Fayyad launch Data Mining and Knowledge Discovery?', ' What was the name of the journal by Kluwer called?', ' Who was the founding editor-in-chief of the Kluwer journal?', ' The KDD International conference became the primary highest quality conference in what field?', ' What is the acceptance rate of research paper submissions in data mining?', ' Data Mining and Knowledge Discovery is the primary research journal of what field?']","['1996', 'Data Mining and Knowledge Discovery', 'Usama Fayyad', 'data mining', 'below 18%.', 'data mining']","[0.9662245512008667, 0.9235193133354187, 0.546513020992279, 0.987063080072403, 0.5923822522163391, 0.958573967218399]"
57,data mining,Background,"The manual extraction of patterns from data has occurred for centuries. Early methods of identifying patterns in data include Bayes' theorem (1700s) and regression analysis (1800s). The proliferation, ubiquity and increasing power of computer technology have dramatically increased data collection, storage, and manipulation ability. As data sets have grown in size and complexity, direct ""hands-on"" data analysis has increasingly been augmented with indirect, automated data processing, aided by other discoveries in computer science, specially in the field of machine learning, such as neural networks, cluster analysis, genetic algorithms (1950s), decision trees and decision rules (1960s), and support vector machines (1990s). Data mining is the process of applying these methods with the intention of uncovering hidden patterns. in large data sets. It bridges the gap from applied statistics and artificial intelligence (which usually provide the mathematical background) to database management by exploiting the way data is stored and indexed in databases to execute the actual learning and discovery algorithms more efficiently, allowing such methods to be applied to ever-larger data sets.
",The manual extraction of patterns from data has occurred for centuries. Early methods of identifying patterns in data include Bayes' theorem (1700s) and regression analysis (1800s).,"The proliferation, ubiquity and increasing power of computer technology have dramatically increased data collection, storage, and manipulation ability. As data sets have grown in size and complexity, direct ""hands-on"" data analysis has increasingly been augmented with indirect, automated data processing, aided by other discoveries in computer science, specially in the field of machine learning, such as neural networks, cluster analysis, genetic algorithms (1950s), decision trees and decision rules (1960s), and support vector machines (1990s). Data mining is the process of applying these methods with the intention of uncovering hidden patterns. in large data sets. It bridges the gap from applied statistics and artificial intelligence (which usually provide the mathematical background) to database management by exploiting the way data is stored and indexed in databases to execute the actual learning and discovery algorithms more efficiently, allowing such methods to be applied to ever-larger data sets.","[' What has dramatically increased data collection, storage, and manipulation ability?', ' What has increased as data sets have grown in size and complexity?', ' How has indirect, automated data processing been augmented?', ' In what decade were genetic algorithms first discovered?', ' What decade saw the discovery of decision trees and decision rules?', ' During what decade did support vector machines first appear?', ' What is the purpose of applying these methods?', ' What does it bridge the gap from applied statistics and artificial intelligence?', ' What can be indexed in databases to execute the actual learning and discovery algorithms?']","['The proliferation, ubiquity and increasing power of computer technology', 'data collection, storage, and manipulation ability', 'aided by other discoveries in computer science', '1950s', '1960s', '1990s', 'uncovering hidden patterns', 'Data mining', 'data']","[0.7180367559194565, 0.36182716488838196, 0.23649082705378532, 0.9532785713672638, 0.9531180262565613, 0.9432944059371948, 0.6394473612308502, 0.8591789603233337, 0.7307462394237518]"
58,data mining,Process,"Polls conducted in 2002, 2004, 2007 and 2014 show that the CRISP-DM methodology is the leading methodology used by data miners. The only other data mining standard named in these polls was SEMMA. However, 3–4 times as many people reported using CRISP-DM. Several teams of researchers have published reviews of data mining process models, and Azevedo and Santos conducted a comparison of CRISP-DM and SEMMA in 2008.","Polls conducted in 2002, 2004, 2007 and 2014 show that the CRISP-DM methodology is the leading methodology used by data miners. The only other data mining standard named in these polls was SEMMA.","However, 3–4 times as many people reported using CRISP-DM. Several teams of researchers have published reviews of data mining process models, and Azevedo and Santos conducted a comparison of CRISP-DM and SEMMA in 2008.","[' How many times as many people reported using CRISP-DM?', ' What has several teams of researchers published reviews of?', ' Azevedo and Santos conducted a comparison of what in 2008?']","['3–4', 'data mining process models', 'CRISP-DM and SEMMA']","[0.8089475929737091, 0.9671332836151123, 0.946826696395874]"
59,data mining,Standards,"There have been some efforts to define standards for the data mining process, for example, the 1999 European Cross Industry Standard Process for Data Mining (CRISP-DM 1.0) and the 2004 Java Data Mining standard (JDM 1.0). Development on successors to these processes (CRISP-DM 2.0 and JDM 2.0) was active in 2006 but has stalled since. JDM 2.0 was withdrawn without reaching a final draft.
","There have been some efforts to define standards for the data mining process, for example, the 1999 European Cross Industry Standard Process for Data Mining (CRISP-DM 1.0) and the 2004 Java Data Mining standard (JDM 1.0). Development on successors to these processes (CRISP-DM 2.0 and JDM 2.0) was active in 2006 but has stalled since.",JDM 2.0 was withdrawn without reaching a final draft.,[' What was withdrawn without reaching a final draft?'],['JDM 2.0'],[0.9766930937767029]
60,data mining,Standards,"For exchanging the extracted models—in particular for use in predictive analytics—the key standard is the Predictive Model Markup Language (PMML), which is an XML-based language developed by the Data Mining Group (DMG) and supported as exchange format by many data mining applications. As the name suggests, it only covers prediction models, a particular data mining task of high importance to business applications. However, extensions to cover (for example) subspace clustering have been proposed independently of the DMG.","For exchanging the extracted models—in particular for use in predictive analytics—the key standard is the Predictive Model Markup Language (PMML), which is an XML-based language developed by the Data Mining Group (DMG) and supported as exchange format by many data mining applications. As the name suggests, it only covers prediction models, a particular data mining task of high importance to business applications.","However, extensions to cover (for example) subspace clustering have been proposed independently of the DMG.",[' Extensions to cover subspace clustering have been proposed independently of what?'],['the DMG'],[0.7692156732082367]
61,data mining,Privacy concerns and ethics,"Data mining requires data preparation which uncovers information or patterns which compromise confidentiality and privacy obligations. A common way for this to occur is through data aggregation. Data aggregation involves combining data together (possibly from various sources) in a way that facilitates analysis (but that also might make identification of private, individual-level data deducible or otherwise apparent). This is not data mining per se, but a result of the preparation of data before—and for the purposes of—the analysis. The threat to an individual's privacy comes into play when the data, once compiled, cause the data miner, or anyone who has access to the newly compiled data set, to be able to identify specific individuals, especially when the data were originally anonymous.",Data mining requires data preparation which uncovers information or patterns which compromise confidentiality and privacy obligations. A common way for this to occur is through data aggregation.,"Data aggregation involves combining data together (possibly from various sources) in a way that facilitates analysis (but that also might make identification of private, individual-level data deducible or otherwise apparent). This is not data mining per se, but a result of the preparation of data before—and for the purposes of—the analysis. The threat to an individual's privacy comes into play when the data, once compiled, cause the data miner, or anyone who has access to the newly compiled data set, to be able to identify specific individuals, especially when the data were originally anonymous.","[' Data aggregation involves combining data together in a way that facilitates what?', ' What might make identification of private, individual-level data deducible?', "" What is a threat to an individual's privacy?"", ' Who can be able to identify specific individuals?', ' What is the purpose of the preparation of data?', ' To be able to identify specific individuals, especially when the data were originally anonymous?']","['analysis', 'Data aggregation', 'when the data, once compiled, cause the data miner, or anyone who has access to the newly compiled data set, to be able to identify specific individuals', 'the data miner', 'analysis', 'the data miner']","[0.9953294396400452, 0.8590757846832275, 0.36528556793928146, 0.473890095949173, 0.44808047264814377, 0.6481559723615646]"
62,data mining,Privacy concerns and ethics,"The inadvertent revelation of personally identifiable information leading to the provider violates Fair Information Practices.   This indiscretion can cause financial,
emotional, or bodily harm to the indicated individual.  In one instance of privacy violation, the patrons of Walgreens filed a lawsuit against the company in 2011 for selling
prescription information to data mining companies who in turn provided the data
to pharmaceutical companies.","The inadvertent revelation of personally identifiable information leading to the provider violates Fair Information Practices. This indiscretion can cause financial,
emotional, or bodily harm to the indicated individual.","In one instance of privacy violation, the patrons of Walgreens filed a lawsuit against the company in 2011 for selling
prescription information to data mining companies who in turn provided the data
to pharmaceutical companies.",[' In what year did patrons of Walgreens file a lawsuit against the company for selling prescription information to data mining companies?'],['2011'],[0.9912062883377075]
