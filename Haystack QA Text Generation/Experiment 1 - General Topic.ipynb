{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4222389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import *\n",
    "from haystack.document_stores import FAISSDocumentStore\n",
    "from haystack.schema import Document\n",
    "from haystack.nodes import DensePassageRetriever, FARMReader\n",
    "from haystack.pipelines import ExtractiveQAPipeline\n",
    "from haystack.utils import print_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc8e231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as urllib2\n",
    "from googlesearch import search\n",
    "from bs4.element import Comment\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fe04566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_documents(urls):\n",
    "    \n",
    "    documents = []\n",
    "\n",
    "    for j, url in enumerate(urls):        \n",
    "        try:\n",
    "            hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "            req = urllib2.Request(url, headers = hdr)\n",
    "            page = urllib2.urlopen(req)\n",
    "            soup = BeautifulSoup(page, \"html.parser\")\n",
    "            \n",
    "            for i, paragraph in enumerate(soup.findAll(\"p\")):\n",
    "                p = paragraph.text.split()\n",
    "                if len(p) == 0:\n",
    "                    continue\n",
    "                documents.append(Document(content = \" \".join(p)))   \n",
    "        except:\n",
    "            \"crap\"\n",
    "        \n",
    "    return documents\n",
    "\n",
    "def create_docs(directory):\n",
    "    import os\n",
    "    \n",
    "    docs = []\n",
    "\n",
    "    document_names = os.listdir(f\"./{directory}\")\n",
    "    for doc in document_names:\n",
    "        text = open(f\"{directory}/{doc}\",  encoding = 'utf8').read()\n",
    "        docs.append(Document(content = text))\n",
    "        \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7f01c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is machine learning?\"\n",
    "urls = [url for url in search(query, tld = \"co.in\", num = 50, stop = 40, pause = 0.5)]   \n",
    "urls = [url for url in urls if \"html\" not in url and \"wikipedia\" not in url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb8315fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = create_documents(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5820c904",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store = FAISSDocumentStore(vector_dim=128, faiss_index_factory_str=\"Flat\")\n",
    "document_store.delete_documents()\n",
    "document_store.write_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f6c6dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RetriBertModel were not initialized from the model checkpoint at yjernite/retribert-base-uncased and are newly initialized: ['bert_query.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Updating Embedding:   0%|                                                                  | 0/1343 [00:00<?, ? docs/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1906744dbcc4d36a98d352261d1a5e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating Embeddings:   0%|          | 0/42 [00:00<?, ? Batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Documents Processed: 10000 docs [43:53,  3.80 docs/s]                                                                  \n"
     ]
    }
   ],
   "source": [
    "from haystack.retriever.dense import EmbeddingRetriever\n",
    "\n",
    "retriever = EmbeddingRetriever(document_store=document_store,\n",
    "                               embedding_model=\"yjernite/retribert-base-uncased\",\n",
    "                               model_format=\"retribert\")\n",
    "\n",
    "document_store.update_embeddings(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "92d40948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "------------Min Length: 0------------\n",
      "\n",
      "\n",
      " It depends on what you mean by \"machine learning model\". There are a lot of different ways to evaluate a machine learning model, but the most common way is to look at how well the model performs in a real world situation. For example, if you have a model that predicts how many ice creams will be sold based on the temperature, and you give it a set of training data, it will give you a very good prediction. If you give the model a new set of data, and it gives you a much better prediction, then you can say that the model is better than the training data.\n",
      "\n",
      "\n",
      "------------Min Length: 50------------\n",
      "\n",
      "\n",
      " It depends on what you mean by \"machine learning model\". There are a lot of different ways to evaluate a machine learning model, but the most common way is to look at how well the model performs in a real world situation. For example, if you have a model that predicts how many ice creams will be sold based on the temperature, and you give it a set of training data, it will give you a very good prediction. If you give the model a new set of data, and it gives you a much better prediction, then you can say that the model is better than the training data.\n",
      "\n",
      "\n",
      "------------Min Length: 100------------\n",
      "\n",
      "\n",
      " It depends on what you mean by \"machine learning model\". There are a lot of different ways to evaluate a machine learning model, but the most common way is to look at how well the model performs in a real world situation. For example, if you have a model that predicts how many ice creams will be sold based on the temperature, and you give it a set of training data, it will give you a very good prediction. If you give the model a new set of data, and it gives you a much better prediction, then you can say that the model is better than the training data.\n",
      "\n",
      "\n",
      "------------Extracted Documents------------\n",
      "\n",
      "\n",
      "When training a machine-learning model, typically about 60% of a dataset is used for training. A further 20% of the data is used to validate the predictions made by the model and adjust additional parameters that optimize the model's output. This fine tuning is designed to boost the accuracy of the model's prediction when presented with new data.\n",
      "\n",
      "\n",
      "A good way to explain the training process is to consider an example using a simple machine-learning model, known as linear regression with gradient descent. In the following example, the model is used to estimate how many ice creams will be sold based on the outside temperature.\n",
      "\n",
      "\n",
      "A traditional machine learning algorithm can be something as simple as linear regression. For instance, imagine you want to predict your income given your years of higher education. In a first step, you have to define a function, e.g. income = y + x * years of education. Then, give your algorithm a set of training data. This could be a simple table with data on some people’s years of higher education and their associated income. Next, let your algorithm draw the line, e.g. through an ordinary least squares (OLS) regression. Now, you can give the algorithm some test data, e.g. your personal years of higher education, and let it predict your income.\n",
      "\n",
      "\n",
      "The gathered data is then split, into a larger proportion for training, say about 70%, and a smaller proportion for evaluation, say the remaining 30%. This evaluation data allows the trained model to be tested, to see how well it is likely to perform on real-world data.\n",
      "\n",
      "\n",
      "The prepared data is split into two groups: the training set and the test set. The training set is a large portion of your data that’s used to tune your machine learning models to the highest accuracy.\n"
     ]
    }
   ],
   "source": [
    "from haystack.generator.transformers import Seq2SeqGenerator\n",
    "from haystack.pipeline import GenerativeQAPipeline\n",
    "\n",
    "generator0 = Seq2SeqGenerator(model_name_or_path=\"yjernite/bart_eli5\", min_length = 0)\n",
    "pipe0 = GenerativeQAPipeline(generator0, retriever)\n",
    "\n",
    "generator50 = Seq2SeqGenerator(model_name_or_path=\"yjernite/bart_eli5\", min_length = 50)\n",
    "pipe50 = GenerativeQAPipeline(generator50, retriever)\n",
    "\n",
    "generator100 = Seq2SeqGenerator(model_name_or_path=\"yjernite/bart_eli5\", min_length = 100)\n",
    "pipe100 = GenerativeQAPipeline(generator100, retriever)\n",
    "\n",
    "\n",
    "q = \"What metrics do we use to evaluate machine learning models?\"\n",
    "\n",
    "ret0 = pipe0.run(query = q, params = {\"Retriever\": {\"top_k\": 5}})\n",
    "ret50 = pipe50.run(query = q, params = {\"Retriever\": {\"top_k\": 5}})\n",
    "ret100 = pipe100.run(query = q, params = {\"Retriever\": {\"top_k\": 5}})\n",
    "\n",
    "print(\"\\n\\n------------Min Length: 0------------\\n\\n\")\n",
    "print(ret0[\"answers\"][0])\n",
    "\n",
    "print(\"\\n\\n------------Min Length: 50------------\\n\\n\")\n",
    "print(ret50[\"answers\"][0])\n",
    "\n",
    "print(\"\\n\\n------------Min Length: 100------------\\n\\n\")\n",
    "print(ret100[\"answers\"][0])\n",
    "\n",
    "\n",
    "print(\"\\n\\n------------Extracted Documents------------\\n\\n\")\n",
    "print(\"\\n\\n\\n\".join([c.content for c in ret0[\"documents\"]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
